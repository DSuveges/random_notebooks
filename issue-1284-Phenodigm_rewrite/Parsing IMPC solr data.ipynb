{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:16:58.834596Z",
     "start_time": "2021-02-08T20:16:58.823553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version:  3.0.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext\n",
    "import re\n",
    "\n",
    "global spark\n",
    "\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '20g')\n",
    "\n",
    "spark = (pyspark.sql.SparkSession\n",
    "    .builder\n",
    "    .appName(\"phenodigm_parser\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.bindAddress\", \"localhost\")\n",
    "    .config(\"spark.sql.broadcastTimeout\", \"36000\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "print('Spark version: ', spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing `type == 'gene'`\n",
    "\n",
    "This is the workflow:\n",
    "\n",
    "```Python\n",
    "if doc['type'] == 'gene':\n",
    "    # this is a human gene\n",
    "    if 'hgnc_gene_id' in doc:\n",
    "        hgnc_gene_id = doc['hgnc_gene_id']\n",
    "        hgnc_gene_symbol = doc['hgnc_gene_symbol']\n",
    "        self.symbol2hgncids[hgnc_gene_symbol] = hgnc_gene_id\n",
    "    elif 'gene_id' in doc:\n",
    "        gene_id = doc['gene_id']\n",
    "        gene_symbol = doc['gene_symbol']\n",
    "        self.mgi2symbols[gene_id] = gene_symbol\n",
    "                            \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:17:11.159931Z",
     "start_time": "2021-02-08T20:17:06.366953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|hgnc_gene_id|hgnc_gene_symbol|\n",
      "+------------+----------------+\n",
      "|      HGNC:5|            A1BG|\n",
      "|  HGNC:37133|        A1BG-AS1|\n",
      "|  HGNC:24086|            A1CF|\n",
      "|      HGNC:7|             A2M|\n",
      "|  HGNC:27057|         A2M-AS1|\n",
      "|  HGNC:23336|           A2ML1|\n",
      "|  HGNC:41022|       A2ML1-AS1|\n",
      "|  HGNC:41523|       A2ML1-AS2|\n",
      "|      HGNC:8|           A2MP1|\n",
      "|  HGNC:30005|         A3GALT2|\n",
      "|  HGNC:18149|          A4GALT|\n",
      "|  HGNC:17968|           A4GNT|\n",
      "|  HGNC:13666|            AAAS|\n",
      "|  HGNC:21298|            AACS|\n",
      "|  HGNC:18226|          AACSP1|\n",
      "|     HGNC:17|           AADAC|\n",
      "|  HGNC:24427|         AADACL2|\n",
      "|  HGNC:50301|     AADACL2-AS1|\n",
      "|  HGNC:32037|         AADACL3|\n",
      "|  HGNC:32038|         AADACL4|\n",
      "+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42346"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_json_files = 'cicaful/type.gene'\n",
    "\n",
    "\n",
    "# Reading and filter files:\n",
    "genes_table = (\n",
    "    spark.read.json(gene_json_files)\n",
    "    .select('hgnc_gene_id', 'hgnc_gene_symbol')\n",
    "    .filter(col('hgnc_gene_id').isNotNull())\n",
    ")\n",
    "\n",
    "# genes_table\n",
    "genes_table.show()\n",
    "genes_table.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing `type == 'gene-gene'`\n",
    "\n",
    "Workflow:\n",
    "\n",
    "```Python\n",
    "elif doc['type'] == 'gene_gene':\n",
    "    # gene_id # hgnc_gene_id\n",
    "    hgnc_gene_id = doc['hgnc_gene_id']\n",
    "    gene_id = doc['gene_id']\n",
    "    if hgnc_gene_id and not hgnc_gene_id in self.hgnc2mgis:\n",
    "        self.hgnc2mgis[hgnc_gene_id] = []\n",
    "    self.hgnc2mgis[hgnc_gene_id].append(gene_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:17:32.308201Z",
     "start_time": "2021-02-08T20:17:31.401878Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_gene_json_files = 'cicaful/type.gene_gene'\n",
    "\n",
    "# For now,I'm not sure if it make sense to do the aggregation.\n",
    "# Aggregation was required because the data was stored in dictionaries\n",
    "gene_gene_table = (\n",
    "    spark.read.json(gene_gene_json_files)\n",
    "    .select('hgnc_gene_id','gene_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing `type == 'mouse_model'`\n",
    "\n",
    "Workflow:\n",
    "\n",
    "```Python\n",
    "elif doc['type'] == 'mouse_model':\n",
    "    marker_symbol = doc['marker_symbol']\n",
    "    marker_id = doc['marker_id']\n",
    "    model_id = doc['model_id']\n",
    "\n",
    "    # if there is a mouse model then add the marker id\n",
    "    if marker_id not in self.mgi2symbols:\n",
    "        self.mgi2symbols[marker_id] = marker_symbol\n",
    "\n",
    "    if not marker_symbol in self.mgi2mouse_models:\n",
    "        self.mgi2mouse_models[marker_symbol] = []\n",
    "    self.mgi2mouse_models[marker_symbol].append(model_id)\n",
    "\n",
    "    if not model_id in self.mouse_models:\n",
    "        self.mouse_models[model_id] = doc\n",
    "\n",
    "        model_phenotypes = []\n",
    "        for raw_mp in doc['model_phenotypes']:\n",
    "            mt = re.match(\"^(MP\\:\\d+)\\s+\", raw_mp)\n",
    "            if mt:\n",
    "                mp_id = mt.groups()[0]\n",
    "                model_phenotypes.append(mp_id)\n",
    "        self.mouse_models[model_id]['model_phenotypes'] = model_phenotypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:17:36.284790Z",
     "start_time": "2021-02-08T20:17:32.464241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+--------------------+------------------+\n",
      "|  marker_id|marker_symbol|   model_id|     model_phenotype|model_phenotype_id|\n",
      "+-----------+-------------+-----------+--------------------+------------------+\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0002160 abnorm...|        MP:0002160|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0004852 decrea...|        MP:0004852|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0002687 oligoz...|        MP:0002687|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0004884 abnorm...|        MP:0004884|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0001153 small ...|        MP:0001153|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0006042 increa...|        MP:0006042|\n",
      "|MGI:1096566|        Pias2|MGI:2678495|MP:0001146 abnorm...|        MP:0001146|\n",
      "|  MGI:94909|          Dmd|MGI:2678497|MP:0002169 no abn...|        MP:0002169|\n",
      "|MGI:1354961|        Synj1|MGI:2678499|MP:0011089 perina...|        MP:0011089|\n",
      "|MGI:1927868|        Pex14|MGI:2678502|MP:0011091 prenat...|        MP:0011091|\n",
      "|MGI:1321395|        Ltbp4|MGI:2678503|MP:0005330 cardio...|        MP:0005330|\n",
      "|MGI:1321395|        Ltbp4|MGI:2678503|MP:0001958 emphysema|        MP:0001958|\n",
      "|MGI:1321395|        Ltbp4|MGI:2678503|MP:0010279 increa...|        MP:0010279|\n",
      "|MGI:1276102|          Aqr|MGI:2678504|MP:0002169 no abn...|        MP:0002169|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0011353 expand...|        MP:0011353|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0002705 dilate...|        MP:0002705|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0008062 abnorm...|        MP:0008062|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0011085 postna...|        MP:0011085|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0008061 absent...|        MP:0008061|\n",
      "|MGI:1859637|        Nphs1|MGI:2678505|MP:0005325 abnorm...|        MP:0005325|\n",
      "+-----------+-------------+-----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250144"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_model_json_files = 'cicaful/type.mouse_model'\n",
    "\n",
    "get_id = udf(\n",
    "    lambda x:  re.match(\"^(MP\\:\\d+)\\s+\", x).groups()[0],\n",
    "    StringType()\n",
    ")\n",
    "   \n",
    "\n",
    "# For now,I'm not sure if it make sense to do the aggregation.\n",
    "# Aggregation was required because the data was stored in dictionaries\n",
    "mouse_model_table = (\n",
    "    spark.read.json(mouse_model_json_files)\n",
    "    .select('marker_id', 'marker_symbol', 'model_id', 'model_phenotypes') # marker id = mouse gene id\n",
    "    .na.drop(subset=[\"marker_id\"])\n",
    "    .withColumn('model_phenotype', explode(col('model_phenotypes')))\n",
    "    .withColumn('model_phenotype_id',get_id(col('model_phenotype')))\n",
    "    .drop('model_phenotypes')\n",
    ")\n",
    "mouse_model_table.show()\n",
    "mouse_model_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T00:37:50.178674Z",
     "start_time": "2021-02-06T00:37:50.115401Z"
    }
   },
   "source": [
    "## Parsing `type == 'disease_model_summary'`\n",
    "\n",
    "Workflow:\n",
    "\n",
    "```Python\n",
    "elif doc['type'] == 'disease_model_summary':\n",
    "    model_id = doc['model_id']\n",
    "    if not model_id in self.mouse_model2diseases:\n",
    "        self.mouse_model2diseases[model_id] = []\n",
    "    self.mouse_model2diseases[model_id].append(doc)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:22:31.455237Z",
     "start_time": "2021-02-08T20:17:36.287073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['association_curated', 'disease_id', 'disease_model_avg_norm', 'disease_model_avg_raw', 'disease_model_max_norm', 'disease_model_max_raw', 'disease_term', 'marker_id', 'marker_locus', 'marker_num_models', 'marker_symbol', 'model_description', 'model_genetic_background', 'model_id', 'model_source', 'type']\n",
      "7016415\n",
      "40280\n"
     ]
    }
   ],
   "source": [
    "disease_model_summary_json_files = 'cicaful/type.disease_model_summary/'\n",
    "\n",
    "# For now,I'm not sure if it make sense to do the aggregation.\n",
    "# Aggregation was required because the data was stored in dictionaries\n",
    "disease_model_table = (\n",
    "    spark.read.json(disease_model_summary_json_files)\n",
    ")\n",
    "\n",
    "# (\n",
    "#     disease_model_table\n",
    "#     .select('association_curated', 'disease_id', 'disease_term', 'marker_id', 'marker_num_models','model_description', 'model_genetic_background', 'model_id')\n",
    "#     .where(col('model_id') == 'MGI:2678495')\n",
    "#     .show()\n",
    "# )\n",
    "\n",
    "print(disease_model_table.columns)\n",
    "print(disease_model_table.count())\n",
    "print(disease_model_table.select('model_id').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:22:49.338444Z",
     "start_time": "2021-02-08T20:22:31.458575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                type|\n",
      "+--------------------+\n",
      "|disease_model_sum...|\n",
      "+--------------------+\n",
      "\n",
      "None\n",
      "12735\n"
     ]
    }
   ],
   "source": [
    "print(disease_model_table.select('type').distinct().show())\n",
    "print(disease_model_table.select('marker_id').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging genes\n",
    "\n",
    "\n",
    "Merging `human_genes` wiht `mouse_genes` and `gene_gene` tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:25:01.455375Z",
     "start_time": "2021-02-08T20:25:00.264464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25163\n",
      "303771\n",
      "42346\n",
      "25168\n"
     ]
    }
   ],
   "source": [
    "print(genes_joined.count())\n",
    "print(mouse_genes.count())\n",
    "print(human_genes.count())\n",
    "print(gene_gene_table.count())\n",
    "# print(mouse_model_table.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:25:03.674221Z",
     "start_time": "2021-02-08T20:25:02.469916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(gene_id='MGI:1913917')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_joined.select(\"gene_id\").collect()[17623]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:38:59.004657Z",
     "start_time": "2021-02-08T17:38:58.168330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52773"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_model_table.select('model_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T17:39:39.411777Z",
     "start_time": "2021-02-08T17:39:39.194317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250144"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_model_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T15:48:10.180515Z",
     "start_time": "2021-02-08T15:48:09.435824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------------+-----------+--------------------+------------------+-----------+----------------+\n",
      "|hgnc_gene_id|  marker_id|marker_symbol|   model_id|     model_phenotype|model_phenotype_id|    gene_id|hgnc_gene_symbol|\n",
      "+------------+-----------+-------------+-----------+--------------------+------------------+-----------+----------------+\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0002160 abnorm...|        MP:0002160|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0004852 decrea...|        MP:0004852|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0002687 oligoz...|        MP:0002687|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0004884 abnorm...|        MP:0004884|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0001153 small ...|        MP:0001153|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0006042 increa...|        MP:0006042|MGI:1096566|           PIAS2|\n",
      "|  HGNC:17311|MGI:1096566|        Pias2|MGI:2678495|MP:0001146 abnorm...|        MP:0001146|MGI:1096566|           PIAS2|\n",
      "|   HGNC:2928|  MGI:94909|          Dmd|MGI:2678497|MP:0002169 no abn...|        MP:0002169|  MGI:94909|             DMD|\n",
      "|  HGNC:11503|MGI:1354961|        Synj1|MGI:2678499|MP:0011089 perina...|        MP:0011089|MGI:1354961|           SYNJ1|\n",
      "|   HGNC:8856|MGI:1927868|        Pex14|MGI:2678502|MP:0011091 prenat...|        MP:0011091|MGI:1927868|           PEX14|\n",
      "|   HGNC:6717|MGI:1321395|        Ltbp4|MGI:2678503|MP:0005330 cardio...|        MP:0005330|MGI:1321395|           LTBP4|\n",
      "|   HGNC:6717|MGI:1321395|        Ltbp4|MGI:2678503|MP:0001958 emphysema|        MP:0001958|MGI:1321395|           LTBP4|\n",
      "|   HGNC:6717|MGI:1321395|        Ltbp4|MGI:2678503|MP:0010279 increa...|        MP:0010279|MGI:1321395|           LTBP4|\n",
      "|  HGNC:29513|MGI:1276102|          Aqr|MGI:2678504|MP:0002169 no abn...|        MP:0002169|MGI:1276102|             AQR|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0011353 expand...|        MP:0011353|MGI:1859637|           NPHS1|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0002705 dilate...|        MP:0002705|MGI:1859637|           NPHS1|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0008062 abnorm...|        MP:0008062|MGI:1859637|           NPHS1|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0011085 postna...|        MP:0011085|MGI:1859637|           NPHS1|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0008061 absent...|        MP:0008061|MGI:1859637|           NPHS1|\n",
      "|   HGNC:7908|MGI:1859637|        Nphs1|MGI:2678505|MP:0005325 abnorm...|        MP:0005325|MGI:1859637|           NPHS1|\n",
      "+------------+-----------+-------------+-----------+--------------------+------------------+-----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_for_human_genes = (\n",
    "    mouse_model_table\n",
    "    .join(gene_gene_table, mouse_model_table.marker_id == gene_gene_table.gene_id, how='inner')\n",
    "    .join(genes_table, on='hgnc_gene_id', how='inner')\n",
    ")\n",
    "\n",
    "models_for_human_genes.count()\n",
    "models_for_human_genes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T16:07:32.298851Z",
     "start_time": "2021-02-08T16:07:19.575400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------------------+---------------------+----------------------+---------------------+------------+---------+------------+-----------------+-------------+-----------------+------------------------+--------+------------+----+\n",
      "|association_curated|disease_id|disease_model_avg_norm|disease_model_avg_raw|disease_model_max_norm|disease_model_max_raw|disease_term|marker_id|marker_locus|marker_num_models|marker_symbol|model_description|model_genetic_background|model_id|model_source|type|\n",
      "+-------------------+----------+----------------------+---------------------+----------------------+---------------------+------------+---------+------------+-----------------+-------------+-----------------+------------------------+--------+------------+----+\n",
      "+-------------------+----------+----------------------+---------------------+----------------------+---------------------+------------+---------+------------+-----------------+-------------+-----------------+------------------------+--------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disease_model_table.where(col('model_id') == 'MGI:2585941').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T12:38:30.424794Z",
     "start_time": "2021-02-08T12:38:29.509043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13109"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_table_joined.select('hgnc_gene_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T13:13:28.985743Z",
     "start_time": "2021-02-08T13:13:28.981191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['association_curated',\n",
       " 'disease_id',\n",
       " 'disease_model_avg_norm',\n",
       " 'disease_model_avg_raw',\n",
       " 'disease_model_max_norm',\n",
       " 'disease_model_max_raw',\n",
       " 'disease_term',\n",
       " 'marker_id',\n",
       " 'marker_locus',\n",
       " 'marker_num_models',\n",
       " 'marker_symbol',\n",
       " 'model_description',\n",
       " 'model_genetic_background',\n",
       " 'model_id',\n",
       " 'model_source',\n",
       " 'type']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_model_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T13:14:25.406563Z",
     "start_time": "2021-02-08T13:14:25.346751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|  marker_id|marker_symbol|\n",
      "+-----------+-------------+\n",
      "|  MGI:96575|         Insr|\n",
      "|  MGI:98419|          Sri|\n",
      "|MGI:1920230|        Wdr11|\n",
      "|MGI:1920230|        Wdr11|\n",
      "|  MGI:97394|          Oat|\n",
      "|  MGI:95657|         Gas2|\n",
      "|MGI:2676312|       Abca12|\n",
      "|MGI:1921393|         Opa1|\n",
      "|  MGI:88378|        Ces1g|\n",
      "|  MGI:96217|         Hprt|\n",
      "|MGI:2147834|       Slc6a8|\n",
      "|MGI:1934606|        Alms1|\n",
      "|MGI:6198564|        conls|\n",
      "|MGI:1098827|        Reep1|\n",
      "|MGI:2442833|         Bbs9|\n",
      "|MGI:3828086|        Zbed6|\n",
      "|MGI:1917706|         Mpc2|\n",
      "|MGI:1924956|        Abcb5|\n",
      "|MGI:3588197|         Vrtn|\n",
      "|MGI:1859152|       Pla2g6|\n",
      "+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disease_model_table.select('marker_id','marker_symbol').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the mouse model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:25:22.076075Z",
     "start_time": "2021-02-08T20:25:18.311703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52773\n",
      "+-----------+-------------+--------------------+------------------------+-----------+--------------------+------------+-----------+\n",
      "|  marker_id|marker_symbol|   model_description|model_genetic_background|   model_id|    model_phenotypes|model_source|       type|\n",
      "+-----------+-------------+--------------------+------------------------+-----------+--------------------+------------+-----------+\n",
      "|MGI:1096566|        Pias2|Pias2<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678495|[MP:0002160 abnor...|         MGI|mouse_model|\n",
      "|  MGI:94909|          Dmd|Dmd<Gt(pT1ATGBeta...|    involves: 129S2/S...|MGI:2678497|[MP:0002169 no ab...|         MGI|mouse_model|\n",
      "|MGI:1354961|        Synj1|Synj1<Gt(pT1ATGBe...|    involves: 129S2/S...|MGI:2678499|[MP:0011089 perin...|         MGI|mouse_model|\n",
      "|MGI:1927868|        Pex14|Pex14<Gt(pT1Betag...|    involves: 129S2/S...|MGI:2678502|[MP:0011091 prena...|         MGI|mouse_model|\n",
      "|MGI:1321395|        Ltbp4|Ltbp4<Gt(U3Cre)1V...|    involves: 129S2/S...|MGI:2678503|[MP:0005330 cardi...|         MGI|mouse_model|\n",
      "|MGI:1276102|          Aqr|Aqr<Gt(pT1Betageo...|    involves: 129S2/S...|MGI:2678504|[MP:0002169 no ab...|         MGI|mouse_model|\n",
      "|MGI:1859637|        Nphs1|Nphs1<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678505|[MP:0011353 expan...|         MGI|mouse_model|\n",
      "|MGI:1859637|        Nphs1|Nphs1<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678506|[MP:0008139 fused...|         MGI|mouse_model|\n",
      "|MGI:1347351|         Ncdn|Ncdn<Gt(pT1Betage...|    involves: 129S2/S...|MGI:2678507|[MP:0013454 lacri...|         MGI|mouse_model|\n",
      "|  MGI:98970|         Xbp1|Xbp1<tm1Nogu>/Xbp...|    involves: 129S/Sv...|MGI:2678536|[MP:0006085 myoca...|         MGI|mouse_model|\n",
      "| MGI:893578|       Scarb1|Scarb1<Hdlq1-NZB/...|    involves: NZB/BlN...|MGI:2678541|[MP:0001556 incre...|         MGI|mouse_model|\n",
      "| MGI:893578|       Scarb1|Scarb1<Hdlq1-NZB/...|    involves: NZB/BlN...|MGI:2678542|[MP:0001556 incre...|         MGI|mouse_model|\n",
      "|MGI:1933547|       Tas1r3|Tas1r3<tm1Rfm>/Ta...|       involves: C57BL/6|MGI:2678583|[MP:0004213 abnor...|         MGI|mouse_model|\n",
      "|MGI:1096325|        Mesp2|Mesp2<tm4Ysa>/Mes...|    involves: C57BL/6...|MGI:2678614|[MP:0004605 abnor...|         MGI|mouse_model|\n",
      "|  MGI:97816|       Ptprz1|Ptprz1<tm1Mno>/Pt...|    involves: 129S1/S...|MGI:2678758|[MP:0002169 no ab...|         MGI|mouse_model|\n",
      "|  MGI:97816|       Ptprz1|Ptprz1<tm1Mno>/Pt...|    B6.129-Ptprz1<tm1...|MGI:2678759|[MP:0001463 abnor...|         MGI|mouse_model|\n",
      "|MGI:1097692|       Opn1mw|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678771|[MP:0002090 abnor...|         MGI|mouse_model|\n",
      "|MGI:1097692|       Opn1mw|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678773|[MP:0002090 abnor...|         MGI|mouse_model|\n",
      "|MGI:1097692|       Opn1mw|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678774|[MP:0002090 abnor...|         MGI|mouse_model|\n",
      "| MGI:108072|        Traf6|Traf6<tm1Ywc>/Tra...|           Not Specified|MGI:2678795|[MP:0008664 decre...|         MGI|mouse_model|\n",
      "+-----------+-------------+--------------------+------------------------+-----------+--------------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mouse_model_json_files = 'cicaful/type.mouse_model'\n",
    "\n",
    "\n",
    "# For now,I'm not sure if it make sense to do the aggregation.\n",
    "# Aggregation was required because the data was stored in dictionaries\n",
    "mouse_model_table = (\n",
    "    spark.read.json(mouse_model_json_files)\n",
    ")\n",
    "\n",
    "\n",
    "# Number of rows in the models table:\n",
    "print(mouse_model_table.count())\n",
    "\n",
    "mouse_model_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:21:20.331301Z",
     "start_time": "2021-02-08T18:21:19.507231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52773\n",
      "+--------------------+\n",
      "|        model_source|\n",
      "+--------------------+\n",
      "|     EuroPhenome,MGP|\n",
      "|EuroPhenome,3i,IM...|\n",
      "|              3i,MGP|\n",
      "|         3i,IMPC,MGP|\n",
      "|             3i,IMPC|\n",
      "|                 MGP|\n",
      "|                IMPC|\n",
      "|  EuroPhenome,3i,MGP|\n",
      "|    EuroPhenome,IMPC|\n",
      "|      EuroPhenome,3i|\n",
      "|                  3i|\n",
      "| EuroPhenome,3i,IMPC|\n",
      "|         EuroPhenome|\n",
      "|                 MGI|\n",
      "|            IMPC,MGP|\n",
      "+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Number of unique model id:\n",
    "print(mouse_model_table.select('model_id').distinct().count())\n",
    "print(mouse_model_table.select('model_source').distinct().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:33:12.955016Z",
     "start_time": "2021-02-08T18:33:12.650431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+------------------------+--------------------+--------------------+------------+-----------+\n",
      "|  marker_id|marker_symbol|   model_description|model_genetic_background|            model_id|    model_phenotypes|model_source|       type|\n",
      "+-----------+-------------+--------------------+------------------------+--------------------+--------------------+------------+-----------+\n",
      "|MGI:2385884|        Ddx27|Ddx27<tm1a(KOMP)W...|             C57BL/6NTac|MGI:4363861#het#e...|[MP:0001488 incre...|    IMPC,MGP|mouse_model|\n",
      "+-----------+-------------+--------------------+------------------------+--------------------+--------------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mouse_model_table.where(col('model_source')=='EuroPhenome,3i').select('model_id','marker_id','model_description').toPandas().model_id\n",
    "(\n",
    "    mouse_model_table\n",
    "    .where(col('model_id') ==  'MGI:4363861#het#early')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T18:30:53.634559Z",
     "start_time": "2021-02-08T18:30:48.333392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MGI:4432914#hom#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4364810#het#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4431547#het#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4364794#hom#early',\n",
       " 'MGI:4432914#hom#early',\n",
       " 'MGI:4363861#het#early',\n",
       " 'MGI:4431677#het#early',\n",
       " 'MGI:4432914#hom#early']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_model_table.where(col('model_source')=='IMPC,MGP').select('model_id').limit(20).toPandas().model_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T19:13:46.126613Z",
     "start_time": "2021-02-08T19:13:46.007335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+-----------+--------------------+\n",
      "|   model_description|model_genetic_background|   model_id|    model_phenotypes|\n",
      "+--------------------+------------------------+-----------+--------------------+\n",
      "|Pias2<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678495|[MP:0002160 abnor...|\n",
      "|Dmd<Gt(pT1ATGBeta...|    involves: 129S2/S...|MGI:2678497|[MP:0002169 no ab...|\n",
      "|Synj1<Gt(pT1ATGBe...|    involves: 129S2/S...|MGI:2678499|[MP:0011089 perin...|\n",
      "|Pex14<Gt(pT1Betag...|    involves: 129S2/S...|MGI:2678502|[MP:0011091 prena...|\n",
      "|Ltbp4<Gt(U3Cre)1V...|    involves: 129S2/S...|MGI:2678503|[MP:0005330 cardi...|\n",
      "|Aqr<Gt(pT1Betageo...|    involves: 129S2/S...|MGI:2678504|[MP:0002169 no ab...|\n",
      "|Nphs1<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678505|[MP:0011353 expan...|\n",
      "|Nphs1<Gt(pT1Betag...|    involves: 129P2/O...|MGI:2678506|[MP:0008139 fused...|\n",
      "|Ncdn<Gt(pT1Betage...|    involves: 129S2/S...|MGI:2678507|[MP:0013454 lacri...|\n",
      "|Xbp1<tm1Nogu>/Xbp...|    involves: 129S/Sv...|MGI:2678536|[MP:0006085 myoca...|\n",
      "|Scarb1<Hdlq1-NZB/...|    involves: NZB/BlN...|MGI:2678541|[MP:0001556 incre...|\n",
      "|Scarb1<Hdlq1-NZB/...|    involves: NZB/BlN...|MGI:2678542|[MP:0001556 incre...|\n",
      "|Tas1r3<tm1Rfm>/Ta...|       involves: C57BL/6|MGI:2678583|[MP:0004213 abnor...|\n",
      "|Mesp2<tm4Ysa>/Mes...|    involves: C57BL/6...|MGI:2678614|[MP:0004605 abnor...|\n",
      "|Ptprz1<tm1Mno>/Pt...|    involves: 129S1/S...|MGI:2678758|[MP:0002169 no ab...|\n",
      "|Ptprz1<tm1Mno>/Pt...|    B6.129-Ptprz1<tm1...|MGI:2678759|[MP:0001463 abnor...|\n",
      "|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678771|[MP:0002090 abnor...|\n",
      "|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678773|[MP:0002090 abnor...|\n",
      "|Opn1mw<tm1(OPN1LW...|           involves: 129|MGI:2678774|[MP:0002090 abnor...|\n",
      "|Traf6<tm1Ywc>/Tra...|           Not Specified|MGI:2678795|[MP:0008664 decre...|\n",
      "+--------------------+------------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mouse_model_table = (\n",
    "    mouse_model_table\n",
    "    .select('model_id','model_phenotypes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T19:47:55.122159Z",
     "start_time": "2021-02-08T19:47:55.009447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+----------------------+---------------------+--------------------+-----------+-----------------+--------------------+------------------------+-----------+\n",
      "| disease_id|disease_model_avg_raw|disease_model_max_norm|disease_model_max_raw|        disease_term|  marker_id|marker_num_models|   model_description|model_genetic_background|   model_id|\n",
      "+-----------+---------------------+----------------------+---------------------+--------------------+-----------+-----------------+--------------------+------------------------+-----------+\n",
      "|ORPHA:90970|                 0.76|                 76.35|                 2.38|Primary Lipodystr...|MGI:1330812|                3|Acox1<lampe1>/Aco...|      involves: C57BL/6J|MGI:5285941|\n",
      "|ORPHA:90970|                 0.36|                 70.89|                 2.21|Primary Lipodystr...|  MGI:88138|               10|Bcl2<tm2.1Lbox>/B...|    involves: 129S1/S...|MGI:5288501|\n",
      "|ORPHA:90970|                 0.36|                 70.89|                 2.21|Primary Lipodystr...|  MGI:88138|               10|Bcl2<tm2.1Lbox>/B...|    involves: 129S1/S...|MGI:5288502|\n",
      "|ORPHA:90970|                 0.37|                 82.42|                 2.56|Primary Lipodystr...|MGI:1921588|                5|Slc6a19<tm1Dgen>/...|    involves: 129 * C...|MGI:5289692|\n",
      "|ORPHA:90970|                 0.68|                 68.17|                 2.12|Primary Lipodystr...|MGI:3652039|                6|Rad21l<tm1Amp>/Ra...|    involves: 129S6/S...|MGI:5292347|\n",
      "|ORPHA:90970|                 0.41|                 80.71|                 2.51|Primary Lipodystr...| MGI:104672|                7|Tfap2b<tm1Rbu>/Tf...|    involves: 129S1/S...|MGI:5292663|\n",
      "|ORPHA:90970|                 0.82|                 79.23|                 2.46|Primary Lipodystr...|MGI:2385849|                2|Sirt7<tm1Fwa>/Sir...|      involves: 129S1/Sv|MGI:5293363|\n",
      "|ORPHA:90970|                  0.3|                 71.14|                 2.21|Primary Lipodystr...| MGI:106016|                5|Tra2b<Gt(P142D08)...|    involves: 129S2/S...|MGI:5293376|\n",
      "|ORPHA:90970|                 0.41|                 70.89|                 2.21|Primary Lipodystr...| MGI:107170|                6|Ptpn22<tm1.1Kas>/...|       involves: C57BL/6|MGI:5294245|\n",
      "|ORPHA:90970|                 0.76|                 82.42|                 2.56|Primary Lipodystr...| MGI:105115|                2|Ctf1<tm1Msd>/Ctf1...|      B6.Cg-Ctf1<tm1Msd>|MGI:5294956|\n",
      "|ORPHA:90970|                 0.82|                 82.42|                 2.56|Primary Lipodystr...|MGI:1344313|               21|    Zeb1<Tw>/Zeb1<+>|          B6.Cg-Zeb1<Tw>|MGI:5295198|\n",
      "|ORPHA:90970|                 0.75|                 82.42|                 2.56|Primary Lipodystr...|MGI:1344313|               21|Zeb1<tm1.1Ajg>/Ze...|    C57BL/6-Zeb1<tm1....|MGI:5295201|\n",
      "|ORPHA:90970|                 0.66|                  73.1|                 2.27|Primary Lipodystr...|MGI:1918817|                4|Mcm9<Gt(AW0655)Wt...|    involves: 129P2/O...|MGI:5295417|\n",
      "|ORPHA:90970|                 0.44|                 82.42|                 2.56|Primary Lipodystr...| MGI:104735|              215|Gt(ROSA)26Sor<tm3...|    involves: 129S6/S...|MGI:5295735|\n",
      "|ORPHA:90970|                 0.37|                 70.89|                 2.21|Primary Lipodystr...|MGI:2385891|                4|Zc3h12a<tm1Fum>/Z...|    C57BL/6-Zc3h12a<t...|MGI:5295987|\n",
      "|ORPHA:90970|                 0.59|                 70.89|                 2.21|Primary Lipodystr...|MGI:1926194|                9|Tnip1<tm1.1Pcoh>/...|    involves: 129P2/O...|MGI:5296231|\n",
      "|ORPHA:90970|                 0.43|                 70.89|                 2.21|Primary Lipodystr...| MGI:893598|                4|Sh2b3<tm1Paw>/Sh2...|    involves: 129S1/S...|MGI:5296515|\n",
      "|ORPHA:90970|                 0.79|                 79.23|                 2.46|Primary Lipodystr...|MGI:1339972|                3|Bhmt<tm1.2Zei>/Bh...|    involves: 129P2/O...|MGI:5297110|\n",
      "|ORPHA:90970|                 0.85|                 79.23|                 2.46|Primary Lipodystr...| MGI:106903|                4|Gucy2c<tm1Gar>/Gu...|    B6.129S6-Gucy2c<t...|MGI:5300906|\n",
      "|ORPHA:90970|                  0.8|                 82.42|                 2.56|Primary Lipodystr...| MGI:104993|               73|Lepr<tm5Mgmj>/Lep...|    B6.129-Lepr<tm5Mgmj>|MGI:5301171|\n",
      "+-----------+---------------------+----------------------+---------------------+--------------------+-----------+-----------------+--------------------+------------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disease_model_table = (\n",
    "    disease_model_table\n",
    "    .drop(*['association_curated', 'marker_locus', 'marker_symbol','model_source','type', 'disease_model_avg_norm'])\n",
    ")\n",
    "\n",
    "disease_model_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-08T20:49:44.575917Z",
     "start_time": "2021-02-08T20:44:28.042608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1626.showString.\n: java.util.concurrent.ExecutionException: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 507.0 failed 1 times, most recent failure: Lost task 0.0 in stage 507.0 (TID 7367, c02zq14flvdn, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:161)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:515)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeBroadcast$1(SparkPlan.scala:188)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:116)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:210)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:100)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:71)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:97)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:222)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce(WholeStageCodegenExec.scala:483)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce$(WholeStageCodegenExec.scala:456)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:137)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:97)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:51)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:95)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:51)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:632)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:692)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:434)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:420)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2695)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2695)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2902)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\n\tat sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 507.0 failed 1 times, most recent failure: Lost task 0.0 in stage 507.0 (TID 7367, c02zq14flvdn, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectIterator(SparkPlan.scala:392)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.$anonfun$relationFuture$1(BroadcastExchangeExec.scala:86)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$1(SQLExecution.scala:182)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-d991744f90b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_diseases_joined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_diseases_joined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1626.showString.\n: java.util.concurrent.ExecutionException: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 507.0 failed 1 times, most recent failure: Lost task 0.0 in stage 507.0 (TID 7367, c02zq14flvdn, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat java.util.concurrent.FutureTask.report(FutureTask.java:122)\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:206)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:161)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:515)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeBroadcast$1(SparkPlan.scala:188)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:116)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenInner(BroadcastHashJoinExec.scala:210)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:100)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:71)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:97)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:222)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.InputAdapter.consume(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce(WholeStageCodegenExec.scala:483)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.doProduce$(WholeStageCodegenExec.scala:456)\n\tat org.apache.spark.sql.execution.InputAdapter.doProduce(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.InputAdapter.produce(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:137)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:97)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:51)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:95)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:39)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:51)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:632)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:692)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:434)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:420)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2695)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2695)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2902)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:337)\n\tat sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 507.0 failed 1 times, most recent failure: Lost task 0.0 in stage 507.0 (TID 7367, c02zq14flvdn, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollectIterator(SparkPlan.scala:392)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.$anonfun$relationFuture$1(BroadcastExchangeExec.scala:86)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$1(SQLExecution.scala:182)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "models_diseases_joined = (\n",
    "    disease_model_table.limit(10000)\n",
    "    .join(mouse_model_table, on='model_id', how='inner')\n",
    ")\n",
    "\n",
    "print(models_diseases_joined.count())\n",
    "print(models_diseases_joined.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
