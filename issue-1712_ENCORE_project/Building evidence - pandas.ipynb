{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2362953",
   "metadata": {},
   "source": [
    "## Changes\n",
    "\n",
    "1. both the fdr and the p-value needs to meet the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18a82a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T20:52:27.510195Z",
     "start_time": "2021-10-12T20:52:27.500248Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_columns(columns):\n",
    "    \"\"\"Parsing column names to cell lines and replicates\n",
    "\n",
    "    Behaviour: 'SIDM00049_CPID1214.gene_summary.txt_neg|fdr' -> \n",
    "    {\n",
    "        column: 'SIDM00049_CPID1214.gene_summary.txt_neg|fdr', \n",
    "        cellLine: SIDM00146,\n",
    "        replicate: CPID1214,\n",
    "        stat: fdr\n",
    "    }\n",
    "\n",
    "    This then converted into a spark dataframe\n",
    "\n",
    "    args:\n",
    "    columns (list): a list with column names from the LogFC file\n",
    "\n",
    "    Returns:\n",
    "    spark.dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # These columns are not interesting:\n",
    "    drop = ['id', 'Note1', 'Note2', 'num']\n",
    "\n",
    "    # These are the values\n",
    "    keys = ['cellLine', 'replicate', 'stat', 'column']\n",
    "\n",
    "    # Filter relevant columns:\n",
    "    columns = [x for x in columns if x not in drop]\n",
    "    print(f'Number of columns: {len(columns)}')\n",
    "    print(f'An example: {columns[2]}')\n",
    "\n",
    "    # Parsig values:\n",
    "    try:\n",
    "        parsedColumns = [dict(zip(keys, x.replace(\n",
    "            '.gene_summary.txt_neg|', '_').split('_') + [x])) for x in columns]\n",
    "        parsedColumns_df = pd.DataFrame(parsedColumns)\n",
    "        parsedColumns_df = parsedColumns_df.loc[parsedColumns_df.stat.isin(\n",
    "            ['p-value', 'fdr', 'lfc', 'goodsgrna'])]\n",
    "\n",
    "    except error as e:\n",
    "        raise e(f\"Failed to parse the following columns: {', '.join(columns)}\")\n",
    "\n",
    "    return parsedColumns_df\n",
    "\n",
    "\n",
    "def parse_targets(gene_pair):\n",
    "    genes = gene_pair.split('~')\n",
    "\n",
    "    assert(len(genes) == 2)\n",
    "    parsed = []\n",
    "\n",
    "    for i, v in enumerate(genes):\n",
    "        parsed.append({\n",
    "            'targetFromSourceId': v,\n",
    "            'geneticBackground': genes[1] if i == 0 else genes[0]\n",
    "        })\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def parse_replicates(row):\n",
    "    returnValue = []\n",
    "    for cellLine in xf.cellLine.unique():\n",
    "        isSignificant = False\n",
    "        replicates = []\n",
    "        for replicate in xf.loc[xf.cellLine == cellLine].replicate.unique():\n",
    "\n",
    "            repl_columns = (\n",
    "                xf.loc[\n",
    "                    (xf.cellLine == cellLine)\n",
    "                    & (xf.replicate == replicate)]\n",
    "                .set_index('stat').column\n",
    "            )\n",
    "\n",
    "            pval = row[repl_columns['p-value']]\n",
    "            lfc = row[repl_columns['lfc']]\n",
    "            fdr = row[repl_columns['fdr']]\n",
    "            isSignificantRepl = False\n",
    "\n",
    "            if (pval < 0.05) & (fdr < 0.05):\n",
    "                isSignificant = True\n",
    "                isSignificantRepl = True\n",
    "\n",
    "            replicates.append({\n",
    "                'replicteId': replicate,\n",
    "                \"logFoldChange\": lfc,\n",
    "                \"pValue\": pval,\n",
    "                \"falseDiscoveryRate\": fdr,\n",
    "                \"isSignificant\": isSignificantRepl\n",
    "            })\n",
    "\n",
    "        if isSignificant:\n",
    "            returnValue.append({\n",
    "                'cellModelId': cellLine,\n",
    "                'replicates': replicates\n",
    "            })\n",
    "\n",
    "    if isSignificant:\n",
    "        return returnValue\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ad29c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fixed values\n",
    "input_file = '/Users/dsuveges/project_data/Shared_Data/OTAR2062/Aug21_ExactMatchData/BRCA-1_ExactMatch_LogFC_All.gene.stats.annotated.txt'\n",
    "filter_column = ['lfc', 'p-value']\n",
    "\n",
    "# Get list of files\n",
    "# These maps needs to be finalized later:\n",
    "CELL_MAP = {\n",
    "    'SIDM00146': {\n",
    "        'diseaseFromSourceMappedId': 'NCIT_C9140', \n",
    "        'tissue': 'bone marrow',\n",
    "        'biosamplesFromSource': [ # Might not be suitable here\n",
    "            'UBERON_0002371'  # bone marrow\n",
    "        ], \n",
    "    }, # https://cellmodelpassports.sanger.ac.uk/passports/SIDM01076\n",
    "}\n",
    "\n",
    "# Get a list of hits from the log2fold dataset\n",
    "\n",
    "\n",
    "# Get the relevant values from the GEMINI and BLISS datasets\n",
    "\n",
    "\n",
    "# Format and output the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "787ef6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c70f8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 464\n",
      "An example: SIDM00049_CPID1211.gene_summary.txt_neg|goodsgrna\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-2ff3cd133148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m df_filtered = (\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_replicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parsed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m         )\n\u001b[0;32m-> 7768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-192-6a8326c9996e>\u001b[0m in \u001b[0;36mparse_replicates\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             repl_columns = (\n\u001b[0;32m---> 68\u001b[0;31m                 xf.loc[\n\u001b[0m\u001b[1;32m     69\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mxf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcellLine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcellLine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                   & (xf.replicate == replicate)]\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reading datafile:\n",
    "df = pd.read_csv(input_file, sep=' ')\n",
    "\n",
    "# Extracting columns:\n",
    "columns = df.columns\n",
    "\n",
    "# Parse columns:\n",
    "xf = parse_columns(columns)\n",
    "\n",
    "# \n",
    "df_filtered = (\n",
    "    df.head()\n",
    "    .assign(parsed = df.apply(parse_replicates, axis=1))\n",
    "    .loc[lambda df: df['parsed'].notna()]\n",
    "    .explode('parsed')\n",
    "    .assign(targets = lambda df: df['id'].apply(parse_targets))\n",
    "    .explode('targets')\n",
    ")\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aa6391b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fdr', 'goodsgrna', 'lfc', 'p-value'}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x[1] for x in df.columns[4:].str.split('|')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "761b2a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cellModelId</th>\n",
       "      <th>replicates</th>\n",
       "      <th>targetFromSourceId</th>\n",
       "      <th>geneticBackground</th>\n",
       "      <th>datatypeId</th>\n",
       "      <th>datasourceId</th>\n",
       "      <th>projectId</th>\n",
       "      <th>diseaseFromSourceId</th>\n",
       "      <th>diseaseFromSourceMappedId</th>\n",
       "      <th>biosamplesFromSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SIDM00146</td>\n",
       "      <td>[{'replicteId': 'CPID1310', 'logFoldChange': -...</td>\n",
       "      <td>ABL2</td>\n",
       "      <td>CDK7</td>\n",
       "      <td>ot_partner</td>\n",
       "      <td>encore</td>\n",
       "      <td>OTAR2062</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SIDM00146</td>\n",
       "      <td>[{'replicteId': 'CPID1310', 'logFoldChange': -...</td>\n",
       "      <td>CDK7</td>\n",
       "      <td>ABL2</td>\n",
       "      <td>ot_partner</td>\n",
       "      <td>encore</td>\n",
       "      <td>OTAR2062</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SIDM00146</td>\n",
       "      <td>[{'replicteId': 'CPID1310', 'logFoldChange': -...</td>\n",
       "      <td>ABL2</td>\n",
       "      <td>CHEK1</td>\n",
       "      <td>ot_partner</td>\n",
       "      <td>encore</td>\n",
       "      <td>OTAR2062</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SIDM00146</td>\n",
       "      <td>[{'replicteId': 'CPID1310', 'logFoldChange': -...</td>\n",
       "      <td>CHEK1</td>\n",
       "      <td>ABL2</td>\n",
       "      <td>ot_partner</td>\n",
       "      <td>encore</td>\n",
       "      <td>OTAR2062</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>SIDM00146</td>\n",
       "      <td>[{'replicteId': 'CPID1310', 'logFoldChange': 0...</td>\n",
       "      <td>ADAD1</td>\n",
       "      <td>AKT1</td>\n",
       "      <td>ot_partner</td>\n",
       "      <td>encore</td>\n",
       "      <td>OTAR2062</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cellModelId                                         replicates  \\\n",
       "59    SIDM00146  [{'replicteId': 'CPID1310', 'logFoldChange': -...   \n",
       "59    SIDM00146  [{'replicteId': 'CPID1310', 'logFoldChange': -...   \n",
       "60    SIDM00146  [{'replicteId': 'CPID1310', 'logFoldChange': -...   \n",
       "60    SIDM00146  [{'replicteId': 'CPID1310', 'logFoldChange': -...   \n",
       "131   SIDM00146  [{'replicteId': 'CPID1310', 'logFoldChange': 0...   \n",
       "\n",
       "    targetFromSourceId geneticBackground  datatypeId datasourceId projectId  \\\n",
       "59                ABL2              CDK7  ot_partner       encore  OTAR2062   \n",
       "59                CDK7              ABL2  ot_partner       encore  OTAR2062   \n",
       "60                ABL2             CHEK1  ot_partner       encore  OTAR2062   \n",
       "60               CHEK1              ABL2  ot_partner       encore  OTAR2062   \n",
       "131              ADAD1              AKT1  ot_partner       encore  OTAR2062   \n",
       "\n",
       "    diseaseFromSourceId diseaseFromSourceMappedId biosamplesFromSource  \n",
       "59           NCIT_C9140                NCIT_C9140     [UBERON_0002371]  \n",
       "59           NCIT_C9140                NCIT_C9140     [UBERON_0002371]  \n",
       "60           NCIT_C9140                NCIT_C9140     [UBERON_0002371]  \n",
       "60           NCIT_C9140                NCIT_C9140     [UBERON_0002371]  \n",
       "131          NCIT_C9140                NCIT_C9140     [UBERON_0002371]  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_combined = (\n",
    "    pd.concat([\n",
    "        df_filtered.parsed.apply(pd.Series),\n",
    "        df_filtered.targets.apply(pd.Series)], axis=1)\n",
    "    .assign(    \n",
    "        datatypeId = \"ot_partner\",\n",
    "        datasourceId = \"encore\",\n",
    "        projectId = \"OTAR2062\",\n",
    "        diseaseFromSourceId = 'NCIT_C9140', # This needs to be reviewed.\n",
    "    )\n",
    ")\n",
    "\n",
    "parsed_combined = (\n",
    "    pd.concat([\n",
    "        parsed_combined,\n",
    "        parsed_combined.cellModelId.map(CELL_MAP).apply(pd.Series)], axis=1)\n",
    "    .drop(['tissue'], axis=1)\n",
    ")\n",
    "\n",
    "parsed_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b6b1c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseaseFromSourceMappedId</th>\n",
       "      <th>tissue</th>\n",
       "      <th>biosamplesFromSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NCIT_C9140</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>[UBERON_0002371]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    diseaseFromSourceMappedId       tissue biosamplesFromSource\n",
       "59                 NCIT_C9140  bone marrow     [UBERON_0002371]\n",
       "59                 NCIT_C9140  bone marrow     [UBERON_0002371]\n",
       "60                 NCIT_C9140  bone marrow     [UBERON_0002371]\n",
       "60                 NCIT_C9140  bone marrow     [UBERON_0002371]\n",
       "131                NCIT_C9140  bone marrow     [UBERON_0002371]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_combined.head().cellModelId.map(CELL_MAP).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7ec8a5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-6cc0680eee80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcellModelId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCELL_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "parsed_combined.head().concat(parsed_combined.head().cellModelId.map(CELL_MAP).apply(pd.Series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a1a80021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SIDM00049', 'CPID1214', 'fdr']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"SIDM00049_CPID1214.gene_summary.txt_neg|fdr\"\n",
    "x.replace('.gene_summary.txt_neg|', '_').split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ddecc132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 464\n",
      "An example: SIDM00049_CPID1211.gene_summary.txt_neg|goodsgrna\n"
     ]
    }
   ],
   "source": [
    "# These columns are not interesting:\n",
    "drop = ['id', 'Note1', 'Note2', 'num']\n",
    "\n",
    "# These are the values \n",
    "keys = ['cellLine', 'replicate', 'stat', 'column']\n",
    "\n",
    "# Filter relevant columns:\n",
    "columns = [x for x in columns if x not in drop]\n",
    "print(f'Number of columns: {len(columns)}')\n",
    "print(f'An example: {columns[2]}')\n",
    "\n",
    "# Parsig values:\n",
    "try:\n",
    "    parsedColumns = [dict(zip(keys, x.replace('.gene_summary.txt_neg|', '_').split('_') + [x])) for x in columns]\n",
    "    parsedColumns_df = pd.DataFrame(parsedColumns)\n",
    "    parsedColumns_df = parsedColumns_df.loc[parsedColumns_df.stat.isin(['p-value', 'fdr', 'lfc', 'goodsgrna'])]\n",
    "except error as e:\n",
    "    raise e(f\"Failed to parse the following columns: {', '.join(columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b2bd51c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cellLine': 'SIDM00049',\n",
       " 'replicate': 'CPID1211',\n",
       " 'stat': 'p-value',\n",
       " 'column': 'SIDM00049_CPID1211.gene_summary.txt_neg|p-value'}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = columns[0]\n",
    "dict(zip(keys, x.replace('.gene_summary.txt_neg|', '_').split('_') + [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5fa63ac8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lfc          86\n",
       "goodsgrna    86\n",
       "fdr          86\n",
       "p-value      86\n",
       "Name: stat, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedColumns_df.stat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3463b85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xf.replicate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c727ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CPID1011', 'CPID1014', 'CPID1017'], dtype=object)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf.loc[xf.cellLine == 'SIDM01090'].replicate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97ef3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cellLine</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIDM00049</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00118</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00136</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00193</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00194</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00214</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00359</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00537</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00677</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00680</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00681</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00776</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00782</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00783</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00789</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00832</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00833</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00834</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00835</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00837</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00839</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00841</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00944</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00957</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM00960</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIDM01090</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           replicate\n",
       "cellLine            \n",
       "SIDM00049          3\n",
       "SIDM00118          3\n",
       "SIDM00136          9\n",
       "SIDM00193          3\n",
       "SIDM00194          3\n",
       "SIDM00214          3\n",
       "SIDM00359          3\n",
       "SIDM00537          3\n",
       "SIDM00677          3\n",
       "SIDM00680          3\n",
       "SIDM00681          4\n",
       "SIDM00776          6\n",
       "SIDM00782          5\n",
       "SIDM00783          3\n",
       "SIDM00789          3\n",
       "SIDM00832          3\n",
       "SIDM00833          2\n",
       "SIDM00834          3\n",
       "SIDM00835          3\n",
       "SIDM00837          3\n",
       "SIDM00839          1\n",
       "SIDM00841          3\n",
       "SIDM00944          3\n",
       "SIDM00957          2\n",
       "SIDM00960          3\n",
       "SIDM01090          3"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    xf[['cellLine', 'replicate']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('cellLine')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5db8c40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LibraryCombinations          16160\n",
       "AnchorCombinations            1600\n",
       "LibrarySingletons             1212\n",
       "ESSENTIAL-NONTARGET            400\n",
       "NONTARGET-NONTARGET            199\n",
       "GIControlsSingletons           198\n",
       "INTERGENIC-INTERGENIC          155\n",
       "NONESSENTIAL-NONESSENTIAL      136\n",
       "AnchorSingletons               120\n",
       "ESSENTIAL-INTERGENIC            92\n",
       "GIControlsCombinations          62\n",
       "Name: Note2, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Note2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6705987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Amount: long (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "|Banana |1000  |USA    |\n",
      "|Carrots|1500  |USA    |\n",
      "|Beans  |1600  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Orange |2000  |USA    |\n",
      "|Banana |400   |China  |\n",
      "|Carrots|1200  |China  |\n",
      "|Beans  |1500  |China  |\n",
      "|Orange |4000  |China  |\n",
      "|Banana |2000  |Canada |\n",
      "|Carrots|2000  |Canada |\n",
      "|Beans  |2000  |Mexico |\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "#Create spark session\n",
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fe982045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Canada: long (nullable = true)\n",
      " |-- China: long (nullable = true)\n",
      " |-- Mexico: long (nullable = true)\n",
      " |-- USA: long (nullable = true)\n",
      "\n",
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico|USA |\n",
      "+-------+------+-----+------+----+\n",
      "|Orange |null  |4000 |null  |4000|\n",
      "|Beans  |null  |1500 |2000  |1600|\n",
      "|Banana |2000  |400  |null  |1000|\n",
      "|Carrots|2000  |1200 |null  |1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1c58fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Product|Country|Total|\n",
      "+-------+-------+-----+\n",
      "|Orange |China  |4000 |\n",
      "|Beans  |China  |1500 |\n",
      "|Beans  |Mexico |2000 |\n",
      "|Banana |Canada |2000 |\n",
      "|Banana |China  |400  |\n",
      "|Carrots|Canada |2000 |\n",
      "|Carrots|China  |1200 |\n",
      "+-------+-------+-----+\n",
      "\n",
      "+-------+-------+-----+\n",
      "|Product|Country|Total|\n",
      "+-------+-------+-----+\n",
      "| Orange|  China| 4000|\n",
      "|  Beans|  China| 1500|\n",
      "|  Beans| Mexico| 2000|\n",
      "| Banana| Canada| 2000|\n",
      "| Banana|  China|  400|\n",
      "|Carrots| Canada| 2000|\n",
      "|Carrots|  China| 1200|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
    "unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
    "    .where(\"Total is not null\")\n",
    "unPivotDF.show(truncate=False)\n",
    "unPivotDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3df72a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:50:24.991794Z",
     "start_time": "2021-10-12T16:50:24.979467Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-75e5d13e3db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrop_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Record'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Select all columns which needs to be pivoted down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpivot_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_cols\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdrop_cols\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpivot_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "index_cols= [\"Hospital\",\"Hospital Address\"]\n",
    "drop_cols = ['Record']\n",
    "# Select all columns which needs to be pivoted down\n",
    "pivot_cols = [c  for c in df.columns if c not in index_cols+drop_cols ]\n",
    "pivot_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61de7455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T12:48:52.587095Z",
     "start_time": "2021-10-13T12:48:52.439459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----------+-------------+\n",
      "|        Hospital|    Hospital Address|MedicinName|Effectiveness|\n",
      "+----------------+--------------------+-----------+-------------+\n",
      "|       Red Cross|     1234 Street 429| Medicine_1|    Effective|\n",
      "|       Red Cross|     1234 Street 429| Medicine_2|    Effective|\n",
      "|       Red Cross|     1234 Street 429| Medicine_3|       Normal|\n",
      "|       Red Cross|     1234 Street 429| Medicine_4|    Effective|\n",
      "|Alberta Hospital|553 Alberta Road 441| Medicine_1|     Effecive|\n",
      "|Alberta Hospital|553 Alberta Road 441| Medicine_2|       Normal|\n",
      "|Alberta Hospital|553 Alberta Road 441| Medicine_3|       Normal|\n",
      "|Alberta Hospital|553 Alberta Road 441| Medicine_4|    Effective|\n",
      "|General Hospital|994 Random Street...| Medicine_1|       Normal|\n",
      "|General Hospital|994 Random Street...| Medicine_2|    Effective|\n",
      "|General Hospital|994 Random Street...| Medicine_3|       Normal|\n",
      "|General Hospital|994 Random Street...| Medicine_4|    Effective|\n",
      "+----------------+--------------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create sample data \n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import  *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# establish spark connection\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "panda_df = pd.DataFrame({'Record': {0: 1, 1: 2, 2: 3},\n",
    " 'Hospital': {0: 'Red Cross', 1: 'Alberta Hospital', 2: 'General Hospital'},\n",
    " 'Hospital Address': {0: '1234 Street 429',\n",
    "  1: '553 Alberta Road 441',\n",
    "  2: '994 Random Street 923'},\n",
    " 'Medicine_1': {0: 'Effective', 1: 'Effecive', 2: 'Normal'},\n",
    " 'Medicine_2': {0: 'Effective', 1: 'Normal', 2: 'Effective'},\n",
    " 'Medicine_3': {0: 'Normal', 1: 'Normal', 2: 'Normal'},\n",
    " 'Medicine_4': {0: 'Effective', 1: 'Effective', 2: 'Effective'}})\n",
    "df = spark.createDataFrame(panda_df)\n",
    "\n",
    "# calculate\n",
    "df.select(\"Hospital\",\"Hospital Address\", \n",
    "          expr(\"stack(4, 'Medicine_1', Medicine_1, 'Medicine_2', Medicine_2, \\\n",
    "          'Medicine_3', Medicine_3,'Medicine_4',Medicine_4) as (MedicinName, Effectiveness)\")\n",
    "         ).where(\"Effectiveness is not null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2640b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T08:31:39.516132Z",
     "start_time": "2021-10-13T08:31:39.267043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+--------------------+----------+----------+----------+----------+\n",
      "|Record|        Hospital|    Hospital Address|Medicine_1|Medicine_2|Medicine_3|Medicine_4|\n",
      "+------+----------------+--------------------+----------+----------+----------+----------+\n",
      "|     1|       Red Cross|     1234 Street 429| Effective| Effective|    Normal| Effective|\n",
      "|     2|Alberta Hospital|553 Alberta Road 441|  Effecive|    Normal|    Normal| Effective|\n",
      "|     3|General Hospital|994 Random Street...|    Normal| Effective|    Normal| Effective|\n",
      "+------+----------------+--------------------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Template pyspark data\n",
    "## \n",
    "\n",
    "panda_df = pd.DataFrame(\n",
    "    {'Record': {0: 1, 1: 2, 2: 3},\n",
    " 'Hospital': {0: 'Red Cross', 1: 'Alberta Hospital', 2: 'General Hospital'},\n",
    " 'Hospital Address': {0: '1234 Street 429',\n",
    "  1: '553 Alberta Road 441',\n",
    "  2: '994 Random Street 923'},\n",
    " 'Medicine_1': {0: 'Effective', 1: 'Effecive', 2: 'Normal'},\n",
    " 'Medicine_2': {0: 'Effective', 1: 'Normal', 2: 'Effective'},\n",
    " 'Medicine_3': {0: 'Normal', 1: 'Normal', 2: 'Normal'},\n",
    " 'Medicine_4': {0: 'Effective', 1: 'Effective', 2: 'Effective'}})\n",
    "df = spark.createDataFrame(panda_df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54890ac9",
   "metadata": {},
   "source": [
    "## Sample dataset\n",
    "\n",
    "Generating a simple dataset to prototype stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e4ef768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T12:49:04.366366Z",
     "start_time": "2021-10-13T12:49:04.246703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+----------+-----------+----------+\n",
      "|animal|voice|farm1_count|farm1_legs|farm2_count|farm2_legs|\n",
      "+------+-----+-----------+----------+-----------+----------+\n",
      "|   cat| miau|          1|         4|          1|         4|\n",
      "|   dog|  vau|          1|         4|          1|         4|\n",
      "| chick| csip|         12|        24|         22|        44|\n",
      "+------+-----+-----------+----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate pandas dataframe\n",
    "pdf = pd.DataFrame({\n",
    "    'animal': ['cat', 'dog', 'chick'],\n",
    "    'voice': ['miau', 'vau', 'csip'],\n",
    "    \n",
    "    # Data from farm 1\n",
    "    'farm1_count': [1, 1, 12],\n",
    "    'farm1_legs': [4, 4, 24],\n",
    "    \n",
    "    # Data from farm 2\n",
    "    'farm2_count': [1, 1, 22],\n",
    "    'farm2_legs': [4, 4, 44],\n",
    "    \n",
    "    # Data from farm 3\n",
    "#     'farm3_count': [2, 5, 2],\n",
    "#     'farm3_legs': [8, 20, 4],\n",
    "})\n",
    "\n",
    "# Convert to spark:\n",
    "df = spark.createDataFrame(pdf)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b4d47d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T12:50:41.976394Z",
     "start_time": "2021-10-13T12:50:41.732879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+--------+-----+----+\n",
      "|animal|voice| farm|    data|count|legs|\n",
      "+------+-----+-----+--------+-----+----+\n",
      "|   cat| miau|farm1|  {1, 4}|    1|   4|\n",
      "|   cat| miau|farm2|  {1, 4}|    1|   4|\n",
      "|   dog|  vau|farm1|  {1, 4}|    1|   4|\n",
      "|   dog|  vau|farm2|  {1, 4}|    1|   4|\n",
      "| chick| csip|farm1|{12, 24}|   12|  24|\n",
      "| chick| csip|farm2|{22, 44}|   22|  44|\n",
      "+------+-----+-----+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Generate the \"unpivot\" expression:\n",
    "# unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
    "# unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
    "#     .where(\"Total is not null\")\n",
    "# unPivotDF.show(truncate=False)\n",
    "\n",
    "unpivot_expression = '''stack(2, 'farm1', farm1, 'farm2', farm2) as (farm, data)'''\n",
    "xs = map -> [[farm1_count|farm1_legs], [farm2_count|farm2_legs]] -> [('farm1', col), ()]\n",
    "\n",
    "resDF = reduce(lambda DF,value: DF.withColumn(*value) , xs, df)\n",
    "\n",
    "colum_operatins = [('farm1' ,struct(('farm1_count').alias('count'),col('farm1_legs').alias('legs')))]\n",
    "(\n",
    "    df.\n",
    "    .withColumn('farm1', struct(col('farm1_count').alias('count'),col('farm1_legs').alias('legs')))\n",
    "    .withColumn('farm2', struct(col('farm2_count').alias('count'),col('farm2_legs').alias('legs')))\n",
    "    .select('animal', 'voice', expr(unpivot_expression))\n",
    "    .select('*', 'data.*')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8908c0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T09:47:06.687297Z",
     "start_time": "2021-10-13T09:47:06.683507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `stack` not found.\n"
     ]
    }
   ],
   "source": [
    "?stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3488aa0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T15:07:17.963925Z",
     "start_time": "2021-10-13T15:07:17.936583Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-62f6239f03f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce' is not defined"
     ]
    }
   ],
   "source": [
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7b60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
