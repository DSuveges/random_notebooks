{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884661cd",
   "metadata": {},
   "source": [
    "# Reviewed process\n",
    "\n",
    "Based on the meeting we had on the 7th with the IMPC team, we agreed on some of the things:\n",
    "\n",
    "1. Let's keep minimal score cutoff for removing low-confidence associations.\n",
    "2. It makes sense to remove IMPC from dataset\n",
    "3. Scoring is important so we should properly calculate the overall association score.\n",
    "\n",
    "To properly calculate the overall association score, I need to follow this procedure:\n",
    "\n",
    "1. Using the downloadable association data with datasource scores\n",
    "2. Apply weight on each datasource\n",
    "3. Aggregate by disease/target pairs.\n",
    "4. Apply harmonic sum on the weighted datasource scores. scale by the maximal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7257d325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:44:58.038079Z",
     "start_time": "2022-08-23T08:44:58.026393Z"
    }
   },
   "outputs": [],
   "source": [
    "from statistics import median\n",
    "from functools import reduce \n",
    "\n",
    "from pyspark.sql import dataframe\n",
    "import pyspark.sql\n",
    "import pyspark.sql.types as t\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = (\n",
    "    pyspark.sql.SparkSession\n",
    "   .builder\n",
    "   .master(\"local[*]\")\n",
    "   .getOrCreate()\n",
    ")\n",
    "   \n",
    "@f.udf(t.FloatType())\n",
    "def harmonic_sum(data: list, scale_factor: float = 1, cap: float = None) -> float:\n",
    "    \"\"\"\n",
    "    Returns an harmonic sum for the data passed\n",
    "    Args:\n",
    "        data (list): list of floats to compute the harmonic sum from\n",
    "        scale_factor (float): a scaling factor to multiply to each datapoint. Defaults to 1\n",
    "        cap (float): if not None, never return an harmonic sum higher than the cap value.\n",
    "    Returns:\n",
    "        harmonic_sum (float): the harmonic sum of the data passed\n",
    "    \"\"\"\n",
    "\n",
    "    data.sort(reverse=True)\n",
    "    harmonic_sum = sum(s / ((i+1) ** scale_factor) for i, s in enumerate(data))\n",
    "    \n",
    "    # Applying cap:\n",
    "    if cap is not None and harmonic_sum > cap:\n",
    "        return cap\n",
    "      \n",
    "    return harmonic_sum\n",
    "\n",
    "# An UDF to calculate median:\n",
    "median_udf = f.udf(lambda l: median(l), t.FloatType())\n",
    "\n",
    "association_dataset = '/Users/dsuveges/project_data/associationByDatasourceDirect'\n",
    "disease_dataset = '/Users/dsuveges/project/random_notebooks/2022.06.08-disease_expansion/diseases_efo.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4834598",
   "metadata": {},
   "source": [
    "### Processing disease as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38792c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T21:06:38.509815Z",
     "start_time": "2022-08-22T21:06:36.418373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all diseases: 23074\n",
      "Number of relevant diseases: 1411\n",
      "+-------------+--------------------+------------+\n",
      "|    diseaseId|        diseaseLabel|  isRelevant|\n",
      "+-------------+--------------------+------------+\n",
      "|   GO_0046483|heterocycle metab...|not_relevant|\n",
      "|   HP_0000112|         Nephropathy|not_relevant|\n",
      "|   HP_0000405|Conductive hearin...|not_relevant|\n",
      "|   HP_0000712|  Emotional lability|not_relevant|\n",
      "|   HP_0001392|Abnormality of th...|not_relevant|\n",
      "|   HP_0002376|Developmental reg...|not_relevant|\n",
      "|   HP_0009487|Ulnar deviation o...|not_relevant|\n",
      "|   HP_0012868|Abnormal sperm ta...|not_relevant|\n",
      "|MONDO_0002185|        hyperostosis|not_relevant|\n",
      "|MONDO_0003453|conjunctival intr...|not_relevant|\n",
      "|MONDO_0004900|  peripheral vertigo|not_relevant|\n",
      "|MONDO_0007244|      Caffey disease|not_relevant|\n",
      "|MONDO_0007321|autosomal dominan...|not_relevant|\n",
      "|MONDO_0007949|   Marshall syndrome|not_relevant|\n",
      "|MONDO_0008016|trismus-pseudocam...|not_relevant|\n",
      "|MONDO_0008682|Denys-Drash syndrome|not_relevant|\n",
      "|MONDO_0009045|cataract-nephropa...|not_relevant|\n",
      "|MONDO_0009485|oculocerebrofacia...|not_relevant|\n",
      "|MONDO_0009544|macrocephaly/mega...|not_relevant|\n",
      "|MONDO_0010024|Beemer-Langer syn...|not_relevant|\n",
      "+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_disease_pattern = ['immuno', 'hemato', 'hemo', 'blood', 'bleed']\n",
    "\n",
    "\n",
    "disease_raw = (\n",
    "    spark.read.json(disease_dataset)\n",
    "    .withColumnRenamed('id', 'diseaseId')\n",
    "    .withColumnRenamed('name', 'diseaseLabel')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "annotated_diseases = (\n",
    "    disease_raw\n",
    "    # Exploding parent column:\n",
    "    .select('diseaseId', 'diseaseLabel', f.explode_outer('parentIds').alias('parentId'))\n",
    "    \n",
    "    # Get parent disease names:\n",
    "    .join(\n",
    "        (\n",
    "            disease_raw\n",
    "            .withColumnRenamed('diseaseId', 'parentId')\n",
    "            .withColumnRenamed('diseaseLabel', 'parentLabel')\n",
    "            .drop('parentIds')\n",
    "        ), on='parentId', how='left')\n",
    "    \n",
    "    # Check if disease name OR parent name is relevant:\n",
    "    .withColumn(\n",
    "        'isRelevant',\n",
    "        f.when(f.col('diseaseLabel').rlike('|'.join(relevant_disease_pattern)), True)\n",
    "        .when(f.col('parentLabel').rlike('|'.join(relevant_disease_pattern)), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "    \n",
    "    # Aggregating by disease, check if at least one parent is relevant:\n",
    "    .groupBy('diseaseId', 'diseaseLabel')\n",
    "    .agg(\n",
    "        f.expr(\"any(isRelevant)\").alias('isRelevant')\n",
    "    )\n",
    "    .withColumn(\n",
    "        'isRelevant',\n",
    "        f.when(f.col('isRelevant') == True, 'relevant')\n",
    "        .otherwise('not_relevant')\n",
    "    )\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "relevant_count = annotated_diseases.filter(f.col('isRelevant') == 'relevant').count()\n",
    "\n",
    "print(f'Number of all diseases: {annotated_diseases.count()}')\n",
    "print(f'Number of relevant diseases: {relevant_count}')\n",
    "\n",
    "annotated_diseases.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeffee5",
   "metadata": {},
   "source": [
    "### Processing targets as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70c9b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T20:20:54.366806Z",
     "start_time": "2022-07-07T20:20:53.757574Z"
    }
   },
   "outputs": [],
   "source": [
    "targets = (\n",
    "    spark.read.parquet('/Users/dsuveges/project_data/targets')\n",
    "    .select(\n",
    "        f.col('id').alias('targetId'),\n",
    "        f.col('approvedSymbol').alias('targetSymbol'),\n",
    "        f.col('approvedName').alias('targetName')\n",
    "    )\n",
    "    .persist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba360f",
   "metadata": {},
   "source": [
    "### Read and explore associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364af675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T20:21:22.954516Z",
     "start_time": "2022-07-07T20:21:22.236008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+-----------+---------------+-------------------+-------------+\n",
      "|         datatypeId|datasourceId|  diseaseId|       targetId|              score|evidenceCount|\n",
      "+-------------------+------------+-----------+---------------+-------------------+-------------+\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000008710| 0.5543493036511893|           10|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000084674| 0.9160297417262854|           12|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000110245| 0.5422007545467868|            4|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000119772|0.20834690189720867|            1|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000124827| 0.1877214660192899|            1|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000130164| 0.9799287909752019|           35|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000132855| 0.5118943392430458|            4|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000138075|0.40148461266246893|            2|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000163631|  0.252464717388771|            1|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000168769| 0.2361316504515463|            4|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000169174| 0.9126744126943533|           13|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000171456| 0.3381036304864004|            4|\n",
      "|genetic_association| gene_burden|EFO_0000589|ENSG00000278318|0.15528019519544883|            1|\n",
      "|genetic_association| gene_burden|EFO_0000612|ENSG00000130164| 0.6107058135484142|           12|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000012048| 0.9751326960796589|           28|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000076242| 0.9467232121290935|           12|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000083093| 0.9244542972068264|           22|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000095002|  0.888307588647697|           15|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000096968| 0.7599134970145264|            2|\n",
      "|genetic_association| gene_burden|EFO_0000616|ENSG00000101347|0.43025937497004446|            9|\n",
      "+-------------------+------------+-----------+---------------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.read.parquet(association_dataset)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8968bda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T21:01:44.315558Z",
     "start_time": "2022-07-07T21:01:42.586246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------------------+------------------+--------------------+-------------+--------------------+\n",
      "|       targetId|     diseaseId|         datatypeId|      datasourceId|               score|evidenceCount|        overallScore|\n",
      "+---------------+--------------+-------------------+------------------+--------------------+-------------+--------------------+\n",
      "|ENSG00000065361| MONDO_0003036|         literature|         europepmc| 0.01823792392834863|            1|0.002217479128108...|\n",
      "|ENSG00000065361|Orphanet_44890|         literature|         europepmc|0.015198269940290528|            2| 0.07437794575529624|\n",
      "|ENSG00000065361|Orphanet_44890|         known_drug|            chembl| 0.12158615952232422|            1| 0.07437794575529624|\n",
      "|ENSG00000065361|   EFO_1000391|genetic_association|ot_genetics_portal| 0.10756044474610776|            2| 0.06538930696596199|\n",
      "|ENSG00000065361| MONDO_0017574|genetic_association|uniprot_literature|   0.607930797611621|            1|  0.3695798546847018|\n",
      "|ENSG00000065361| MONDO_0009491|         literature|         europepmc|0.030396539880581056|            1|0.003695798546847...|\n",
      "|ENSG00000065361| MONDO_0016748|   somatic_mutation|cancer_gene_census|   0.607930797611621|            1|  0.3695798546847018|\n",
      "|ENSG00000065361| MONDO_0021118|         literature|         europepmc| 0.06079307976116211|            1|0.007391597093694037|\n",
      "|ENSG00000065361|Orphanet_79364|         literature|         europepmc|0.024317231904464845|            1|0.002956638837477...|\n",
      "|ENSG00000065361|   EFO_0004587|genetic_association|ot_genetics_portal| 0.30630293777671963|            3|  0.1862109892733839|\n",
      "|ENSG00000065361| MONDO_0002872|         literature|         europepmc|0.030396539880581056|            1|0.003695798546847...|\n",
      "|ENSG00000065361| MONDO_0008315|         known_drug|            chembl|  0.1654922726831635|            3| 0.10060784933083547|\n",
      "|ENSG00000065361| MONDO_0002616|         literature|         europepmc| 0.01823792392834863|            1|0.002217479128108...|\n",
      "|ENSG00000065361|   EFO_0000401|         literature|         europepmc| 0.17022062333125393|            1|0.020696471862343302|\n",
      "|ENSG00000065361|   EFO_1000233|   somatic_mutation|cancer_gene_census|   0.607930797611621|            1|  0.3695798546847018|\n",
      "|ENSG00000065361|   EFO_0000232|         literature|         europepmc| 0.19635452598739553|           23|0.023873992719633832|\n",
      "|ENSG00000065361|   EFO_0004208|genetic_association|ot_genetics_portal| 0.18717939475801698|            4| 0.11379211875170175|\n",
      "|ENSG00000065361|   EFO_0008524|   somatic_mutation|cancer_gene_census|  0.3039653988058105|            1|  0.1847899273423509|\n",
      "|ENSG00000065361|   EFO_0005741|         literature|         europepmc|0.030396539880581056|            1|0.003695798546847...|\n",
      "|ENSG00000065361|   EFO_0004784|genetic_association|ot_genetics_portal| 0.44196357326893204|           14|   0.268683267612664|\n",
      "+---------------+--------------+-------------------+------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = 'ENSG00000065361' # HER3\n",
    "disease = 'EFO_0000571' # Lung adenocarcinoma\n",
    "# The association score is 0.37\n",
    "\n",
    "overall_score = (\n",
    "    spark.read.parquet('/Users/dsuveges/project_data/associationByOverallDirect/')\n",
    "    .drop('evidenceCount')\n",
    "    .withColumnRenamed('score', 'overallScore')\n",
    ")\n",
    "\n",
    "example_assoc = (\n",
    "    spark.read.parquet(association_dataset)\n",
    "    .filter(\n",
    "        (f.col('targetId') == target) \n",
    "#         & (f.col('diseaseId') == disease)\n",
    "    )\n",
    "    .join(overall_score, on=['targetId', 'diseaseId'], how='inner')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "example_assoc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf8605c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T21:11:11.184333Z",
     "start_time": "2022-07-07T21:11:10.861417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------+--------------+--------------------+-----------------------+\n",
      "|     diseaseId|       targetId|evidence_count|harmonic_score|       originalScore|calculated_overallScore|\n",
      "+--------------+---------------+--------------+--------------+--------------------+-----------------------+\n",
      "| MONDO_0003036|ENSG00000065361|             1|  0.0036475847|0.002217479128108...|   0.001780099504592...|\n",
      "|Orphanet_44890|ENSG00000065361|             3|    0.12310599| 0.07437794575529624|    0.06007836035369098|\n",
      "|   EFO_1000391|ENSG00000065361|             2|    0.10756045| 0.06538930696596199|    0.05249180389663397|\n",
      "| MONDO_0017574|ENSG00000065361|             1|     0.6079308|  0.3695798546847018|     0.2966832487959592|\n",
      "| MONDO_0009491|ENSG00000065361|             1|  0.0060793078|0.003695798546847...|   0.002966832469779377|\n",
      "| MONDO_0016748|ENSG00000065361|             1|     0.6079308|  0.3695798546847018|     0.2966832487959592|\n",
      "| MONDO_0021118|ENSG00000065361|             1|  0.0121586155|0.007391597093694037|   0.005933664939558754|\n",
      "|Orphanet_79364|ENSG00000065361|             1|  0.0048634466|0.002956638837477...|   0.002373466157625...|\n",
      "|   EFO_0004587|ENSG00000065361|             3|    0.30630293|  0.1862109892733839|    0.14948239652971923|\n",
      "| MONDO_0002872|ENSG00000065361|             1|  0.0060793078|0.003695798546847...|   0.002966832469779377|\n",
      "| MONDO_0008315|ENSG00000065361|             3|    0.16549227| 0.10060784933083547|    0.08076377263693679|\n",
      "| MONDO_0002616|ENSG00000065361|             1|  0.0036475847|0.002217479128108...|   0.001780099504592...|\n",
      "|   EFO_0000401|ENSG00000065361|             1|   0.034044124|0.020696471862343302|    0.01661426219436881|\n",
      "|   EFO_1000233|ENSG00000065361|             1|     0.6079308|  0.3695798546847018|     0.2966832487959592|\n",
      "|   EFO_0000232|ENSG00000065361|            23|   0.039270904|0.023873992719633832|   0.019165042716064656|\n",
      "|   EFO_0004208|ENSG00000065361|             4|     0.1871794| 0.11379211875170175|    0.09134755933778306|\n",
      "|   EFO_0008524|ENSG00000065361|             1|     0.3039654|  0.1847899273423509|     0.1483416243979796|\n",
      "|   EFO_0005741|ENSG00000065361|             1|  0.0060793078|0.003695798546847...|   0.002966832469779377|\n",
      "|   EFO_0004784|ENSG00000065361|            14|    0.44196358|   0.268683267612664|    0.21568770023384354|\n",
      "|   EFO_1001972|ENSG00000065361|             1|    0.45594808| 0.27718489101352634|    0.22251243659696937|\n",
      "+--------------+---------------+--------------+--------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "weights = {\n",
    "    \"cancer_gene_census\": 1,\n",
    "    \"cancer_biomarkers\": 0.5,\n",
    "    \"chembl\": 1,\n",
    "    \"crispr\": 1,\n",
    "    \"europepmc\": 0.2,\n",
    "    \"eva\": 1,\n",
    "    \"eva_somatic\": 1,\n",
    "    \"expression_atlas\": 0.2,\n",
    "    \"gene2phenotype\": 1,\n",
    "    \"genomics_england\": 1,\n",
    "    \"ot_genetics_portal\": 1,\n",
    "    \"intogen\": 1,\n",
    "    \"impc\": 0.2,\n",
    "    \"phewas_catalog\": 1,\n",
    "    \"progeny\": 0.5,\n",
    "    \"reactome\": 1,\n",
    "    \"slapenrich\": 0.5,\n",
    "    \"sysbio\": 0.5,\n",
    "    \"uniprot\": 1,\n",
    "    \"uniprot_literature\": 1,\n",
    "    \"uniprot_somatic\": 1,\n",
    "}\n",
    "\n",
    "@f.udf(t.FloatType())\n",
    "def harmonic_sum(data: list, scale_factor: float = 1, cap: float = None) -> float:\n",
    "    \"\"\"\n",
    "    Returns an harmonic sum for the data passed\n",
    "    Args:\n",
    "        data (list): list of floats to compute the harmonic sum from\n",
    "        scale_factor (float): a scaling factor to multiply to each datapoint. Defaults to 1\n",
    "        cap (float): if not None, never return an harmonic sum higher than the cap value.\n",
    "    Returns:\n",
    "        harmonic_sum (float): the harmonic sum of the data passed\n",
    "    \"\"\"\n",
    "\n",
    "    data.sort(reverse=True)\n",
    "    harmonic_sum = sum(s / ((i+1) ** scale_factor) for i, s in enumerate(data))\n",
    "    \n",
    "    # Applying cap:\n",
    "    if cap is not None and harmonic_sum > cap:\n",
    "        return cap\n",
    "      \n",
    "    return harmonic_sum\n",
    "\n",
    "\n",
    "\n",
    "# The theoretical maximum of the scores:\n",
    "max_score = 2.0490903410431183 # 3.377194851502127\n",
    "\n",
    "mapping_expr = f.create_map([f.lit(x) for x in chain(*weights.items())])\n",
    "(\n",
    "    example_assoc\n",
    "    .withColumn('weighted_score', f.col('score') * mapping_expr[f.col(\"datasourceId\")])\n",
    "    .groupBy('diseaseId', 'targetId')\n",
    "    .agg(\n",
    "        f.sum(f.col('evidenceCount')).alias('evidence_count'),\n",
    "        harmonic_sum(f.collect_list(f.col('weighted_score'))).alias('harmonic_score'),\n",
    "        f.first('overallScore').alias('originalScore')\n",
    "    )\n",
    "    .withColumn('calculated_overallScore', f.col('harmonic_score')/max_score)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7065c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T20:50:51.201527Z",
     "start_time": "2022-07-07T20:50:51.190963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.377194851502127"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @f.udf(t.FloatType())\n",
    "def harmonic_sum(data: list, scale_factor: float = 1, cap: float = None) -> float:\n",
    "    \"\"\"\n",
    "    Returns an harmonic sum for the data passed\n",
    "    Args:\n",
    "        data (list): list of floats to compute the harmonic sum from\n",
    "        scale_factor (float): a scaling factor to multiply to each datapoint. Defaults to 1\n",
    "        cap (float): if not None, never return an harmonic sum higher than the cap value.\n",
    "    Returns:\n",
    "        harmonic_sum (float): the harmonic sum of the data passed\n",
    "    \"\"\"\n",
    "\n",
    "    data.sort(reverse=True)\n",
    "    harmonic_sum = sum(s / ((i+1) ** scale_factor) for i, s in enumerate(data))\n",
    "    \n",
    "    # Applying cap:\n",
    "    if cap is not None and harmonic_sum > cap:\n",
    "        return cap\n",
    "      \n",
    "    return harmonic_sum\n",
    "\n",
    "harmonic_sum(list(weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a001617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T21:10:41.833542Z",
     "start_time": "2022-07-07T21:10:41.273056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-------------------+------------------+-------------------+-------------+------------------+\n",
      "|       targetId|  diseaseId|         datatypeId|      datasourceId|              score|evidenceCount|      overallScore|\n",
      "+---------------+-----------+-------------------+------------------+-------------------+-------------+------------------+\n",
      "|ENSG00000065361|EFO_0004587|genetic_association|ot_genetics_portal|0.30630293777671963|            3|0.1862109892733839|\n",
      "+---------------+-----------+-------------------+------------------+-------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    example_assoc\n",
    "    .filter(f.col('diseaseId') == 'EFO_0004587')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e079428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T08:38:38.978701Z",
     "start_time": "2022-07-08T08:38:38.923065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 20], [6, 4323], [12, 32, 12], [342]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [10, 20, 6, 4323, 12, 32, 12, 342]\n",
    "bp = [2, 4, 7]\n",
    "\n",
    "[l[b[0]:b[1]] for b in zip([0] + bp, bp + [len(l)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0493e9f",
   "metadata": {},
   "source": [
    "## Problem with diease classification\n",
    "\n",
    "**Date**: 2022.08.22\n",
    "\n",
    "As Violeta reported my script wrongly classified some of the diseases. Two examples:\n",
    "- EFO_0000095 - chronic lymphocytic leukemia => Not relevant\n",
    "- EFO_0004587 - lymphocyte count => not_relevant\n",
    "- EFO_0007993 - lymphocyte percentage of leukocytes => not_relevant\n",
    "\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Increase the scope of words that mark a disease relevant for hematological point of view.\n",
    "2. Get a list of all diseases that relevant in hematology\n",
    "3. Re-organize the dataset from term -> parent into a term -> children format.\n",
    "4. For each relevant disease term, recursively fetch all children.\n",
    "5. From the combined set of all descendats, generate a unique set of diseases that are considered relevant.\n",
    "5. Annotate with a boolean flag all diseases if they are relevant or not.\n",
    "\n",
    "### Follow up:\n",
    "\n",
    "1. Re-run the entire analysis.\n",
    "2. Save data.\n",
    "3. Submit to Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395be801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:38:09.499743Z",
     "start_time": "2022-08-23T08:38:05.219923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|   diseaseId|        diseaseLabel|           parentIds|\n",
      "+------------+--------------------+--------------------+\n",
      "|DOID_0050890|     synucleinopathy|[MONDO_0019052, M...|\n",
      "|  DOID_10113|     trypanosomiasis|     [MONDO_0002428]|\n",
      "|  DOID_10718|          giardiasis|[MONDO_0002428, E...|\n",
      "|  DOID_13406|pulmonary sarcoid...|[Orphanet_797, MO...|\n",
      "|   DOID_1947|      trichomoniasis|     [MONDO_0002428]|\n",
      "|   DOID_7551|           gonorrhea|[EFO_0003955, MON...|\n",
      "| EFO_0011021|BRCA1 mutation ca...|       [EFO_0007658]|\n",
      "| EFO_0011022|BRCA2 mutation ca...|       [EFO_0007658]|\n",
      "|  GO_0000003|reproductive process|        [GO_0008150]|\n",
      "|  GO_0000226|microtubule cytos...|        [GO_0006996]|\n",
      "|  GO_0000278|  mitotic cell cycle|        [GO_0007049]|\n",
      "|  GO_0001775|     cell activation|        [GO_0044763]|\n",
      "|  GO_0002445|type II hypersens...|        [GO_0002524]|\n",
      "|  GO_0002524|    hypersensitivity|        [GO_0002526]|\n",
      "|  GO_0002526|acute inflammator...|        [GO_0006954]|\n",
      "|  GO_0002682|regulation of imm...|        [GO_0050789]|\n",
      "|  GO_0002694|regulation of leu...|[GO_0050865, GO_0...|\n",
      "|  GO_0002695|negative regulati...|        [GO_0002694]|\n",
      "|  GO_0003008|      system process|        [GO_0032501]|\n",
      "|  GO_0003012|muscle system pro...|        [GO_0003008]|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of diseases: 23074\n"
     ]
    }
   ],
   "source": [
    "association_dataset = '/Users/dsuveges/project_data/associationByDatatypeDirect'\n",
    "disease_dataset = '/Users/dsuveges/project/random_notebooks/2022.06.08-disease_expansion/diseases_efo.json'\n",
    "\n",
    "# All children terms of a disease will be collected if the disease label contains any of these words:\n",
    "relevant_disease_pattern = ['immuno', 'hemato', 'hemo', 'blood', 'bleed', 'lympho']\n",
    "\n",
    "# Reading and parsing disease dataset:\n",
    "disease_raw = (\n",
    "    spark.read.json(disease_dataset)\n",
    "    .withColumnRenamed('id', 'diseaseId')\n",
    "    .withColumnRenamed('name', 'diseaseLabel')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "disease_raw.show()\n",
    "print(f'Number of diseases: {disease_raw.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e24dd5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T14:59:14.256480Z",
     "start_time": "2022-08-23T14:59:13.154210Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant diseases: 2419\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve all ascendants of a disease term:\n",
    "def get_children(did: str, children: list=[]) -> list:\n",
    "    \"\"\"\n",
    "    Every terms are added to the ancestors list.\n",
    "    Every terms are looked up in the children dictionary. \n",
    "    If a term could not be found returning the ancestry dictionary\n",
    "    If a term has childrend, we call the same function for all children.\n",
    "    \n",
    "    Args:\n",
    "        did (str): disease identifier\n",
    "        children (list): list of ancestors\n",
    "    Return:\n",
    "        list of ancestors\n",
    "    \"\"\"\n",
    "    children.append(did)\n",
    "\n",
    "    # Extract child terms:\n",
    "    try:\n",
    "        c = descendant_mapping[did]\n",
    "\n",
    "    # The term doesn't have children:\n",
    "    except KeyError:\n",
    "        return children\n",
    "    \n",
    "    for child in c:\n",
    "        get_children(child, children)\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "# Get all disease values with relevant names:\n",
    "relevant_parent_terms = [ x[0] for x in (\n",
    "    disease_raw\n",
    "    .filter(f.col('diseaseLabel').rlike('|'.join(relevant_disease_pattern)))\n",
    "    .select('diseaseId')\n",
    "    .collect()\n",
    ")]\n",
    "\n",
    "# Reconstruct data so instead of parent, it will contain children terms:\n",
    "childrend_rows = (\n",
    "    disease_raw\n",
    "    .select('diseaseId', f.explode('parentIds').alias('parentId'))\n",
    "    .groupBy('parentId')\n",
    "    .agg(f.collect_set(f.col('diseaseId')).alias('childIds'))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# Creating a mapping dictionary: keys are parent terms, values are lists of children.\n",
    "descendant_mapping = {row['parentId']: row['childIds'] for row in childrend_rows}\n",
    "\n",
    "# Fetching all the descendant of relevant diseases:\n",
    "all_children = [get_children(term, []) for term in relevant_parent_terms]\n",
    "\n",
    "# Concatenating the lists into one set of unique diseases:\n",
    "all_relevant = list(set(reduce(lambda x, y: x+y, all_children)))\n",
    "\n",
    "print(f'Number of relevant diseases: {len(all_relevant)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1278ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T15:04:47.724498Z",
     "start_time": "2022-08-23T15:04:47.569190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "| diseaseId|        diseaseLabel|\n",
      "+----------+--------------------+\n",
      "|GO_0007596|   blood coagulation|\n",
      "|GO_1900133|regulation of ren...|\n",
      "|GO_1900134|negative regulati...|\n",
      "|GO_1900135|positive regulati...|\n",
      "|HP_0000225|   Gingival bleeding|\n",
      "|HP_0000573|  Retinal hemorrhage|\n",
      "|HP_0001871|Abnormality of bl...|\n",
      "|HP_0001892|   Abnormal bleeding|\n",
      "|HP_0001898|Increased red blo...|\n",
      "|HP_0001933|Subcutaneous hemo...|\n",
      "|HP_0002239|Gastrointestinal ...|\n",
      "|HP_0003010|Prolonged bleedin...|\n",
      "|HP_0003111|Abnormal blood io...|\n",
      "|HP_0004421|Elevated systolic...|\n",
      "|HP_0004804|Congenital hemoly...|\n",
      "|HP_0005117|Elevated diastoli...|\n",
      "|HP_0005387|Combined immunode...|\n",
      "|HP_0008277|Abnormal blood zi...|\n",
      "|HP_0010931|Abnormal blood so...|\n",
      "|HP_0011015|Abnormal blood gl...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_parents = (\n",
    "    disease_raw\n",
    "    .filter(f.col('diseaseLabel').rlike('|'.join(relevant_disease_pattern)))\n",
    "    .select('diseaseId', 'diseaseLabel')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "(\n",
    "    relevant_parents\n",
    "    .toPandas()\n",
    "    .to_csv('relevant_parent_terms.tsv', sep='\\t', index=False)\n",
    ")\n",
    "\n",
    "relevant_parents.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f359487d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T15:07:27.335456Z",
     "start_time": "2022-08-23T15:07:27.064227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+----------+--------+\n",
      "| diseaseId|        diseaseLabel|           parentIds|isRelevant|isParent|\n",
      "+----------+--------------------+--------------------+----------+--------+\n",
      "|GO_0072718|response to cispl...|       [EFO_0004647]|      true|   false|\n",
      "|GO_0097328|response to carbo...|       [EFO_0004647]|      true|   false|\n",
      "|GO_1902520|response to doxor...|       [EFO_0005257]|      true|   false|\n",
      "|GO_1902522|response to epiru...|       [EFO_0005257]|      true|   false|\n",
      "|HP_0000132|         Menorrhagia|[HP_0001892, HP_0...|      true|   false|\n",
      "|HP_0000978|Bruising suscepti...|        [HP_0001933]|      true|   false|\n",
      "|HP_0000979|             Purpura|        [HP_0001933]|      true|   false|\n",
      "|HP_0001693|       Cardiac shunt|        [HP_0011028]|      true|   false|\n",
      "|HP_0001873|    Thrombocytopenia|        [HP_0001871]|      true|   false|\n",
      "|HP_0001876|        Pancytopenia|        [HP_0001871]|      true|   false|\n",
      "|HP_0001877|Abnormal erythroc...|        [HP_0001871]|      true|   false|\n",
      "|HP_0001880|        Eosinophilia|        [HP_0001974]|      true|   false|\n",
      "|HP_0001881|Abnormal leukocyt...|[HP_0002715, HP_0...|      true|   false|\n",
      "|HP_0001891|Iron deficiency a...|        [HP_0010972]|      true|   false|\n",
      "|HP_0001907|     Thromboembolism|        [HP_0001977]|      true|   false|\n",
      "|HP_0001913|    Granulocytopenia|        [HP_0001881]|      true|   false|\n",
      "|HP_0001915|     Aplastic anemia|[HP_0001876, EFO_...|      true|   false|\n",
      "|HP_0001928|Abnormality of co...|        [HP_0001871]|      true|   false|\n",
      "|HP_0001943|        Hypoglycemia|        [HP_0011015]|      true|   false|\n",
      "|HP_0001974|        Leukocytosis|        [HP_0001881]|      true|   false|\n",
      "+----------+--------------------+--------------------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    relevant_diseases\n",
    "    .join(relevant_parents.select('diseaseId', f.lit(True).alias('isParent')), on='diseaseId', how='left')\n",
    "    .withColumn('isParent', f.when(f.col('isParent') == True, True).otherwise(False))\n",
    "    .filter((f.col('isParent')==False) & (f.col('isRelevant')==True))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7886ff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T15:12:15.464824Z",
     "start_time": "2022-08-24T15:12:13.360056Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+----------+\n",
      "|   diseaseId|        diseaseLabel|           parentIds|isRelevant|\n",
      "+------------+--------------------+--------------------+----------+\n",
      "|DOID_0050890|     synucleinopathy|[MONDO_0019052, M...|     false|\n",
      "|  DOID_10113|     trypanosomiasis|     [MONDO_0002428]|     false|\n",
      "|  DOID_10718|          giardiasis|[MONDO_0002428, E...|     false|\n",
      "|  DOID_13406|pulmonary sarcoid...|[Orphanet_797, MO...|     false|\n",
      "|   DOID_1947|      trichomoniasis|     [MONDO_0002428]|     false|\n",
      "|   DOID_7551|           gonorrhea|[EFO_0003955, MON...|     false|\n",
      "| EFO_0011021|BRCA1 mutation ca...|       [EFO_0007658]|     false|\n",
      "| EFO_0011022|BRCA2 mutation ca...|       [EFO_0007658]|     false|\n",
      "|  GO_0000003|reproductive process|        [GO_0008150]|     false|\n",
      "|  GO_0000226|microtubule cytos...|        [GO_0006996]|     false|\n",
      "|  GO_0000278|  mitotic cell cycle|        [GO_0007049]|     false|\n",
      "|  GO_0001775|     cell activation|        [GO_0044763]|     false|\n",
      "|  GO_0002445|type II hypersens...|        [GO_0002524]|     false|\n",
      "|  GO_0002524|    hypersensitivity|        [GO_0002526]|     false|\n",
      "|  GO_0002526|acute inflammator...|        [GO_0006954]|     false|\n",
      "|  GO_0002682|regulation of imm...|        [GO_0050789]|     false|\n",
      "|  GO_0002694|regulation of leu...|[GO_0050865, GO_0...|     false|\n",
      "|  GO_0002695|negative regulati...|        [GO_0002694]|     false|\n",
      "|  GO_0003008|      system process|        [GO_0032501]|     false|\n",
      "|  GO_0003012|muscle system pro...|        [GO_0003008]|     false|\n",
      "+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Annotating diseases if they are hematologically relevant:\n",
    "relevant_diseases = (\n",
    "    disease_raw\n",
    "    .withColumn('isRelevant', f.when(f.col('diseaseId').isin(all_relevant), True).otherwise(False))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "relevant_diseases.show()\n",
    "# # Saving relevant diseases as a tsv:\n",
    "# (\n",
    "#     relevant_diseases\n",
    "#     .filter(f.col('isRelevant') == True)\n",
    "#     .select('diseaseId', 'diseaseLabel')\n",
    "#     .toPandas()\n",
    "#     .to_csv('/Users/dsuveges/Downloads/all_relevant_diseases.tsv', sep='\\t', index=False)\n",
    "# )\n",
    "\n",
    "# Saving all diseases with annotation:\n",
    "# (\n",
    "#     relevant_diseases\n",
    "#     .withColumn('parentIds', f.concat_ws('|', f.col('parentIds')))\n",
    "#     .toPandas()\n",
    "#     .to_csv('all_diseases_w_flag.tsv', sep='\\t', index=False)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51525056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T21:01:21.051189Z",
     "start_time": "2022-08-22T21:01:20.945795Z"
    }
   },
   "source": [
    "### Processing associations\n",
    "\n",
    "1. Read assoction file\n",
    "2. Drop animal model data\n",
    "3. Aggregating associations\n",
    "4. Calcualte harmonic sum\n",
    "5. Join disease info\n",
    "6. Join target info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0e2471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:39:34.467782Z",
     "start_time": "2022-08-23T08:39:29.184473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all associations: 2120908\n",
      "Number of associations supported by sources not including mouse: 1614569\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of all associations: {spark.read.parquet(association_dataset).select(\"diseaseId\", \"targetId\").distinct().count()}')\n",
    "\n",
    "no_animal_associations = (\n",
    "    spark.read.parquet(association_dataset)\n",
    "    .filter(f.col('datatypeId') != 'animal_model')\n",
    "    .select(\"diseaseId\", \"targetId\").distinct()\n",
    ")\n",
    "\n",
    "print(f'Number of associations supported by sources not including mouse: {no_animal_associations.count()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9fc46e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:39:41.191845Z",
     "start_time": "2022-08-23T08:39:40.977326Z"
    }
   },
   "outputs": [],
   "source": [
    "@f.udf(t.FloatType())\n",
    "def harmonic_sum(data: list, scale_factor: float = 1, cap: float = None) -> float:\n",
    "    \"\"\"\n",
    "    Returns an harmonic sum for the data passed\n",
    "    Args:\n",
    "        data (list): list of floats to compute the harmonic sum from\n",
    "        scale_factor (float): a scaling factor to multiply to each datapoint. Defaults to 1\n",
    "        cap (float): if not None, never return an harmonic sum higher than the cap value.\n",
    "    Returns:\n",
    "        harmonic_sum (float): the harmonic sum of the data passed\n",
    "    \"\"\"\n",
    "\n",
    "    data.sort(reverse=True)\n",
    "    harmonic_sum = sum(s / ((i+1) ** scale_factor) for i, s in enumerate(data))\n",
    "    \n",
    "    # Applying cap:\n",
    "    if cap is not None and harmonic_sum > cap:\n",
    "        return cap\n",
    "      \n",
    "    return harmonic_sum\n",
    "\n",
    "# An UDF to calculate median:\n",
    "median_udf = f.udf(lambda l: median([x for x in l if x >= 1]), t.FloatType())\n",
    "\n",
    "\n",
    "# Processing targets:\n",
    "targets = (\n",
    "    spark.read.parquet('/Users/dsuveges/project_data/targets')\n",
    "    .select(\n",
    "        f.col('id').alias('targetId'),\n",
    "        f.col('approvedSymbol').alias('targetSymbol'),\n",
    "        f.col('approvedName').alias('targetName')\n",
    "    )\n",
    "    .persist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfedcd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:39:49.425069Z",
     "start_time": "2022-08-23T08:39:44.897377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-------------+--------------------+----------+------------+--------------------+\n",
      "|       targetId| diseaseId|overall_score|        diseaseLabel|isRelevant|targetSymbol|          targetName|\n",
      "+---------------+----------+-------------+--------------------+----------+------------+--------------------+\n",
      "|ENSG00000113749|DOID_10718| 0.0121586155|          giardiasis|     false|        HRH2|histamine recepto...|\n",
      "|ENSG00000120937|DOID_13406|  0.018237924|pulmonary sarcoid...|     false|        NPPB|natriuretic pepti...|\n",
      "|ENSG00000066427| DOID_7551| 0.0121586155|           gonorrhea|     false|       ATXN3|            ataxin 3|\n",
      "|ENSG00000095739| DOID_7551|   0.03039654|           gonorrhea|     false|       BAMBI|BMP and activin m...|\n",
      "|ENSG00000102755| DOID_7551|   0.18691845|           gonorrhea|     false|        FLT1|fms related recep...|\n",
      "|ENSG00000103335| DOID_7551|    0.5912127|           gonorrhea|     false|      PIEZO1|piezo type mechan...|\n",
      "|ENSG00000106004| DOID_7551|    0.6392139|           gonorrhea|     false|       HOXA5|         homeobox A5|\n",
      "|ENSG00000116132| DOID_7551|   0.41379485|           gonorrhea|     false|       PRRX1|paired related ho...|\n",
      "|ENSG00000118046| DOID_7551|   0.58841276|           gonorrhea|     false|       STK11|serine/threonine ...|\n",
      "|ENSG00000121060| DOID_7551|   0.46363166|           gonorrhea|     false|      TRIM25|tripartite motif ...|\n",
      "|ENSG00000130770| DOID_7551|   0.24317232|           gonorrhea|     false|     ATP5IF1|ATP synthase inhi...|\n",
      "|ENSG00000137752| DOID_7551|   0.21351543|           gonorrhea|     false|       CASP1|           caspase 1|\n",
      "|ENSG00000147133| DOID_7551|  0.018237924|           gonorrhea|     false|        TAF1|TATA-box binding ...|\n",
      "|ENSG00000149806| DOID_7551|   0.03647585|           gonorrhea|     false|         FAU|FAU ubiquitin lik...|\n",
      "|ENSG00000154370| DOID_7551|    0.2310137|           gonorrhea|     false|      TRIM11|tripartite motif ...|\n",
      "|ENSG00000158941| DOID_7551|   0.05471377|           gonorrhea|     false|       CCAR2|cell cycle and ap...|\n",
      "|ENSG00000163629| DOID_7551|   0.03039654|           gonorrhea|     false|      PTPN13|protein tyrosine ...|\n",
      "|ENSG00000167081| DOID_7551|    0.5838669|           gonorrhea|     false|        PBX3|      PBX homeobox 3|\n",
      "|ENSG00000169714| DOID_7551| 0.0121586155|           gonorrhea|     false|        CNBP|CCHC-type zinc fi...|\n",
      "|ENSG00000173267| DOID_7551|    0.2978861|           gonorrhea|     false|        SNCG|     synuclein gamma|\n",
      "+---------------+----------+-------------+--------------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assoc_df = (\n",
    "    # Reading associations:\n",
    "    spark.read.parquet(association_dataset)\n",
    "    \n",
    "    # Dropping all animal model data:\n",
    "    .filter(f.col('datatypeId') != 'animal_model')\n",
    "    \n",
    "    # aggregating by association and calculate overall score:\n",
    "    .groupBy('diseaseId', 'targetId')\n",
    "    .agg(harmonic_sum(f.collect_list(f.col('score'))).alias('overall_score'))\n",
    "    \n",
    "    # Joining with diseases and disease annotation.\n",
    "    .join(relevant_diseases.drop('parentIds'), on='diseaseId')\n",
    "    \n",
    "    # Joining with target annotation:\n",
    "    .join(targets, on='targetId', how='left')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "# How does it look like:\n",
    "assoc_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ad23b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T21:31:54.519398Z",
     "start_time": "2022-08-22T21:31:11.883874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving data in a partitioned parquet:\n",
    "(\n",
    "    assoc_df\n",
    "    .select('targetId', 'targetSymbol', 'targetName', 'diseaseId', 'diseaseLabel', 'isRelevant', 'overall_score')\n",
    "    .write.mode('overwrite').parquet('Associations_w_disease_annot')\n",
    ")\n",
    "\n",
    "# Saving data in a single tsv file:\n",
    "(\n",
    "    assoc_df\n",
    "    .select('targetId', 'targetSymbol', 'targetName', 'diseaseId', 'diseaseLabel', 'isRelevant', 'overall_score')\n",
    "    .toPandas()\n",
    "    .to_csv('annotated_associations.tsv.gz', sep='\\t', compression='infer', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02cac6ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:45:28.574637Z",
     "start_time": "2022-08-23T08:45:05.378218Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregated_associations = (\n",
    "    assoc_df\n",
    "    \n",
    "    # Applying a filter based on the overall score: \n",
    "    # iteratively we can adjust this to make sure we are not too stringent\n",
    "    .filter(\n",
    "        (f.col('overall_score') >= 0.1)\n",
    "    )\n",
    "    \n",
    "    # Grouping data by target and the relevance flag:\n",
    "    .groupby('targetId', 'targetName', 'targetSymbol')\n",
    "    .pivot('isRelevant')\n",
    "    .agg(\n",
    "        f.max(f.col('overall_score')).alias('max'),\n",
    "        f.mean(f.col('overall_score')).alias('mean_score'),\n",
    "        f.count(f.col('overall_score')).alias('disease_count'),\n",
    "        median_udf(f.collect_list(f.col('overall_score'))).alias('median_score'),\n",
    "    )\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "aggregated_associations.count()\n",
    "\n",
    "# Saving data in in tsv:\n",
    "(\n",
    "    aggregated_associations\n",
    "    .toPandas()\n",
    "    .to_csv('aggregated_associations.tsv.gz', sep='\\t', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a76047d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:45:44.110647Z",
     "start_time": "2022-08-23T08:45:44.069157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 97200\n",
      "drwxr-xr-x   12 dsuveges  EBI\\Domain Users   384B 23 Aug 09:45 .\n",
      "drwxrwxr-x   87 dsuveges  EBI\\Domain Users   2.7K 16 Aug 14:38 ..\n",
      "drwxr-xr-x    5 dsuveges  EBI\\Domain Users   160B  7 Jul 21:14 .ipynb_checkpoints\n",
      "drwxr-xr-x  404 dsuveges  EBI\\Domain Users    13K 22 Aug 22:31 Associations_w_disease_annot\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users   132K 22 Aug 22:19 Bulk_analysis.ipynb\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users    44K 23 Aug 09:45 Correct process.ipynb\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users    38K 12 Jul 19:07 Finding disease parents.ipynb\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users   1.1M 23 Aug 09:45 aggregated_associations.tsv.gz\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users   118K 22 Aug 16:53 all_relevant_diseases.tsv\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users    43M 22 Aug 22:31 annotated_associations.tsv.gz\n",
      "-rw-r--r--    1 dsuveges  EBI\\Domain Users   2.4M 24 Jun 11:17 diseases_efo.json\n",
      "drwxr-xr-x    3 dsuveges  EBI\\Domain Users    96B  6 Jul 08:09 pub\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b17f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T15:11:18.639377Z",
     "start_time": "2022-08-24T15:11:16.869605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+----------+\n",
      "|  diseaseId|         diseaseName|category|isRelevant|\n",
      "+-----------+--------------------+--------+----------+\n",
      "|  DOID_7551|           gonorrhea|    null|     false|\n",
      "|EFO_0004254|membranous glomer...|    null|     false|\n",
      "|EFO_0005189|respiratory quotient|    null|     false|\n",
      "|EFO_0005853|response to silic...|    null|     false|\n",
      "|EFO_0006317|response to thiop...|    null|     false|\n",
      "|EFO_0007229|      cryptococcosis|    null|     false|\n",
      "|EFO_0007391|Nematoda infectio...|    null|     false|\n",
      "|EFO_0008080|cerebrospinal flu...|    null|     false|\n",
      "|EFO_0008167|interleukin 1 Rec...|    null|     false|\n",
      "|EFO_0008181|interleukin 23 re...|    null|     false|\n",
      "|EFO_0009960|atypical femoral ...|    null|     false|\n",
      "|EFO_0010586|    CD40 measurement|    null|     false|\n",
      "|EFO_0010717|            afebrile|    null|     false|\n",
      "|EFO_0010977|macrovascular com...|    null|     false|\n",
      "|EFO_0011044|BMI-adjusted neck...|    null|     false|\n",
      "|EFO_0020045|prostaglandins me...|    null|     false|\n",
      "|EFO_0020110|14-3-3 protein si...|    null|     false|\n",
      "|EFO_0020628|periostin measure...|    null|     false|\n",
      "|EFO_0020658|proliferation-ass...|    null|     false|\n",
      "|EFO_0020661|proteasome activa...|    null|     false|\n",
      "+-----------+--------------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disease_dataset = '/Users/dsuveges/project_data/diseases_22.06'\n",
    "\n",
    "# Create a dataframe with the relevant disease identifiers and the corresponding category label:\n",
    "category_of_interest = spark.createDataFrame([\n",
    "    {'id': 'EFO_0005803', 'category': 'D'}, # hemotologic diseases \n",
    "    {'id': 'EFO_0004503', 'category': 'M'}, # hemotological measurement\n",
    "    {'id': 'HP_0001871',  'category': 'P'}  # Abnormality of the blood and blood-forming tissues\n",
    "])\n",
    "\n",
    "# Relevant diseases are all descendants of the above terms:\n",
    "relevant_diseases = (\n",
    "    spark.read.parquet(disease_dataset)\n",
    "    \n",
    "    # Extract the relevant rows from the disease index:\n",
    "    .join(category_of_interest, on='id', how='right')\n",
    "    \n",
    "    # Extract descendants:\n",
    "    .select('category', f.explode('descendants').alias('id'))\n",
    "    \n",
    "    # Grouping by disease id -> get a list of categories the disease is annotated with:\n",
    "    .groupby('id')\n",
    "    .agg(f.collect_set('category').alias('category'))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "# Join the disease index with the above generated list:\n",
    "annotated_diseases = (\n",
    "    spark.read.parquet(disease_dataset)\n",
    "    .join(relevant_diseases, on='id', how='left')\n",
    "    .select(\n",
    "        f.col('id').alias('diseaseId'),\n",
    "        f.col('name').alias('diseaseName'),\n",
    "        f.col('category')\n",
    "    )\n",
    "    .withColumn('isRelevant', f.when(f.col('category').isNotNull(), True).otherwise(False))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "annotated_diseases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65ce78b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T15:37:21.974341Z",
     "start_time": "2022-08-24T15:37:21.163706Z"
    }
   },
   "outputs": [],
   "source": [
    "# relevant_diseases.show()\n",
    "\n",
    "(\n",
    "    annotated_diseases\n",
    "    .withColumnRenamed('isRelevant', 'isRelevantNew')\n",
    "    .drop('diseaseName')\n",
    "    .join(\n",
    "        (\n",
    "            relevant_diseases\n",
    "            .withColumnRenamed('isRelevant', 'isRelevantOld')\n",
    "            .drop('parentIds')\n",
    "        )\n",
    "        , on='diseaseId', how='inner'\n",
    "    )\n",
    "    .withColumn(\n",
    "        'source',\n",
    "        f.when(\n",
    "            (\n",
    "                (f.col('isRelevantOld') == True) &\n",
    "                (f.col('isRelevantNew') == True)\n",
    "            ), f.lit('both'))\n",
    "        .when(\n",
    "            (\n",
    "                (f.col('isRelevantOld') == True) &\n",
    "                (f.col('isRelevantNew') == False)\n",
    "            ), f.lit('old_only'))\n",
    "        .when(\n",
    "            (\n",
    "                (f.col('isRelevantOld') == True) &\n",
    "                (f.col('isRelevantNew') == True)\n",
    "            ), f.lit('new_only'))\n",
    "        .otherwise(f.lit('none'))\n",
    "    )\n",
    "#     .select('diseaseLabel', 'category', 'isRelevantOld', 'isRelevantNew')\n",
    "#     .filter(\n",
    "#         (f.col('isRelevantOld') == True) &\n",
    "#         (f.col('isRelevantNew') == False)\n",
    "#     )\n",
    "#     .groupBy('source')\n",
    "#     .count()\n",
    "    .select('diseaseLabel', 'diseaseId', 'isRelevantOld', 'isRelevantNew', 'source')\n",
    "    .toPandas()\n",
    "    .to_csv('comparing_disease_classification.tsv', sep='\\t', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1913555c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T10:52:24.246358Z",
     "start_time": "2022-08-25T10:52:24.171651Z"
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o15445.parquet.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:46)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:377)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:833)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-e92e5fbad8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gs://ot-team/jarrod/nmm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     .count()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    456\u001b[0m                        modifiedAfter=modifiedAfter)\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     def text(self, paths, wholetext=False, lineSep=None, pathGlobFilter=None,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o15445.parquet.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"gs\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:46)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:377)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:325)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:307)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:307)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:833)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.read.parquet('/Users/dsuveges/Downloads/ENSG00000130203-colocalising-studies.json')\n",
    "    .show(1, False, True)\n",
    "#     .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6741b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
