{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4e0f88",
   "metadata": {},
   "source": [
    "# Fetch interactions from pdb\n",
    "\n",
    "**procecc:**\n",
    "\n",
    "1. Read pre-defined data\n",
    "2. Re-arrange the same data by pdb vs. ligand\n",
    "3. Fetch pdb header (via single thread 100 structure: 18 sec.)\n",
    "4. Process header \n",
    "5. Return data in proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a33ffcc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T15:57:30.515206Z",
     "start_time": "2022-03-25T15:57:30.494957Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "\n",
    "import requests\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import (\n",
    "    col, udf, struct, lit, split, expr, collect_set, struct, \n",
    "    regexp_replace, min as pyspark_min, explode, when,\n",
    "    array_contains, count, first, element_at, size, sum as pyspark_sum, array, array_sort\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    FloatType, ArrayType, StructType, StructField, BooleanType, StringType, IntegerType\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from collections import defaultdict\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "# establish spark connection\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5cad5f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T15:37:59.924017Z",
     "start_time": "2022-03-15T15:37:59.921371Z"
    }
   },
   "outputs": [],
   "source": [
    "data = '/Users/dsuveges/project/random_notebooks/issue-1891_extracting_drug-ligand_complex/molecules_w_targets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cddb1f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T15:42:40.631644Z",
     "start_time": "2022-03-15T15:42:39.230040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------------+\n",
      "|pdb_structure_id|collect_set(pdb_compound_id)|\n",
      "+----------------+----------------------------+\n",
      "|            1avd|                       [BTN]|\n",
      "|            1d5m|                       [ALC]|\n",
      "|            1d6q|                       [GOL]|\n",
      "|            1e9b|                       [ATM]|\n",
      "|            1ere|                       [EST]|\n",
      "|            1j3z|                       [CMO]|\n",
      "|            1jan|                        [ZN]|\n",
      "|            1ln2|                       [MSE]|\n",
      "|            1lq8|                  [NDG, IPA]|\n",
      "|            1ozj|                        [ZN]|\n",
      "|            1qxe|                  [FUX, OXY]|\n",
      "|            1raz|                        [ZN]|\n",
      "|            1t2v|                       [SEP]|\n",
      "|            1t9s|                   [ZN, 5GP]|\n",
      "|            1y8q|                   [ATP, ZN]|\n",
      "|            1ydb|                   [AZM, ZN]|\n",
      "|            1yxu|                       [AMP]|\n",
      "|            1z0f|                       [GDP]|\n",
      "|            1z89|                  [62P, NAP]|\n",
      "|            2b02|                       [MSE]|\n",
      "+----------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "27315\n"
     ]
    }
   ],
   "source": [
    "# Dataset witht all the details, produced earlier:\n",
    "input_dataset = (\n",
    "    spark.read.parquet(data)\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "# This dataset is grouped by pdb id to get all the compounds:\n",
    "data_to_look_up = (\n",
    "    input_dataset\n",
    "    .filter(col('ensembl_gene_id').startswith('ENSG'))\n",
    "    .groupby('pdb_structure_id')\n",
    "    .agg(collect_set(col('pdb_compound_id')))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "data_to_look_up.show()\n",
    "print(data_to_look_up.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f52367d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T16:03:17.649960Z",
     "start_time": "2022-03-15T16:00:56.969300Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch PDB structure: 4y14\n",
      "Failed to fetch PDB structure: 7ozy\n",
      "Failed to fetch PDB structure: 4cql\n",
      "Failed to fetch PDB structure: 4xol\n",
      "Failed to fetch PDB structure: 5dak\n",
      "Failed to fetch PDB structure: 5e83\n",
      "Failed to fetch PDB structure: 5em3\n",
      "Failed to fetch PDB structure: 5epz\n",
      "Failed to fetch PDB structure: 5gli\n",
      "Failed to fetch PDB structure: 5hou\n",
      "Failed to fetch PDB structure: 5j9x\n",
      "Failed to fetch PDB structure: 5l60\n",
      "Failed to fetch PDB structure: 6tks\n",
      "Failed to fetch PDB structure: 6wjd\n",
      "Failed to fetch PDB structure: 6zel\n",
      "Failed to fetch PDB structure: 6yjv\n",
      "Failed to fetch PDB structure: 6ts0\n",
      "Failed to fetch PDB structure: 7bfa\n",
      "Failed to fetch PDB structure: 6t8v\n",
      "Failed to fetch PDB structure: 6wov\n",
      "Failed to fetch PDB structure: 7l20\n",
      "Failed to fetch PDB structure: 4ug0\n",
      "Failed to fetch PDB structure: 7ai1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import urllib\n",
    "\n",
    "def fetch_pdb(pdbId: str) -> None:\n",
    "    \"\"\"This function fetches a single PDB structure from PDBEurope\n",
    "    \n",
    "    Args:\n",
    "        pdb_strcture_id: string, a single PDB structure identifier\n",
    "        folder: string, a folder to save the structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        urllib.request.urlretrieve(f'https://www.ebi.ac.uk/pdbe/static/entry/download/{pdbId}.header', f'./{pdbId}.pdb')\n",
    "    except:\n",
    "        # logging.warning(f'Failed to fetch PDB structure: {pdb_strcture_id}')\n",
    "        print(f'Failed to fetch PDB structure: {pdbId}')\n",
    "\n",
    "    \n",
    "\n",
    "@udf(IntegerType())\n",
    "def test_parser(pdbId):\n",
    "    try:\n",
    "        with open(f'{pdbId}.pdb', 'rt') as f:\n",
    "            lines = f.readlines()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    binding_sites_lines = filter(lambda line: line.startswith('REMARK 800') and ':' in line, lines)\n",
    "    return len([line for line in binding_sites_lines])\n",
    "\n",
    "\n",
    "# Download data:\n",
    "(\n",
    "    data_to_look_up\n",
    "    .limit(1000)\n",
    "    .toPandas()\n",
    "    .pdb_structure_id\n",
    "    .apply(fetch_pdb)\n",
    ")\n",
    "\n",
    "parsing_test = (\n",
    "    data_to_look_up\n",
    "    .limit(1000)\n",
    "    .withColumn('test', test_parser(col('pdb_structure_id')))\n",
    "    .persist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55d8760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T16:05:52.595124Z",
     "start_time": "2022-03-15T16:05:52.528171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------------------------------------+----+\n",
      "|pdb_structure_id|collect_set(pdb_compound_id)                           |test|\n",
      "+----------------+-------------------------------------------------------+----+\n",
      "|1d5m            |[ALC]                                                  |0   |\n",
      "|1d6q            |[GOL]                                                  |0   |\n",
      "|1lq8            |[NDG, IPA]                                             |0   |\n",
      "|1t2v            |[SEP]                                                  |0   |\n",
      "|2b02            |[MSE]                                                  |0   |\n",
      "|2qki            |[GOL]                                                  |0   |\n",
      "|3jz2            |[GOL]                                                  |0   |\n",
      "|4lbo            |[SIA, BGC]                                             |0   |\n",
      "|4oc5            |[ZN]                                                   |0   |\n",
      "|5czx            |[EDO]                                                  |0   |\n",
      "|5f84            |[UDP, BGC]                                             |0   |\n",
      "|5goi            |[DSN, DAS, DGN, DPR, DLE, DSG, DGL, DLY, DPN, DTY, DAL]|0   |\n",
      "|5l0t            |[GOL, UDP]                                             |0   |\n",
      "|5o45            |[SAR, CCS]                                             |0   |\n",
      "|5ub5            |[UDP]                                                  |0   |\n",
      "|6ibx            |[DMS]                                                  |0   |\n",
      "|6iwr            |[UDP]                                                  |0   |\n",
      "|6nix            |[B3P]                                                  |0   |\n",
      "|6pok            |[GOL]                                                  |0   |\n",
      "|6qf7            |[PRO]                                                  |0   |\n",
      "+----------------+-------------------------------------------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    parsing_test\n",
    "    .filter(col('test') == 0)\n",
    "    .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f36ee0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T14:32:01.752012Z",
     "start_time": "2022-03-22T14:32:01.401607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+--------------+\n",
      "|study_id|lead_variant_id|tag_variant_id|\n",
      "+--------+---------------+--------------+\n",
      "| study_1|           var1|          var1|\n",
      "| study_1|           var1|          var2|\n",
      "| study_1|           var1|          var3|\n",
      "| study_1|           var4|          var4|\n",
      "| study_1|           var4|          var5|\n",
      "| study_1|           var6|          var6|\n",
      "| study_1|           var6|          var7|\n",
      "| study_1|           var6|          var8|\n",
      "| study_2|           var9|          var9|\n",
      "| study_2|           var9|          var2|\n",
      "| study_2|           var9|          var3|\n",
      "| study_3|          var10|          var4|\n",
      "| study_3|          var10|          var5|\n",
      "| study_3|          var10|         var10|\n",
      "| study_3|          var11|         var11|\n",
      "| study_3|          var11|          var2|\n",
      "+--------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var1\",\n",
    "        \"lead_variant_id\": \"var1\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var2\",\n",
    "        \"lead_variant_id\": \"var1\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var3\",\n",
    "        \"lead_variant_id\": \"var1\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var4\",\n",
    "        \"lead_variant_id\": \"var4\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var5\",\n",
    "        \"lead_variant_id\": \"var4\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var6\",\n",
    "        \"lead_variant_id\": \"var6\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var7\",\n",
    "        \"lead_variant_id\": \"var6\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_1\",\n",
    "        \"tag_variant_id\": \"var8\",\n",
    "        \"lead_variant_id\": \"var6\",\n",
    "    },\n",
    "#    \n",
    "#\n",
    "    {\n",
    "        \"study_id\": \"study_2\",\n",
    "        \"tag_variant_id\": \"var9\",\n",
    "        \"lead_variant_id\": \"var9\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_2\",\n",
    "        \"tag_variant_id\": \"var2\",\n",
    "        \"lead_variant_id\": \"var9\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_2\",\n",
    "        \"tag_variant_id\": \"var3\",\n",
    "        \"lead_variant_id\": \"var9\",\n",
    "    },\n",
    "#\n",
    "#\n",
    "    {\n",
    "        \"study_id\": \"study_3\",\n",
    "        \"tag_variant_id\": \"var4\",\n",
    "        \"lead_variant_id\": \"var10\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_3\",\n",
    "        \"tag_variant_id\": \"var5\",\n",
    "        \"lead_variant_id\": \"var10\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_3\",\n",
    "        \"tag_variant_id\": \"var10\",\n",
    "        \"lead_variant_id\": \"var10\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_3\",\n",
    "        \"tag_variant_id\": \"var11\",\n",
    "        \"lead_variant_id\": \"var11\",\n",
    "    },\n",
    "    {\n",
    "        \"study_id\": \"study_3\",\n",
    "        \"tag_variant_id\": \"var2\",\n",
    "        \"lead_variant_id\": \"var11\",\n",
    "    },\n",
    "]\n",
    "\n",
    "df = (\n",
    "    spark.createDataFrame(test_data)\n",
    "    .select('study_id', 'lead_variant_id', 'tag_variant_id')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "df.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba000f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T21:23:59.633209Z",
     "start_time": "2022-03-21T21:23:59.113211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------------+--------------+\n",
      "|lead_variant_id_left|study_id_left|lead_variant_id_right|study_id_right|\n",
      "+--------------------+-------------+---------------------+--------------+\n",
      "|                var9|      study_2|                 var1|       study_1|\n",
      "|                var4|      study_1|                var10|       study_3|\n",
      "|               var11|      study_3|                 var1|       study_1|\n",
      "|                var9|      study_2|                var11|       study_3|\n",
      "+--------------------+-------------+---------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['study_id', 'lead_variant_id']\n",
    "\n",
    "# Creating the two dataset to be joined:\n",
    "left_df = reduce(lambda DF, col: DF.withColumnRenamed(col, col+'_left'), columns, df)\n",
    "right_df = reduce(lambda DF, col: DF.withColumnRenamed(col, col+'_right'), columns, df)\n",
    "\n",
    "\n",
    "overlapping_signals = (\n",
    "    left_df\n",
    "    .join(right_df, on='tag_variant_id', how='inner')\n",
    "    .filter(col('study_id_right') != col('study_id_left'))\n",
    "    .filter(col('lead_variant_id_left') > col('lead_variant_id_right'))\n",
    "    .drop('tag_variant_id')\n",
    "    .distinct()\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "overlapping_signals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51ddd574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-21T21:28:02.934984Z",
     "start_time": "2022-03-21T21:28:02.562051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+-------------+--------------+-------------+-------------------+--------------+--------------------+\n",
      "|lead_variant_id_right|lead_variant_id_left|study_id_left|study_id_right|study_id_left|tag_variant_id_left|study_id_right|tag_variant_id_right|\n",
      "+---------------------+--------------------+-------------+--------------+-------------+-------------------+--------------+--------------------+\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var4|       study_3|               var10|\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var4|       study_3|                var5|\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var4|       study_3|                var4|\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var5|       study_3|               var10|\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var5|       study_3|                var5|\n",
      "|                var10|                var4|      study_1|       study_3|      study_1|               var5|       study_3|                var4|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var9|       study_3|                var2|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var9|       study_3|               var11|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var9|       study_1|                var3|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var9|       study_1|                var2|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var9|       study_1|                var1|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var2|       study_3|                var2|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var2|       study_3|               var11|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var2|       study_1|                var3|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var2|       study_1|                var2|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var2|       study_1|                var1|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var3|       study_3|                var2|\n",
      "|                var11|                var9|      study_2|       study_3|      study_2|               var3|       study_3|               var11|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var3|       study_1|                var3|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var3|       study_1|                var2|\n",
      "|                 var1|                var9|      study_2|       study_1|      study_2|               var3|       study_1|                var1|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|              var11|       study_1|                var3|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|              var11|       study_1|                var2|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|              var11|       study_1|                var1|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|               var2|       study_1|                var3|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|               var2|       study_1|                var2|\n",
      "|                 var1|               var11|      study_3|       study_1|      study_3|               var2|       study_1|                var1|\n",
      "+---------------------+--------------------+-------------+--------------+-------------+-------------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    overlapping_signals\n",
    "    .join(left_df.withColumnRenamed('tag_variant_id', 'tag_variant_id_left'), on='lead_variant_id_left', how='inner')\n",
    "    .join(right_df.withColumnRenamed('tag_variant_id', 'tag_variant_id_right'), on='lead_variant_id_right', how='inner')\n",
    "    .show(30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "067a16a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T11:40:33.665831Z",
     "start_time": "2022-03-22T11:40:33.269349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADD-WGR-FIRTH'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    (\n",
    "        pd.read_csv('http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90082001-GCST90083000/GCST90082654/GCST90082654_buildGRCh38.tsv.gz', sep='\\t', compression='infer')\n",
    "        .Model.unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6f9d69e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T13:09:04.533691Z",
     "start_time": "2022-03-22T13:09:03.447443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+--------+--------+---------------+----+-------------------+-------------------------+--------+----------------+----------+---------------+----------+--------+---------------+--------------+-------------+--------------+-----------+\n",
      "| id|canonicalSmiles|inchiKey|drugType|blackBoxWarning|name|yearOfFirstApproval|maximumClinicalTrialPhase|parentId|hasBeenWithdrawn|isApproved|withdrawnNotice|tradeNames|synonyms|crossReferences|childChemblIds|linkedTargets|linkedDiseases|description|\n",
      "+---+---------------+--------+--------+---------------+----+-------------------+-------------------------+--------+----------------+----------+---------------+----------+--------+---------------+--------------+-------------+--------------+-----------+\n",
      "+---+---------------+--------+--------+---------------+----+-------------------+-------------------------+--------+----------------+----------+---------------+----------+--------+---------------+--------------+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.read.parquet('/Users/dsuveges/project_data/molecule/')\n",
    "    .filter(col('inchiKey') == 'WHMQZCPGFZBLBG-UHFFFAOYSA-N')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d00fb76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T13:08:21.960993Z",
     "start_time": "2022-03-23T13:08:21.905265Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: [Column<'t_r'>, Column<'t_l'>] of type <class 'list'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-90c620712e44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m's_l'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'study1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_l'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's_r'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'study2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ])\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollect_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't_l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variants'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mcollect_set\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollect_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \"\"\"\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function_over_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"collect_set\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_invoke_function_over_column\u001b[0;34m(name, col)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter3.9/lib/python3.9/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;34m\"Invalid argument, not a string or column: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;34m\"{0} of type {1}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: [Column<'t_r'>, Column<'t_l'>] of type <class 'list'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "(\n",
    "    spark.createDataFrame([\n",
    "        {'s_l': 'study1', 't_l':['v1', 'v2', 'v3'], 's_r': 'study2', 't_r':['v1', 'v4', 'v5', 'v3']}\n",
    "    ])\n",
    "    .withColumn(collect_set([col('t_r'), col('t_l')]).alias('variants'))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5129f60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T07:11:57.211803Z",
     "start_time": "2022-03-24T07:11:57.022248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|key|values|\n",
      "+---+------+\n",
      "|  1|     1|\n",
      "|  1|     2|\n",
      "|  1|     3|\n",
      "|  1|     4|\n",
      "|  2|     3|\n",
      "|  2|     4|\n",
      "|  2|     5|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum, explode, max as pyspark_max, expr, collect_list, exp\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df = (\n",
    "    spark\n",
    "    .createDataFrame(\n",
    "        [(1, [1, 2, 3, 4]), (2, [3, 4, 5])],\n",
    "        (\"key\", \"values\"))\n",
    "    .withColumn(\"values\", explode(\"values\"))\n",
    ")\n",
    "\n",
    "#Df mormalised no-log\n",
    "w1 = Window.partitionBy(\"key\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2acb7410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T21:34:22.845051Z",
     "start_time": "2022-03-23T21:34:22.338768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------------+\n",
      "|key|values|           x/max(x)|\n",
      "+---+------+-------------------+\n",
      "|  1|     1|                0.1|\n",
      "|  1|     2|                0.2|\n",
      "|  1|     3|                0.3|\n",
      "|  1|     4|                0.4|\n",
      "|  2|     3|               0.25|\n",
      "|  2|     4|0.33333333333333337|\n",
      "|  2|     5| 0.4166666666666667|\n",
      "+---+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_norm_nonLog = (\n",
    "    df\n",
    "    .withColumn(\"x/max(x)\", (col(\"values\") / pyspark_max(col(\"values\")).over(w1)) / pyspark_sum(col(\"values\") / pyspark_max(col(\"values\")).over(w1)).over(w1))\n",
    "#     .withColumn(\"x/max(x)\", col(\"values\") / col(\"max\"))\n",
    "#     .withColumn(\"sum(x/max(x))\", pyspark_sum(col(\"x/max(x)\")).over(w1))\n",
    "#     .withColumn(\"x/max(x)/sum(x/max(x))\", col(\"x/max(x)\") / col(\"sum(x/max(x))\"))   \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1df0fed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T07:05:11.751527Z",
     "start_time": "2022-03-24T07:05:10.983187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|key|       norm|\n",
      "+---+-----------+\n",
      "|  1|0.032058604|\n",
      "|  1|0.087144315|\n",
      "|  1| 0.23688282|\n",
      "|  1|  0.6439143|\n",
      "|  2| 0.09003057|\n",
      "|  2| 0.24472848|\n",
      "|  2| 0.66524094|\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# norm1 <- function(x, log = FALSE) {\n",
    "#   if (all(is.na(x))) return(x)\n",
    "#   if (log) {\n",
    "#     x <- x - max(x, na.rm = TRUE)\n",
    "#     x <- exp(x)    \n",
    "#   } else {\n",
    "#     ## This does not work if x contains NaNs or +Infs\n",
    "#     stopifnot(all(x >= 0, na.rm = TRUE))\n",
    "#     x <- x / max(x, na.rm = TRUE)\n",
    "#   }\n",
    "#   return(x / sum(x, na.rm = TRUE))\n",
    "# }\n",
    "\n",
    "@udf(ArrayType(FloatType()))\n",
    "def normLog (a: list) -> list:\n",
    "    a = [math.exp(x - max(a)) for x in a]\n",
    "    a = [x/sum(a) for x in a]\n",
    "    \n",
    "    return a\n",
    "    \n",
    "    \n",
    "(\n",
    "    df\n",
    "    .groupBy('key')\n",
    "    .agg(\n",
    "        normLog(collect_list(col('values'))).alias('norm')\n",
    "    )\n",
    "    .withColumn('norm', explode(\"norm\"))\n",
    "    .show()\n",
    ")\n",
    "\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eae8feb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T07:14:19.225916Z",
     "start_time": "2022-03-24T07:14:18.779059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------------+\n",
      "|key|values|           logDifMax|               norm|\n",
      "+---+------+--------------------+-------------------+\n",
      "|  1|     1|0.049787068367863944|0.03205860328008499|\n",
      "|  1|     2|  0.1353352832366127|0.08714431874203257|\n",
      "|  1|     3| 0.36787944117144233|0.23688281808991013|\n",
      "|  1|     4|                 1.0| 0.6439142598879724|\n",
      "|  2|     3|  0.1353352832366127|0.09003057317038046|\n",
      "|  2|     4| 0.36787944117144233|0.24472847105479764|\n",
      "|  2|     5|                 1.0| 0.6652409557748218|\n",
      "+---+------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .withColumn(\"logDifMax\", exp(col('values') - pyspark_max(col(\"values\")).over(w1)))\n",
    "    .withColumn('norm', col(\"logDifMax\")/pyspark_sum(col(\"logDifMax\")).over(w1))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9577a540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T15:53:33.764615Z",
     "start_time": "2022-03-25T15:53:33.169679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|lead_id|study_id|\n",
      "+-------+--------+\n",
      "|     l1|      s1|\n",
      "|     l2|      s1|\n",
      "|     l1|      s2|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([{\n",
    "    \"study_id\": \"s1\",\n",
    "    \"lead_id\": \"l1\",\n",
    "},\n",
    "{\n",
    "    \"study_id\": \"s1\",\n",
    "    \"lead_id\": \"l2\",\n",
    "\n",
    "},\n",
    "{\n",
    "    \"study_id\": \"s2\",\n",
    "    \"lead_id\": \"l1\",\n",
    "}]).persist()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9ec05f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T16:00:25.101800Z",
     "start_time": "2022-03-25T16:00:24.508202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+-------+\n",
      "|unique_test|study_id_r|study_id_l|lead_id|\n",
      "+-----------+----------+----------+-------+\n",
      "|   [s1, s2]|        s2|        s1|     l1|\n",
      "+-----------+----------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df.withColumnRenamed('study_id', 'study_id_l')\n",
    "    .join(df.withColumnRenamed('study_id', 'study_id_r'), on='lead_id', how='inner')\n",
    "    .filter(col('study_id_r') != col('study_id_l'))\n",
    "    .withColumn('unique_test', array_sort(array(col('study_id_l'), col('study_id_r'))))\n",
    "    .groupBy('unique_test')\n",
    "    .agg(\n",
    "        *[first(c).alias(c) for c in ['study_id_r', 'study_id_l', 'lead_id']]\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72b66b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T15:58:57.988886Z",
     "start_time": "2022-03-25T15:58:57.979846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_id', 'study_id']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbab207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
