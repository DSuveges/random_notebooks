{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping the new json schema\n",
    "\n",
    "\n",
    "As part of the consolidation of the evidence objects in the backend, we are re-modeling the [json schema](https://github.com/opentargets/json_schema) to reflect the new simplified/flattened design.\n",
    "\n",
    "Based on the meeting we had on 2020.11.11 the following conclusions were reached:\n",
    "\n",
    "* We need to maintain a json schema that guides our data providers and can be used as template to generate evidence strings.\n",
    "* The schema will reflect the concepts of the new platform design, so the units of the schema is going to be data source centric instead of data type.\n",
    "* Each of the valuable columns will be defined in a common section.\n",
    "* For each data source there will only be a list of required fields.\n",
    "* We haven't reached a consensus on how the unique association fields are defined, and at which point of the evidence generation. So for the first iteration of the json schema, the unique_association_fields will be omitted.\n",
    "\n",
    "The schema is written based on the most recent iteration of the [evidence schema review](https://docs.google.com/spreadsheets/d/11jdPCo_vxY3jaP54xKTsXBshR5HMrpUf5oXJNgtbKm8/edit#gid=1735847104) document.\n",
    "\n",
    "The technical approach:\n",
    "\n",
    "* To avoid manual work with the json document, I'm collating information in an excel file and will use that as a source for the definitions.\n",
    "* The same excel file will be used to get the source names from where we are expecting the given field.\n",
    "\n",
    "## The first run completed:\n",
    "\n",
    "- [X] processing the review document to get the rough list of fields\n",
    "- [x] get fields2datasource mapping\n",
    "- [x] generate json schema based on the meeting\n",
    "\n",
    "\n",
    "## The first run didn't cover:\n",
    "\n",
    "- [ ] some fields are missing eg. uniprot id\n",
    "- [ ] some fields shoudl not be here: `score` and `id`\n",
    "- [ ] the precise requirements of the fields are still sparse -> add more data to `field_description.xlsx`\n",
    "- [ ] no structure whatsoever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the list of data source for every field\n",
    "\n",
    "This information is extracted from the evidence schema review file. The end of the process is a comma separated list of data sources for every field. This column is used later to generate the mandatory list of fields for every data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T01:32:16.268651Z",
     "start_time": "2020-11-12T01:32:16.247276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer_gene_census</th>\n",
       "      <th>chembl</th>\n",
       "      <th>clingen</th>\n",
       "      <th>crispr</th>\n",
       "      <th>europepmc</th>\n",
       "      <th>eva</th>\n",
       "      <th>eva_somatic</th>\n",
       "      <th>expression_atlas</th>\n",
       "      <th>gene2phenotype</th>\n",
       "      <th>genomics_england</th>\n",
       "      <th>intogen</th>\n",
       "      <th>ot_genetics_portal</th>\n",
       "      <th>phenodigm</th>\n",
       "      <th>phewas_catalog</th>\n",
       "      <th>progeny</th>\n",
       "      <th>reactome</th>\n",
       "      <th>slapenrich</th>\n",
       "      <th>sysbio</th>\n",
       "      <th>uniprot_literature</th>\n",
       "      <th>uniprot_somatic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allelicRequirement</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biologicalModelAllelicComposition</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biologicalModelGeneticBackground</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinicalPhase</th>\n",
       "      <td>0</td>\n",
       "      <td>427943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinicalSignificance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107532</td>\n",
       "      <td>8173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cancer_gene_census  chembl  clingen  \\\n",
       "allelicRequirement                                  0       0     1075   \n",
       "biologicalModelAllelicComposition                   0       0        0   \n",
       "biologicalModelGeneticBackground                    0       0        0   \n",
       "clinicalPhase                                       0  427943        0   \n",
       "clinicalSignificance                                0       0        0   \n",
       "\n",
       "                                   crispr  europepmc     eva  eva_somatic  \\\n",
       "allelicRequirement                      0          0       0            0   \n",
       "biologicalModelAllelicComposition       0          0       0            0   \n",
       "biologicalModelGeneticBackground        0          0       0            0   \n",
       "clinicalPhase                           0          0       0            0   \n",
       "clinicalSignificance                    0          0  107532         8173   \n",
       "\n",
       "                                   expression_atlas  gene2phenotype  \\\n",
       "allelicRequirement                                0            2451   \n",
       "biologicalModelAllelicComposition                 0               0   \n",
       "biologicalModelGeneticBackground                  0               0   \n",
       "clinicalPhase                                     0               0   \n",
       "clinicalSignificance                              0               0   \n",
       "\n",
       "                                   genomics_england  intogen  \\\n",
       "allelicRequirement                                0        0   \n",
       "biologicalModelAllelicComposition                 0        0   \n",
       "biologicalModelGeneticBackground                  0        0   \n",
       "clinicalPhase                                     0        0   \n",
       "clinicalSignificance                              0        0   \n",
       "\n",
       "                                   ot_genetics_portal  phenodigm  \\\n",
       "allelicRequirement                                  0          0   \n",
       "biologicalModelAllelicComposition                   0     564310   \n",
       "biologicalModelGeneticBackground                    0     564310   \n",
       "clinicalPhase                                       0          0   \n",
       "clinicalSignificance                                0          0   \n",
       "\n",
       "                                   phewas_catalog  progeny  reactome  \\\n",
       "allelicRequirement                              0        0         0   \n",
       "biologicalModelAllelicComposition               0        0         0   \n",
       "biologicalModelGeneticBackground                0        0         0   \n",
       "clinicalPhase                                   0        0         0   \n",
       "clinicalSignificance                            0        0         0   \n",
       "\n",
       "                                   slapenrich  sysbio  uniprot_literature  \\\n",
       "allelicRequirement                          0       0                   0   \n",
       "biologicalModelAllelicComposition           0       0                   0   \n",
       "biologicalModelGeneticBackground            0       0                   0   \n",
       "clinicalPhase                               0       0                   0   \n",
       "clinicalSignificance                        0       0                   0   \n",
       "\n",
       "                                   uniprot_somatic  \n",
       "allelicRequirement                               0  \n",
       "biologicalModelAllelicComposition                0  \n",
       "biologicalModelGeneticBackground                 0  \n",
       "clinicalPhase                                    0  \n",
       "clinicalSignificance                             0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the source names for every field:\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "notnull_table = pd.read_csv('iter9_notnull_table.tsv', sep='\\t')\n",
    "notnull_table.index = notnull_table.key.tolist()\n",
    "notnull_table.drop('key', axis=1, inplace=True)\n",
    "notnull_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T21:11:03.048756Z",
     "start_time": "2020-11-11T21:11:02.990035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         clingen,gene2phenotype\n",
       "1                      phenodigm\n",
       "2                      phenodigm\n",
       "3                         chembl\n",
       "4                eva,eva_somatic\n",
       "                 ...            \n",
       "57    cancer_gene_census,intogen\n",
       "58                      reactome\n",
       "59    cancer_gene_census,intogen\n",
       "60    cancer_gene_census,intogen\n",
       "61            cancer_gene_census\n",
       "Length: 62, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looping through all fields and extracting all sources where the data is present:\n",
    "lookup = lambda x: ','.join(notnull_table.loc[x].where(lambda x: x != 0).dropna().index.to_list())\n",
    "pd.Series(notnull_table.index).apply(lookup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading field description\n",
    "\n",
    "1. Read excel file with the field descriptions\n",
    "2. Parse values. \n",
    "3. Start building json object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T01:08:49.967723Z",
     "start_time": "2020-11-12T01:08:49.943993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend_name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>minimum</th>\n",
       "      <th>exclusiveMinimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>accepted_values</th>\n",
       "      <th>nullable</th>\n",
       "      <th>pattern</th>\n",
       "      <th>data_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allelicRequirement</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clingen,gene2phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biologicalModelAllelicComposition</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phenodigm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biologicalModelGeneticBackground</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phenodigm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clinicalPhase</td>\n",
       "      <td>integer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chembl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinicalSignificance</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eva,eva_somatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        backend_name     type description  minimum  \\\n",
       "0                 allelicRequirement   string         NaN      NaN   \n",
       "1  biologicalModelAllelicComposition   string         NaN      NaN   \n",
       "2   biologicalModelGeneticBackground   string         NaN      NaN   \n",
       "3                      clinicalPhase  integer         NaN      NaN   \n",
       "4               clinicalSignificance   string         NaN      NaN   \n",
       "\n",
       "   exclusiveMinimum  maximum  accepted_values nullable pattern  \\\n",
       "0               NaN      NaN              NaN      NaN     NaN   \n",
       "1               NaN      NaN              NaN      NaN     NaN   \n",
       "2               NaN      NaN              NaN      NaN     NaN   \n",
       "3               NaN      NaN              NaN      NaN     NaN   \n",
       "4               NaN      NaN              NaN      NaN     NaN   \n",
       "\n",
       "              data_source  \n",
       "0  clingen,gene2phenotype  \n",
       "1               phenodigm  \n",
       "2               phenodigm  \n",
       "3                  chembl  \n",
       "4         eva,eva_somatic  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_description = 'field_descriptions.xlsx'\n",
    "fields_df = pd.read_excel(field_description)\n",
    "fields_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T23:21:38.774276Z",
     "start_time": "2020-11-11T23:21:38.759184Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_data_sources(df):\n",
    "    # Parsing dataframe to get list of fields for each data source:\n",
    "    parsed_sources = defaultdict(list)\n",
    "    for i, row in df.iterrows():\n",
    "        for source in row['data_source'].split(','):\n",
    "            \n",
    "            # Only using ot_genetics for now:\n",
    "            if source != 'ot_genetics_portal':\n",
    "                continue\n",
    "                \n",
    "            parsed_sources[source].append(row['backend_name'])\n",
    "\n",
    "    # Each data source then exploded into schemas:\n",
    "    source_schemas = []\n",
    "    for source, fields in parsed_sources.items():\n",
    "        source_schema = OrderedDict()\n",
    "\n",
    "        # Adding property definitions:\n",
    "        source_schema['properties'] = OrderedDict({'datasourceId': {\"const\": source}})\n",
    "        \n",
    "        for field in fields:\n",
    "            if field == 'datasourceId':\n",
    "                continue\n",
    "                \n",
    "            source_schema['properties'][field] = {\"$ref\": f\"#/definitions/{field}\"}\n",
    "        \n",
    "        source_schema['required'] = fields\n",
    "\n",
    "\n",
    "        # Adding source schema:\n",
    "        source_schemas.append(source_schema)\n",
    "        \n",
    "    return(source_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T02:56:16.834428Z",
     "start_time": "2020-11-12T02:56:16.783238Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
      "  \"title\": \"OpenTargets\",\n",
      "  \"description\": \"OpenTargets evidence objects\",\n",
      "  \"type\": \"object\",\n",
      "  \"oneOf\": [\n",
      "    {\n",
      "      \"properties\": {\n",
      "        \"datasourceId\": {\n",
      "          \"const\": \"ot_genetics_portal\"\n",
      "        },\n",
      "        \"confidenceIntervalLower\": {\n",
      "          \"$ref\": \"#/definitions/confidenceIntervalLower\"\n",
      "        },\n",
      "        \"confidenceIntervalUpper\": {\n",
      "          \"$ref\": \"#/definitions/confidenceIntervalUpper\"\n",
      "        },\n",
      "        \"diseaseFromSource\": {\n",
      "          \"$ref\": \"#/definitions/diseaseFromSource\"\n",
      "        },\n",
      "        \"diseaseId\": {\n",
      "          \"$ref\": \"#/definitions/diseaseId\"\n",
      "        },\n",
      "        \"id\": {\n",
      "          \"$ref\": \"#/definitions/id\"\n",
      "        },\n",
      "        \"literature\": {\n",
      "          \"$ref\": \"#/definitions/literature\"\n",
      "        },\n",
      "        \"locus2GeneScore\": {\n",
      "          \"$ref\": \"#/definitions/locus2GeneScore\"\n",
      "        },\n",
      "        \"oddsRatio\": {\n",
      "          \"$ref\": \"#/definitions/oddsRatio\"\n",
      "        },\n",
      "        \"publicationFirstAuthor\": {\n",
      "          \"$ref\": \"#/definitions/publicationFirstAuthor\"\n",
      "        },\n",
      "        \"publicationYear\": {\n",
      "          \"$ref\": \"#/definitions/publicationYear\"\n",
      "        },\n",
      "        \"resourceScore\": {\n",
      "          \"$ref\": \"#/definitions/resourceScore\"\n",
      "        },\n",
      "        \"resourceScoreExponent\": {\n",
      "          \"$ref\": \"#/definitions/resourceScoreExponent\"\n",
      "        },\n",
      "        \"resourceScoreMantissa\": {\n",
      "          \"$ref\": \"#/definitions/resourceScoreMantissa\"\n",
      "        },\n",
      "        \"score\": {\n",
      "          \"$ref\": \"#/definitions/score\"\n",
      "        },\n",
      "        \"studyId\": {\n",
      "          \"$ref\": \"#/definitions/studyId\"\n",
      "        },\n",
      "        \"studySampleSize\": {\n",
      "          \"$ref\": \"#/definitions/studySampleSize\"\n",
      "        },\n",
      "        \"targetId\": {\n",
      "          \"$ref\": \"#/definitions/targetId\"\n",
      "        },\n",
      "        \"variantFunctionalConsequenceId\": {\n",
      "          \"$ref\": \"#/definitions/variantFunctionalConsequenceId\"\n",
      "        },\n",
      "        \"variantId\": {\n",
      "          \"$ref\": \"#/definitions/variantId\"\n",
      "        },\n",
      "        \"variantRsId\": {\n",
      "          \"$ref\": \"#/definitions/variantRsId\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"confidenceIntervalLower\",\n",
      "        \"confidenceIntervalUpper\",\n",
      "        \"datasourceId\",\n",
      "        \"diseaseFromSource\",\n",
      "        \"diseaseId\",\n",
      "        \"id\",\n",
      "        \"literature\",\n",
      "        \"locus2GeneScore\",\n",
      "        \"oddsRatio\",\n",
      "        \"publicationFirstAuthor\",\n",
      "        \"publicationYear\",\n",
      "        \"resourceScore\",\n",
      "        \"resourceScoreExponent\",\n",
      "        \"resourceScoreMantissa\",\n",
      "        \"score\",\n",
      "        \"studyId\",\n",
      "        \"studySampleSize\",\n",
      "        \"targetId\",\n",
      "        \"variantFunctionalConsequenceId\",\n",
      "        \"variantId\",\n",
      "        \"variantRsId\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"definitions\": {\n",
      "    \"confidenceIntervalLower\": {\n",
      "      \"type\": [\n",
      "        \"number\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"Lower value of the confidence interval\"\n",
      "    },\n",
      "    \"confidenceIntervalUpper\": {\n",
      "      \"type\": [\n",
      "        \"number\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"Upper value of the confidence interval\"\n",
      "    },\n",
      "    \"datasourceId\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"diseaseFromSource\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"diseaseId\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"literature\": {\n",
      "      \"type\": [\n",
      "        \"string\",\n",
      "        \"null\"\n",
      "      ]\n",
      "    },\n",
      "    \"locus2GeneScore\": {\n",
      "      \"type\": \"number\",\n",
      "      \"description\": \"Locus to gene score\",\n",
      "      \"maximum\": 1.0,\n",
      "      \"exclusiveMinimum\": 0.0\n",
      "    },\n",
      "    \"oddsRatio\": {\n",
      "      \"type\": [\n",
      "        \"number\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"Odds ratio of the association\"\n",
      "    },\n",
      "    \"publicationFirstAuthor\": {\n",
      "      \"type\": [\n",
      "        \"string\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"First author of the publication\"\n",
      "    },\n",
      "    \"publicationYear\": {\n",
      "      \"type\": [\n",
      "        \"integer\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"Year of publication\"\n",
      "    },\n",
      "    \"resourceScore\": {\n",
      "      \"type\": [\n",
      "        \"number\",\n",
      "        \"null\"\n",
      "      ]\n",
      "    },\n",
      "    \"resourceScoreExponent\": {\n",
      "      \"type\": \"integer\",\n",
      "      \"description\": \"Exponent of the association p-value\",\n",
      "      \"maximum\": 0.0\n",
      "    },\n",
      "    \"resourceScoreMantissa\": {\n",
      "      \"type\": \"number\",\n",
      "      \"description\": \"Mantissa of the association p-value\",\n",
      "      \"exclusiveMinimum\": 0.0\n",
      "    },\n",
      "    \"score\": {\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"studyId\": {\n",
      "      \"type\": \"string\",\n",
      "      \"description\": \"GWAS study accession\"\n",
      "    },\n",
      "    \"studySampleSize\": {\n",
      "      \"type\": \"integer\",\n",
      "      \"description\": \"Sample size of the GWAS study\",\n",
      "      \"exclusiveMinimum\": 0.0\n",
      "    },\n",
      "    \"targetId\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"variantFunctionalConsequenceId\": {\n",
      "      \"type\": \"string\",\n",
      "      \"description\": \"SO code of the functional consequence of the variant\"\n",
      "    },\n",
      "    \"variantId\": {\n",
      "      \"type\": \"string\",\n",
      "      \"description\": \"Identifier of the variant in the OpenTargets Genetics portal\"\n",
      "    },\n",
      "    \"variantRsId\": {\n",
      "      \"type\": [\n",
      "        \"string\",\n",
      "        \"null\"\n",
      "      ],\n",
      "      \"description\": \"rs identifier of the variant\",\n",
      "      \"pattern\": \"^rs[0-9]{1,}$\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Reloading possible modifications from the xlsx file:\n",
    "fields_df = pd.read_excel(field_description)\n",
    "\n",
    "# constants for the json schema:\n",
    "schema_obj = OrderedDict({\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"title\": \"OpenTargets\",\n",
    "    \"description\": \"OpenTargets evidence objects\",\n",
    "    \"type\": \"object\",\n",
    "    \"oneOf\": {},\n",
    "    \"definitions\": OrderedDict()\n",
    "})\n",
    "\n",
    "# Adding all the required fields for all data sources:\n",
    "schema_obj[\"oneOf\"] = parse_data_sources(fields_df)\n",
    "\n",
    "# Parsing dataframe to get list of fields for each data source:\n",
    "parsed_sources = defaultdict(list)\n",
    "\n",
    "for i, row in fields_df.iterrows():\n",
    "    field = row['backend_name']\n",
    "    \n",
    "    # Only using ot_genetics for now:\n",
    "    if 'ot_genetics_portal' not in row['data_source']:\n",
    "        continue\n",
    "\n",
    "    field_annotation = OrderedDict()\n",
    "    \n",
    "    # Setting type - maybe nullable:\n",
    "    if row['nullable']:\n",
    "        field_annotation['type'] = [row['type'], \"null\"]\n",
    "    else:\n",
    "        field_annotation['type'] = row['type']\n",
    "    \n",
    "    # Adding description:\n",
    "    if isinstance(row['description'], str):\n",
    "        field_annotation['description'] = row['description']\n",
    "\n",
    "    # Adding minimum:\n",
    "    if not np.isnan(row['minimum']):\n",
    "        field_annotation['minimum'] = row['minimum']\n",
    "        \n",
    "    # Adding description:\n",
    "    if not np.isnan(row['maximum']):\n",
    "        field_annotation['maximum'] = row['maximum']\n",
    "\n",
    "    # Adding minimum:\n",
    "    if not np.isnan(row['exclusiveMinimum']):\n",
    "        field_annotation['exclusiveMinimum'] = row['exclusiveMinimum']\n",
    "        \n",
    "    # Adding pattern:\n",
    "    if isinstance(row['pattern'], str):\n",
    "        field_annotation['pattern'] = row['pattern']\n",
    "        \n",
    "    schema_obj['definitions'][field] = field_annotation\n",
    "    \n",
    "    \n",
    "    \n",
    "print(json.dumps(schema_obj, indent=2))\n",
    "\n",
    "with open('json_schema_v0.1.json', 'w') as f:\n",
    "    json.dump(schema_obj, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T12:38:36.635076Z",
     "start_time": "2020-11-12T12:38:36.630465Z"
    }
   },
   "outputs": [],
   "source": [
    "l = ['Elemér', 'Gábor', 'József', 'Emese', 'Zoltán', 'egér']\n",
    "\n",
    "l_filtered = [x for x in l if x[0] == 'E'] # Case sensitive\n",
    "l_filtered = [x for x in l if re.match('^E', x)] # Regular expression - case sensitive\n",
    "l_filtered = [x for x in l if re.match('^E', x, re.IGNORECASE)] # Regexp - case insensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T12:38:36.820722Z",
     "start_time": "2020-11-12T12:38:36.818154Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T12:38:40.743904Z",
     "start_time": "2020-11-12T12:38:40.739533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elemér', 'Emese', 'egér']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in l if re.match('^E', x, re.IGNORECASE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T11:29:32.860119Z",
     "start_time": "2020-11-13T11:29:32.195249Z"
    }
   },
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'<!DOCTYP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-f6736647abf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://drive.google.com/file/d/1vHoyIsQDBNmUfq2IUdZDoz3G457V5cqW/view?usp=sharing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'<!DOCTYP'"
     ]
    }
   ],
   "source": [
    "pd.read_excel('https://drive.google.com/file/d/1vHoyIsQDBNmUfq2IUdZDoz3G457V5cqW/view?usp=sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:52:36.437213Z",
     "start_time": "2020-11-13T12:52:35.444868Z"
    }
   },
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:53:31.798338Z",
     "start_time": "2020-11-13T12:53:31.775704Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ForMedium-8f02213e02aa.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-3e3466fa406e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m credentials = ServiceAccountCredentials.from_json_keyfile_name(\n\u001b[0;32m----> 5\u001b[0;31m          'ForMedium-8f02213e02aa.json', scope) # Your json file here\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.6/site-packages/oauth2client/service_account.py\u001b[0m in \u001b[0;36mfrom_json_keyfile_name\u001b[0;34m(cls, filename, scopes, token_uri, revoke_uri)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mkeyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m             \u001b[0mclient_credentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         return cls._from_parsed_json_keyfile(client_credentials, scopes,\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ForMedium-8f02213e02aa.json'"
     ]
    }
   ],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(\n",
    "         'ForMedium-8f02213e02aa.json', scope) # Your json file here\n",
    "\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "wks = gc.open(\"NYC subway data\").sheet1\n",
    "\n",
    "data = wks.get_all_values()\n",
    "headers = data.pop(0)\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
