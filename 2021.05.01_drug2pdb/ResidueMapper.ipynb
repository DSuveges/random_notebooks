{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb35656",
   "metadata": {},
   "source": [
    "Parsing gencode file takes ~40sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6851d546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:24:23.749378Z",
     "start_time": "2022-04-30T00:24:23.208113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chr': '17', 'pos': 27787802, 'strand': '-'},\n",
       " {'chr': '17', 'pos': 27787801, 'strand': '-'},\n",
       " {'chr': '17', 'pos': 27787800, 'strand': '-'}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class ResidueMapper:\n",
    "    \n",
    "    def __init__(self, GENCODEFile: str, verbose: bool =False) -> None:\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Reading GENCODE data and filter for CDS segments:\n",
    "        gtf_columns = ['chr', 'source', 'featureType', 'start', 'end', 'score', 'strand', 'phase', 'annotation']\n",
    "        df = (\n",
    "            pd.read_csv(GENCODEFile, sep='\\t', comment='#', header=0, names=gtf_columns)\n",
    "            .query('featureType == \"CDS\"')\n",
    "            .reset_index(drop=True)\n",
    "            .drop(['source', 'score', 'phase'], axis=1)\n",
    "        )\n",
    "\n",
    "        # Parse annotations for separate columns:\n",
    "        annotations_df = pd.DataFrame(\n",
    "            df.annotation\n",
    "            .apply(lambda features: {feature.split('=')[0]: feature.split('=')[1] for feature in features.split(';')})\n",
    "            .to_list()\n",
    "        )\n",
    "\n",
    "        # Join annotations with coordinates:\n",
    "        self.full_gencode = (\n",
    "            df\n",
    "            .drop('annotation', axis=1)\n",
    "            .merge(annotations_df, left_index=True, right_index=True)\n",
    "\n",
    "            # Remove versions:\n",
    "            .assign(\n",
    "                gene_id = lambda df: df.gene_id.str.replace(r'\\.\\d+', '', regex=True),\n",
    "                transcript_id = lambda df: df.transcript_id.str.replace(r'\\.\\d+', '', regex=True),\n",
    "                protein_id = lambda df: df.protein_id.str.replace(r'\\.\\d+', '', regex=True),\n",
    "                exon_id = lambda df: df.exon_id.str.replace(r'\\.\\d+', '', regex=True),\n",
    "                chr = lambda df: df.chr.str.replace(r'chr', '', regex=False),\n",
    "                feature_length = lambda df: df.end - df.start\n",
    "            )\n",
    "\n",
    "            # Dropping unused columns:\n",
    "            .drop([\n",
    "                'ID', 'Parent', 'gene_type', 'transcript_type', 'transcript_support_level',\n",
    "                'exon_number', 'level', 'hgnc_id', 'tag', 'havana_gene', 'havana_transcript',\n",
    "                'ccdsid', 'ont', 'featureType', 'transcript_name'\n",
    "            ], axis=1)\n",
    "        )\n",
    "    \n",
    "    def map_position(self, translation_id: str, aminoacid_position: int) -> list:\n",
    "\n",
    "        # Filter gencode data for relevant protein only:\n",
    "        selected = (\n",
    "            self.full_gencode\n",
    "            .query('protein_id == @translation_id')\n",
    "            .sort_values('start')\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Extract relevant data:\n",
    "        row = selected.iloc[0]\n",
    "        gene_id = row['gene_id']\n",
    "        chromosome = row['chr']\n",
    "        transcript_id = row['transcript_id']\n",
    "        gene_name = row['gene_name']\n",
    "        strand = row['strand']\n",
    "\n",
    "        # Magic:\n",
    "        positions = reduce(lambda x,y: x+y,(selected.apply(lambda row: list(range(row['start'],row['end']+1)), axis = 1)),[])\n",
    "\n",
    "        # If the gene is on the negative strand we need to flip the list:\n",
    "        if strand == '-':\n",
    "            positions = positions[::-1]\n",
    "\n",
    "        # Extracting positions:\n",
    "        extracted_positions = positions[(aminoacid_position-1)*3:(aminoacid_position-1)*3+3]\n",
    "        return [{'chr': chromosome, 'pos': position, 'strand': strand} for position in extracted_positions]\n",
    "\n",
    "\n",
    "# Source file:\n",
    "gencodeFile = '/Users/dsuveges/Downloads/gencode.v40.annotation.gff3.gz'\n",
    "\n",
    "# Map an amino acid position of a given protein:\n",
    "translation_id = 'ENSP00000327251'\n",
    "aminoacid_position = 115\n",
    "\n",
    "mapper = ResidueMapper(gencodeFile)\n",
    "mapper.map_position(translation_id, aminoacid_position)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "516a49e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:25:41.067591Z",
     "start_time": "2022-04-30T00:25:40.586831Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGC"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "chrom=17\n",
    "start=27787800\n",
    "end=27787802\n",
    "\n",
    "curl -s https://rest.ensembl.org/sequence/region/human/${chrom}:${start}..${end}:-1?content-type=text/plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "45a0d656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:27:25.884615Z",
     "start_time": "2022-04-30T00:27:25.791650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chr': '12', 'pos': 56093060, 'strand': '+'},\n",
       " {'chr': '12', 'pos': 56093061, 'strand': '+'},\n",
       " {'chr': '12', 'pos': 56093062, 'strand': '+'}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An other example:\n",
    "translation_id = 'ENSP00000267101'\n",
    "aminoacid_position = 420\n",
    "\n",
    "mapper.map_position(translation_id, aminoacid_position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21191d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T00:28:00.391133Z",
     "start_time": "2022-04-30T00:28:00.332391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chr': '17', 'pos': 27787802, 'strand': '-'},\n",
       " {'chr': '17', 'pos': 27787801, 'strand': '-'},\n",
       " {'chr': '17', 'pos': 27787800, 'strand': '-'}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An other re-run:\n",
    "translation_id = 'ENSP00000327251'\n",
    "aminoacid_position = 115\n",
    "\n",
    "mapper.map_position(translation_id, aminoacid_position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc91f8f",
   "metadata": {},
   "source": [
    "One query takes ~100ms. So 10 lookup per second. 250000 lookups ~7 hours without parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da5438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
