{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/12/16 11:53:39 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/12/16 11:53:40 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/12/16 11:53:40 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/12/16 11:53:40 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as f, types as t, Column, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# pics_data = spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set/').persist()\n",
    "# pics_data.filter(f.col('tagVariantId').isNotNull() & f.col('pics_99_perc_credset')).show()\n",
    "\n",
    "# ld_data = spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/ld_expanded_assoc')\n",
    "# ld_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative overall R\n",
    "\n",
    "- This most likely can be explained by duplication... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+---------------+---------+--------------------+-------------+--------------------+--------------------+\n",
      "|     studyId|      variantId|   tagVariantId|R_overall|             pics_mu|pics_postprob|pics_95_perc_credset|pics_99_perc_credset|\n",
      "+------------+---------------+---------------+---------+--------------------+-------------+--------------------+--------------------+\n",
      "|GCST000278_1|1_112770941_C_A|1_112779261_T_A|-0.051554|0.014678789508465448|          NaN|                true|                true|\n",
      "+------------+---------------+---------------+---------+--------------------+-------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    pics_data\n",
    "    .filter(\n",
    "        (f.col('studyId') =='GCST000278_1') & \n",
    "        (f.col('variantId') =='1_112770941_C_A') &\n",
    "        (f.col('tagVariantId') =='1_112779261_T_A')\n",
    "    )\n",
    "    .drop('chromosome')\n",
    "    .show() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+------------+----------+------------------+---------------+------------------+\n",
      "|      variantId|gnomadPopulation|     studyId|sampleSize|relativeSampleSize|   tagVariantId|                 r|\n",
      "+---------------+----------------+------------+----------+------------------+---------------+------------------+\n",
      "|1_112770941_C_A|             nfe|GCST000278_1|    2790.0|               1.0|1_112779261_T_A|0.9745720726356035|\n",
      "|1_112770941_C_A|             nfe|GCST000278_1|    2790.0|               1.0|1_112779261_T_A|0.9745720726356035|\n",
      "|1_112770941_C_A|             nfe|GCST000278_1|    2790.0|               1.0|1_112779261_T_A|0.9745720726356035|\n",
      "|1_112770941_C_A|             nfe|GCST000278_1|    2790.0|               1.0|1_112779261_T_A|0.9745720726356035|\n",
      "+---------------+----------------+------------+----------+------------------+---------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    ld_data\n",
    "    .filter(\n",
    "        (f.col('studyId') =='GCST000278_1') & \n",
    "        (f.col('variantId') =='1_112770941_C_A') &\n",
    "        (f.col('tagVariantId') =='1_112779261_T_A')\n",
    "    )\n",
    "    # .distinct()\n",
    "    .select('variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r')\n",
    "    .show() \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## posterior probability NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+---------+-----------------+-------------+--------------------+--------------------+\n",
      "|   studyId|      variantId|   tagVariantId|R_overall|          pics_mu|pics_postprob|pics_95_perc_credset|pics_99_perc_credset|\n",
      "+----------+---------------+---------------+---------+-----------------+-------------+--------------------+--------------------+\n",
      "|GCST000175|1_184051811_G_A|1_184041593_C_A| 0.966352|7.561187580349171|          NaN|                true|                true|\n",
      "+----------+---------------+---------------+---------+-----------------+-------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  1|  GCST000175|1_184051811_G_A|  1_184041593_C_A| 0.966352|   7.561187580349171|                 NaN|                true|                true|\n",
    "\n",
    "(\n",
    "    pics_data\n",
    "    .filter(\n",
    "        (f.col('studyId') =='GCST000175') & \n",
    "        (f.col('variantId') =='1_184051811_G_A') &\n",
    "        (f.col('tagVariantId') =='1_184041593_C_A')\n",
    "    )\n",
    "    .drop('chromosome')\n",
    "    .show() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+----------+----------+------------------+---------------+------------------+\n",
      "|      variantId|gnomadPopulation|   studyId|sampleSize|relativeSampleSize|   tagVariantId|                 r|\n",
      "+---------------+----------------+----------+----------+------------------+---------------+------------------+\n",
      "|1_184051811_G_A|             nfe|GCST000175|   30968.0|               1.0|1_184041593_C_A|0.9663520794409783|\n",
      "+---------------+----------------+----------+----------+------------------+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    ld_data\n",
    "    .filter(\n",
    "        (f.col('studyId') =='GCST000175') & \n",
    "        (f.col('variantId') =='1_184051811_G_A') &\n",
    "        (f.col('tagVariantId') =='1_184041593_C_A')\n",
    "    )\n",
    "    # .distinct()\n",
    "    .select('variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r')\n",
    "    .show() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def _pics_standard_deviation(neglog_p: Column, r: Column, k: float) -> Column:\n",
    "    \"\"\"Compute the PICS standard deviation.\n",
    "\n",
    "    Args:\n",
    "        neglog_p (Column): Negative log p-value\n",
    "        r (Column): R-squared\n",
    "        k (float): Empiric constant that can be adjusted to fit the curve, 6.4 recommended.\n",
    "\n",
    "    Returns:\n",
    "        Column: PICS standard deviation\n",
    "\n",
    "    Examples:\n",
    "        >>> k = 6.4\n",
    "        >>> d = [(1.0, 1.0), (10.0, 1.0), (10.0, 0.5), (100.0, 0.5), (1.0, 0.0)]\n",
    "        >>> spark.createDataFrame(d).toDF(\"neglog_p\", \"r\").withColumn(\"std\", _pics_standard_deviation(f.col(\"neglog_p\"), f.col(\"r\"), k)).show()\n",
    "        +--------+---+-----------------+\n",
    "        |neglog_p|  r|              std|\n",
    "        +--------+---+-----------------+\n",
    "        |     1.0|1.0|              0.0|\n",
    "        |    10.0|1.0|              0.0|\n",
    "        |    10.0|0.5|1.571749395040553|\n",
    "        |   100.0|0.5|4.970307999319905|\n",
    "        |     1.0|0.0|              0.5|\n",
    "        +--------+---+-----------------+\n",
    "        <BLANKLINE>\n",
    "    \"\"\"\n",
    "    return f.sqrt(1 - f.abs(r) ** k) * f.sqrt(neglog_p) / 2\n",
    "\n",
    "\n",
    "def _pics_mu(neglog_p: Column, r: Column) -> Column:\n",
    "    \"\"\"Compute the PICS mu.\n",
    "\n",
    "    Args:\n",
    "        neglog_p (Column): Negative log p-value\n",
    "        r (Column): R\n",
    "\n",
    "    Returns:\n",
    "        Column: PICS mu\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [(1.0, 1.0), (10.0, 1.0), (10.0, 0.5), (100.0, 0.5), (1.0, 0.0)]\n",
    "        >>> spark.createDataFrame(d).toDF(\"neglog_p\", \"r\").withColumn(\"mu\", _pics_mu(f.col(\"neglog_p\"), f.col(\"r\"))).show()\n",
    "        +--------+---+----+\n",
    "        |neglog_p|  r|  mu|\n",
    "        +--------+---+----+\n",
    "        |     1.0|1.0| 1.0|\n",
    "        |    10.0|1.0|10.0|\n",
    "        |    10.0|0.5| 2.5|\n",
    "        |   100.0|0.5|25.0|\n",
    "        |     1.0|0.0| 0.0|\n",
    "        +--------+---+----+\n",
    "        <BLANKLINE>\n",
    "    \"\"\"\n",
    "    return neglog_p * (r**2)\n",
    "\n",
    "\n",
    "def _neglog_p(p_value_mantissa: Column, p_value_exponent: Column) -> Column:\n",
    "    \"\"\"Compute the negative log p-value.\n",
    "\n",
    "    Args:\n",
    "        p_value_mantissa (Column): P-value mantissa\n",
    "        p_value_exponent (Column): P-value exponent\n",
    "\n",
    "    Returns:\n",
    "        Column: Negative log p-value\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [(1, 1), (5, -2), (1, -1000)]\n",
    "        >>> df = spark.createDataFrame(d).toDF(\"p_value_mantissa\", \"p_value_exponent\")\n",
    "        >>> df.withColumn(\"neg_log_p\", _neglog_p(f.col(\"p_value_mantissa\"), f.col(\"p_value_exponent\"))).show()\n",
    "        +----------------+----------------+------------------+\n",
    "        |p_value_mantissa|p_value_exponent|         neg_log_p|\n",
    "        +----------------+----------------+------------------+\n",
    "        |               1|               1|              -1.0|\n",
    "        |               5|              -2|1.3010299956639813|\n",
    "        |               1|           -1000|            1000.0|\n",
    "        +----------------+----------------+------------------+\n",
    "        <BLANKLINE>\n",
    "    \"\"\"\n",
    "    return -1 * (f.log10(p_value_mantissa) + p_value_exponent)\n",
    "\n",
    "\n",
    "def _weighted_r_overall(\n",
    "    chromosome: Column,\n",
    "    study_id: Column,\n",
    "    variant_id: Column,\n",
    "    tag_variant_id: Column,\n",
    "    relative_sample_size: Column,\n",
    "    r: Column,\n",
    ") -> Column:\n",
    "    \"\"\"Aggregation of weighted R information using ancestry proportions.\n",
    "\n",
    "    Args:\n",
    "        chromosome (Column): Chromosome\n",
    "        study_id (Column): Study identifier\n",
    "        variant_id (Column): Variant identifier\n",
    "        tag_variant_id (Column): Tag variant identifier\n",
    "        relative_sample_size (Column): Relative sample size\n",
    "        r (Column): Correlation\n",
    "\n",
    "    Returns:\n",
    "        Column: Estimates weighted R information\n",
    "    \"\"\"\n",
    "    pseudo_r = f.when(r >= 1, 0.9999995).otherwise(r)\n",
    "    zscore_overall = f.sum(f.atan(pseudo_r) * relative_sample_size).over(\n",
    "        Window.partitionBy(chromosome, study_id, variant_id, tag_variant_id)\n",
    "    )\n",
    "    return f.round(f.tan(zscore_overall), 6)\n",
    "\n",
    "\n",
    "@f.udf(t.DoubleType())\n",
    "def _norm_sf(mu: float, std: float, neglog_p: float):\n",
    "    \"\"\"Returns the survival function of the normal distribution for the p-value.\n",
    "\n",
    "    Args:\n",
    "        mu (float): mean\n",
    "        std (float): standard deviation\n",
    "        neglog_p (float): negative log p-value\n",
    "\n",
    "    Returns:\n",
    "        float: survival function\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [{\"mu\": 0, \"neglog_p\": 0, \"std\": 1}, {\"mu\": 1, \"neglog_p\": 10, \"std\": 10}]\n",
    "        >>> spark.createDataFrame(d).withColumn(\"norm_sf\", _norm_sf(f.col(\"mu\"), f.col(\"std\"), f.col(\"neglog_p\"))).show()\n",
    "        +---+--------+---+-------------------+\n",
    "        | mu|neglog_p|std|            norm_sf|\n",
    "        +---+--------+---+-------------------+\n",
    "        |  0|       0|  1|                1.0|\n",
    "        |  1|      10| 10|0.36812025069351895|\n",
    "        +---+--------+---+-------------------+\n",
    "        <BLANKLINE>\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(norm(mu, std).sf(neglog_p) * 2)\n",
    "    except TypeError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _pics_posterior_probability(\n",
    "    pics_mu: Column,\n",
    "    pics_std: Column,\n",
    "    neglog_p: Column,\n",
    "    chromosome: Column,\n",
    "    study_id: Column,\n",
    "    variant_id: Column,\n",
    ") -> Column:\n",
    "    \"\"\"Compute the PICS posterior probability.\n",
    "\n",
    "    Args:\n",
    "        pics_mu (Column): PICS mu\n",
    "        pics_std (Column): PICS standard deviation\n",
    "        neglog_p (Column): Negative log p-value\n",
    "        chromosome (Column): Chromosome column\n",
    "        study_id (Column): Study ID column\n",
    "        variant_id (Column): Variant ID column\n",
    "\n",
    "    Returns:\n",
    "        Column: PICS posterior probability\n",
    "    \"\"\"\n",
    "    pics_relative_prob = f.when(pics_std == 0, 1.0).otherwise(\n",
    "        _norm_sf(pics_mu, pics_std, neglog_p)\n",
    "    )\n",
    "    w_lead = Window.partitionBy(chromosome, study_id, variant_id)\n",
    "    pics_relative_prob_sum = f.sum(pics_relative_prob).over(w_lead)\n",
    "    return pics_relative_prob / pics_relative_prob_sum\n",
    "\n",
    "\n",
    "def _is_in_credset(\n",
    "    chromosome: Column,\n",
    "    study_id: Column,\n",
    "    variant_id: Column,\n",
    "    pics_postprob: Column,\n",
    "    credset_probability: float,\n",
    ") -> Column:\n",
    "    \"\"\"Check whether a variant is in the XX% credible set.\n",
    "\n",
    "    Args:\n",
    "        chromosome (Column): Chromosome column\n",
    "        study_id (Column): Study ID column\n",
    "        variant_id (Column): Variant ID column\n",
    "        pics_postprob (Column): PICS posterior probability column\n",
    "        credset_probability (float): Credible set probability\n",
    "\n",
    "    Returns:\n",
    "        Column: Whether the variant is in the credible set\n",
    "    \"\"\"\n",
    "    w_cumlead = (\n",
    "        Window.partitionBy(chromosome, study_id, variant_id)\n",
    "        .orderBy(f.desc(pics_postprob))\n",
    "        .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    )\n",
    "    pics_postprob_cumsum = f.sum(pics_postprob).over(w_cumlead)\n",
    "    w_credset = Window.partitionBy(chromosome, study_id, variant_id).orderBy(\n",
    "        pics_postprob_cumsum\n",
    "    )\n",
    "    return f.when(\n",
    "        f.lag(pics_postprob_cumsum, 1).over(w_credset) >= credset_probability, False\n",
    "    ).otherwise(True)\n",
    "\n",
    "\n",
    "k = 6.3\n",
    "\n",
    "# (\n",
    "#     ld_data\n",
    "#     .filter(\n",
    "#         (f.col('studyId') =='GCST000175') & \n",
    "#         (f.col('variantId') =='1_184051811_G_A') &\n",
    "#         (f.col('tagVariantId') =='1_184041593_C_A')\n",
    "#     )\n",
    "#     # .distinct()\n",
    "#     .select(\"chromosome\", 'variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r', \"pValueMantissa\", \"pValueExponent\")\n",
    "#     .withColumn(\n",
    "#         \"R_overall\",\n",
    "#         _weighted_r_overall(\n",
    "#             f.col(\"chromosome\"),\n",
    "#             f.col(\"studyId\"),\n",
    "#             f.col(\"variantId\"),\n",
    "#             f.col(\"tagVariantId\"),\n",
    "#             f.col(\"relativeSampleSize\"),\n",
    "#             f.col(\"r\"),\n",
    "#         ),\n",
    "#     )\n",
    "#     .withColumn(\n",
    "#         \"pics_mu\",\n",
    "#         _pics_mu(\n",
    "#             _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "#             f.col(\"R_overall\"),\n",
    "#         ),\n",
    "#     )\n",
    "#     .withColumn(\n",
    "#         \"pics_std\",\n",
    "#         _pics_standard_deviation(\n",
    "#             _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "#             f.col(\"R_overall\"),\n",
    "#             k,\n",
    "#         ),\n",
    "#     )\n",
    "#     .withColumn(\n",
    "#         \"pics_postprob\",\n",
    "#         _pics_posterior_probability(\n",
    "#             f.col(\"pics_mu\"),\n",
    "#             f.col(\"pics_std\"),\n",
    "#             _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "#             f.col(\"chromosome\"),\n",
    "#             f.col(\"studyId\"),\n",
    "#             f.col(\"variantId\"),\n",
    "#         ),\n",
    "#     )\n",
    "#     .withColumn(\n",
    "#         \"pics_95_perc_credset\",\n",
    "#         _is_in_credset(\n",
    "#             f.col(\"chromosome\"),\n",
    "#             f.col(\"studyId\"),\n",
    "#             f.col(\"variantId\"),\n",
    "#             f.col(\"pics_postprob\"),\n",
    "#             0.95,\n",
    "#         ),\n",
    "#     )\n",
    "#     .withColumn(\n",
    "#         \"pics_99_perc_credset\",\n",
    "#         _is_in_credset(\n",
    "#             f.col(\"chromosome\"),\n",
    "#             f.col(\"studyId\"),\n",
    "#             f.col(\"variantId\"),\n",
    "#             f.col(\"pics_postprob\"),\n",
    "#             0.99,\n",
    "#         ),\n",
    "#     )\n",
    "#     .show() \n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping PICS again\n",
    "**Input:**\n",
    "- associations: DataFrame,\n",
    "- studies: DataFrame,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52676571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# studies = spark.read.parquet()\n",
    "ld_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_data = ld_data.select(\"chromosome\", 'variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r', \"pValueMantissa\", \"pValueExponent\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    ld_data\n",
    "    # .distinct()\n",
    "    .select(\"chromosome\", 'variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r', \"pValueMantissa\", \"pValueExponent\")\n",
    "    .distinct()\n",
    "    .withColumn(\n",
    "        \"R_overall\",\n",
    "        _weighted_r_overall(\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "            f.col(\"tagVariantId\"),\n",
    "            f.col(\"relativeSampleSize\"),\n",
    "            f.col(\"r\"),\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_mu\",\n",
    "        _pics_mu(\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"R_overall\"),\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_std\",\n",
    "        _pics_standard_deviation(\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"R_overall\"),\n",
    "            k,\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_postprob\",\n",
    "        _pics_posterior_probability(\n",
    "            f.col(\"pics_mu\"),\n",
    "            f.col(\"pics_std\"),\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_95_perc_credset\",\n",
    "        _is_in_credset(\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "            f.col(\"pics_postprob\"),\n",
    "            0.95,\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_99_perc_credset\",\n",
    "        _is_in_credset(\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "            f.col(\"pics_postprob\"),\n",
    "            0.99,\n",
    "        ),\n",
    "    )\n",
    "    .write.mode('overwrite').parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set_update')\n",
    ")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------\n",
      " chromosome          | 11                                           \n",
      " position            | 99622442                                     \n",
      " referenceAllele     | C                                            \n",
      " alternateAllele     | G                                            \n",
      " variantId           | 11_99622442_C_G                              \n",
      " studyId             | GCST000109                                   \n",
      " pValueMantissa      | 9.0                                          \n",
      " pValueExponent      | -6                                           \n",
      " beta                | null                                         \n",
      " beta_ci_lower       | null                                         \n",
      " beta_ci_upper       | null                                         \n",
      " odds_ratio          | null                                         \n",
      " odds_ratio_ci_lower | null                                         \n",
      " odds_ratio_ci_upper | null                                         \n",
      " qualityControl      | [Subsignificant p-value, Palindrome alleles] \n",
      "-RECORD 1-----------------------------------------------------------\n",
      " chromosome          | 12                                           \n",
      " position            | 54705212                                     \n",
      " referenceAllele     | T                                            \n",
      " alternateAllele     | A                                            \n",
      " variantId           | 12_54705212_T_A                              \n",
      " studyId             | GCST000167                                   \n",
      " pValueMantissa      | 2.0                                          \n",
      " pValueExponent      | -7                                           \n",
      " beta                | null                                         \n",
      " beta_ci_lower       | null                                         \n",
      " beta_ci_upper       | null                                         \n",
      " odds_ratio          | null                                         \n",
      " odds_ratio_ci_lower | null                                         \n",
      " odds_ratio_ci_upper | null                                         \n",
      " qualityControl      | [Subsignificant p-value, Palindrome alleles] \n",
      "-RECORD 2-----------------------------------------------------------\n",
      " chromosome          | 2                                            \n",
      " position            | 170876715                                    \n",
      " referenceAllele     | G                                            \n",
      " alternateAllele     | C                                            \n",
      " variantId           | 2_170876715_G_C                              \n",
      " studyId             | GCST000227                                   \n",
      " pValueMantissa      | 3.0                                          \n",
      " pValueExponent      | -6                                           \n",
      " beta                | null                                         \n",
      " beta_ci_lower       | null                                         \n",
      " beta_ci_upper       | null                                         \n",
      " odds_ratio          | null                                         \n",
      " odds_ratio_ci_lower | null                                         \n",
      " odds_ratio_ci_upper | null                                         \n",
      " qualityControl      | [Subsignificant p-value, Palindrome alleles] \n",
      "-RECORD 3-----------------------------------------------------------\n",
      " chromosome          | 16                                           \n",
      " position            | 6860384                                      \n",
      " referenceAllele     | A                                            \n",
      " alternateAllele     | T                                            \n",
      " variantId           | 16_6860384_A_T                               \n",
      " studyId             | GCST000253                                   \n",
      " pValueMantissa      | 9.0                                          \n",
      " pValueExponent      | -6                                           \n",
      " beta                | null                                         \n",
      " beta_ci_lower       | null                                         \n",
      " beta_ci_upper       | null                                         \n",
      " odds_ratio          | null                                         \n",
      " odds_ratio_ci_lower | null                                         \n",
      " odds_ratio_ci_upper | null                                         \n",
      " qualityControl      | [Subsignificant p-value, Palindrome alleles] \n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assoc_columns = [\n",
    "    \"chromosome\",\n",
    "    \"position\",\n",
    "    \"referenceAllele\",\n",
    "    \"alternateAllele\",\n",
    "    \"variantId\",\n",
    "    \"studyId\",\n",
    "    \"pValueMantissa\",\n",
    "    \"pValueExponent\",\n",
    "    \"beta\",\n",
    "    \"beta_ci_lower\",\n",
    "    \"beta_ci_upper\",\n",
    "    \"odds_ratio\",\n",
    "    \"odds_ratio_ci_lower\",\n",
    "    \"odds_ratio_ci_upper\",\n",
    "    \"qualityControl\",\n",
    "]\n",
    "# studies = etl.spark.read.parquet(cfg.etl.gwas_ingest.outputs.gwas_catalog_studies)\n",
    "\n",
    "\n",
    "spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/gwas_catalog_associations').select(*assoc_columns).filter(f.size(f.col('qualityControl'))>1).show(4, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/15 11:05:20 WARN org.apache.spark.sql.execution.CacheManager: Asked to cache already cached data.\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+--------+---------------+---------------+--------------+--------------+------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|chromosome|     variantId|     studyId|position|referenceAllele|alternateAllele|pValueMantissa|pValueExponent|  beta|       beta_ci_lower|       beta_ci_upper|odds_ratio|odds_ratio_ci_lower|odds_ratio_ci_upper|      qualityControl|sampleSize|tagVariantId|R_overall|pics_mu|pics_std|pics_postprob|pics_95_perc_credset|pics_99_perc_credset|\n",
      "+----------+--------------+------------+--------+---------------+---------------+--------------+--------------+------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|      null|          null|  GCST000333|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|    2521.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST000402|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|    1177.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|    rs10458787|  GCST000642|    null|           null|           null|           1.0|            -6|  0.09| 0.05393846193438052| 0.12606153806561948|      null|               null|               null|[Subsignificant p...|   23072.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST000717|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|     758.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST000950|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|    2796.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST001641|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|     499.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null| SNP_A-1841655|  GCST001899|    null|           null|           null|           1.0|           -16|  null|                null|                null|      3.14|  2.396900624611526|  4.113478839615213|[Incomplete genom...|     794.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   kgp14389214|  GCST002337|    null|           null|           null|           2.0|            -7|  null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST002583|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|     372.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|chr1:244216257|  GCST002927|    null|           null|           null|           9.0|            -6| -1.51| -2.1765913153360557| -0.8434086846639443|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|chr22:49251399|  GCST002927|    null|           null|           null|           6.0|            -6| -1.03| -1.4760067275665087| -0.5839932724334913|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null| chr1:59088629|  GCST002928|    null|           null|           null|           8.0|            -6|  1.15|  0.6452055427449034|  1.6547944572550963|      null|               null|               null|[Subsignificant p...|   26572.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null| chr8:96524590|  GCST002934|    null|           null|           null|           3.0|            -6| 0.262| 0.15205784285082652|  0.3719421571491735|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|     rs7601312|  GCST003048|    null|           null|           null|           4.0|            -8|  null|                null|                null| 1.0638298| 1.0405906978040083|  1.087587891912136|[Incomplete genom...|9.371982E7|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   kgp11333367|  GCST003059|    null|           null|           null|           1.0|            -6|  null|                null|                null|       4.3|  2.396889071753008| 7.7141659236140665|[Subsignificant p...|   11000.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   HLA-C*04:01|  GCST003183|    null|           null|           null|           9.0|           -11| 0.183|  0.1276725681085338| 0.23832743189146618|      null|               null|               null|[Incomplete genom...|  113670.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null| chr3:62052190|GCST003518_4|    null|           null|           null|           5.0|            -6|0.8709|  0.4969584170393273|  1.2448415829606727|      null|               null|               null|[Subsignificant p...|   17480.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null| chr6:29329730|GCST003518_4|    null|           null|           null|           4.0|            -7| 2.414|   1.480585246627706|   3.347414753372294|      null|               null|               null|[Subsignificant p...|   17480.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|          null|  GCST003618|    null|           null|           null|          null|          null|  null|                null|                null|      null|               null|               null|                null|     221.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|Chr1:230305312|  GCST003661|    null|           null|           null|           9.0|            -8|-0.017|-0.02323288724955...|-0.01076711275044...|      null|               null|               null|[Subsignificant p...|   41035.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "+----------+--------------+------------+--------+---------------+---------------+--------------+--------------+------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set').persist()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1467587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(~f.isnan(f.col('pics_postprob')) & f.col('pics_postprob').isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270796"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(f.col('pics_99_perc_credset') | f.col('pics_95_perc_credset')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35685656"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231664"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(f.col('pics_99_perc_credset') | f.col('pics_95_perc_credset')).select(f.col('variantId')).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17095414"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(f.col('tagVariantId').isNotNull()).select(f.col('variantId'), 'tagVariantId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:=====================================================>(197 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " pValueMantissa       | 2.0                \n",
      " chromosome           | 1                  \n",
      " pValueExponent       | -12                \n",
      " studyId              | GCST000289         \n",
      " variantId            | 1_62465961_C_A     \n",
      " tagVariantId         | 1_62664760_C_T     \n",
      " R_overall            | -0.946715          \n",
      " pics_mu              | 10.485427553848778 \n",
      " pics_std             | 0.9298549512727865 \n",
      " pics_postprob        | NaN                \n",
      " pics_95_perc_credset | false              \n",
      " pics_99_perc_credset | false              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test = (\n",
    "    df\n",
    "    .filter((f.col('studyId')=='GCST000263') & (f.col(\"variantId\")==\"1_10293054_T_C\"))\n",
    "    .select('pValueMantissa','chromosome', 'pValueExponent', 'studyId', 'variantId', 'tagVariantId', 'R_overall','pics_mu', 'pics_std', 'pics_postprob', 'pics_95_perc_credset', 'pics_99_perc_credset')\n",
    "    .distinct()\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "test.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " chromosome           | 1                  \n",
      " variantId            | 1_19816373_C_T     \n",
      " studyId              | GCST000311         \n",
      " position             | 19816373           \n",
      " referenceAllele      | C                  \n",
      " alternateAllele      | T                  \n",
      " pValueMantissa       | 7.0                \n",
      " pValueExponent       | -9                 \n",
      " beta                 | null               \n",
      " beta_ci_lower        | null               \n",
      " beta_ci_upper        | null               \n",
      " odds_ratio           | null               \n",
      " odds_ratio_ci_lower  | null               \n",
      " odds_ratio_ci_upper  | null               \n",
      " qualityControl       | []                 \n",
      " sampleSize           | 42300.0            \n",
      " tagVariantId         | 1_19816373_C_T     \n",
      " R_overall            | 1.0                \n",
      " pics_mu              | 8.154901959985743  \n",
      " pics_std             | 0.0                \n",
      " pics_postprob        | 0.1852548353298165 \n",
      " pics_95_perc_credset | true               \n",
      " pics_99_perc_credset | true               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(f.col('pics_95_perc_credset') & (f.col('pics_postprob')>0) & (~f.isnan(f.col('pics_postprob')))).show(1, False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " pValueMantissa             | 1.0                \n",
      " chromosome                 | 1                  \n",
      " pValueExponent             | -8                 \n",
      " studyId                    | GCST003496         \n",
      " variantId                  | 1_43610348_G_A     \n",
      " tagVariantId               | 1_43649351_A_G     \n",
      " R_overall                  | 0.72293            \n",
      " pics_mu_pocok              | 4.1810222792       \n",
      " pics_std_pocok             | 1.3194613210926271 \n",
      " pics_postprob_pocok        | 1.0                \n",
      " pics_95_perc_credset_pocok | true               \n",
      " pics_99_perc_credset_pocok | true               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pocok_notna = (\n",
    "    test\n",
    "    # .distinct()\n",
    "    # .select(\"chromosome\", 'variantId','gnomadPopulation','studyId','sampleSize','relativeSampleSize', 'tagVariantId', 'r', \"pValueMantissa\", \"pValueExponent\")\n",
    "    .drop('pics_mu', 'pics_std', 'pics_postprob', 'pics_95_perc_credset', 'pics_99_perc_credset')\n",
    "    # .distinct()\n",
    "    # .withColumn(\n",
    "    #     \"R_overall\",\n",
    "    #     _weighted_r_overall(\n",
    "    #         f.col(\"chromosome\"),\n",
    "    #         f.col(\"studyId\"),\n",
    "    #         f.col(\"variantId\"),\n",
    "    #         f.col(\"tagVariantId\"),\n",
    "    #         f.col(\"relativeSampleSize\"),\n",
    "    #         f.col(\"r\"),\n",
    "    #     ),\n",
    "    # )\n",
    "    .withColumn(\n",
    "        \"pics_mu_recal\",\n",
    "        _pics_mu(\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"R_overall\"),\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_std_recal\",\n",
    "        _pics_standard_deviation(\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"R_overall\"),\n",
    "            k,\n",
    "        ),\n",
    "    )\n",
    "    .filter(~f.isnan(f.col('pics_std_recal')))\n",
    "    .withColumn(\n",
    "        \"pics_postprob_recal\",\n",
    "        _pics_posterior_probability(\n",
    "            f.col(\"pics_mu_recal\"),\n",
    "            f.col(\"pics_std_recal\"),\n",
    "            _neglog_p(f.col(\"pValueMantissa\"), f.col(\"pValueExponent\")),\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_95_perc_credset_recal\",\n",
    "        _is_in_credset(\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "            f.col(\"pics_postprob_recal\"),\n",
    "            0.95,\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"pics_99_perc_credset_recal\",\n",
    "        _is_in_credset(\n",
    "            f.col(\"chromosome\"),\n",
    "            f.col(\"studyId\"),\n",
    "            f.col(\"variantId\"),\n",
    "            f.col(\"pics_postprob_recal\"),\n",
    "            0.99,\n",
    "        ),\n",
    "    )\n",
    "    # .write.mode('overwrite').parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set_update')\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "pocok.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/15 16:29:49 WARN org.apache.spark.sql.execution.CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "x = (\n",
    "    test.drop('pValueMantissa','chromosome', 'pValueExponent')\n",
    "    .join(\n",
    "        pocok.drop('pValueMantissa','chromosome', 'pValueExponent', 'R_overall'),\n",
    "        on=['studyId', 'variantId', 'tagVariantId'],\n",
    "        how='left'\n",
    "    )\n",
    "    # .filter(f.col('pics_postprob') != f.col('pics_postprob_pocok'))\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "colnames = x.columns\n",
    "colnames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " R_overall                  | -0.946715          \n",
      " pics_95_perc_credset       | false              \n",
      " pics_95_perc_credset_recal | true               \n",
      " pics_99_perc_credset       | false              \n",
      " pics_99_perc_credset_recal | true               \n",
      " pics_mu                    | 10.485427553848778 \n",
      " pics_mu_recal              | 10.485427553848778 \n",
      " pics_postprob              | NaN                \n",
      " pics_postprob_recal        | 1.0                \n",
      " pics_std                   | 0.9298549512727865 \n",
      " pics_std_recal             | 0.9237525075131878 \n",
      " studyId                    | GCST000289         \n",
      " tagVariantId               | 1_62664760_C_T     \n",
      " variantId                  | 1_62465961_C_A     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.select(*[\n",
    "    f.col(c).alias(c.replace('pocok', 'recal')) for c in colnames\n",
    "]).show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|chromosome|        variantId|      studyId|position|referenceAllele|alternateAllele|pValueMantissa|pValueExponent|   beta|       beta_ci_lower|       beta_ci_upper|odds_ratio|odds_ratio_ci_lower|odds_ratio_ci_upper|      qualityControl|sampleSize|tagVariantId|R_overall|pics_mu|pics_std|pics_postprob|pics_95_perc_credset|pics_99_perc_credset|\n",
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|      null|             null|   GCST000009|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     920.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST000009|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     740.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs10889677|   GCST000311|    null|           null|           null|           1.0|            -8|   null|                null|                null|      null|               null|               null|[Incomplete genom...|   42300.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST000526|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     229.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs11713158| GCST001428_5|    null|           null|           null|           9.0|            -7|   5.04|   3.029060633271225|   7.050939366728775|      null|               null|               null|[Subsignificant p...|    3936.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|     snp2-1167588|   GCST001691|    null|           null|           null|           7.0|            -8|   null|                null|                null|      null|               null|               null|[Subsignificant p...|    4075.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs11712263|GCST001762_44|    null|           null|           null|           8.0|            -6|   0.03|0.016831448941171397|  0.0431685510588286|      null|               null|               null|[Subsignificant p...|    7335.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|      kgp11394149|   GCST002337|    null|           null|           null|           2.0|            -7|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|        kgp172957|   GCST002337|    null|           null|           null|           7.0|            -6|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|      kgp18356648|   GCST002337|    null|           null|           null|           2.0|            -6|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   HLA-DQA1*05:01|   GCST002463|    null|           null|           null|           3.0|            -9|   null|                null|                null|      1.89| 1.5314735633423446|  2.332459459635801|[Incomplete genom...|   79075.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr6:144226924|   GCST002594|    null|           null|           null|           3.0|            -6|-0.9204| -1.3066242803057224| -0.5341757196942775|      null|               null|               null|[Subsignificant p...|   94140.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002600|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     342.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002600|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     425.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002683|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|    3889.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|    chr1:14929571|   GCST002927|    null|           null|           null|           8.0|            -6| -0.294|-0.42305180037652035|-0.16494819962347965|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr1:227555822|   GCST002927|    null|           null|           null|           2.0|            -6|  -1.32| -1.8642813241066774| -0.7757186758933228|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr17:59505389|   GCST002932|    null|           null|           null|           6.0|            -6|   1.14|  0.6463614859943496|  1.6336385140056502|      null|               null|               null|[Subsignificant p...|   35113.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr5:116971885|   GCST002932|    null|           null|           null|           2.0|            -6|   1.23|  0.7228287661733235|  1.7371712338266765|      null|               null|               null|[Subsignificant p...|   35113.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|chr11:102118158-A|   GCST002992|    null|           null|           null|           3.0|            -8|   null|                null|                null|       4.9|  2.793022875169206|  8.596420821847165|[Incomplete genom...| 1665216.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.unpersist()\n",
    "df = spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set').persist()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1467587"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(~f.isnan(f.col('pics_postprob')) & f.col('pics_postprob').isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|chromosome|        variantId|      studyId|position|referenceAllele|alternateAllele|pValueMantissa|pValueExponent|   beta|       beta_ci_lower|       beta_ci_upper|odds_ratio|odds_ratio_ci_lower|odds_ratio_ci_upper|      qualityControl|sampleSize|tagVariantId|R_overall|pics_mu|pics_std|pics_postprob|pics_95_perc_credset|pics_99_perc_credset|\n",
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "|      null|             null|   GCST000009|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     920.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST000009|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     740.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs10889677|   GCST000311|    null|           null|           null|           1.0|            -8|   null|                null|                null|      null|               null|               null|[Incomplete genom...|   42300.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST000526|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     229.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs11713158| GCST001428_5|    null|           null|           null|           9.0|            -7|   5.04|   3.029060633271225|   7.050939366728775|      null|               null|               null|[Subsignificant p...|    3936.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|     snp2-1167588|   GCST001691|    null|           null|           null|           7.0|            -8|   null|                null|                null|      null|               null|               null|[Subsignificant p...|    4075.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|       rs11712263|GCST001762_44|    null|           null|           null|           8.0|            -6|   0.03|0.016831448941171397|  0.0431685510588286|      null|               null|               null|[Subsignificant p...|    7335.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|      kgp11394149|   GCST002337|    null|           null|           null|           2.0|            -7|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|        kgp172957|   GCST002337|    null|           null|           null|           7.0|            -6|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|      kgp18356648|   GCST002337|    null|           null|           null|           2.0|            -6|   null|                null|                null|      null|               null|               null|[Subsignificant p...|   87500.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   HLA-DQA1*05:01|   GCST002463|    null|           null|           null|           3.0|            -9|   null|                null|                null|      1.89| 1.5314735633423446|  2.332459459635801|[Incomplete genom...|   79075.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr6:144226924|   GCST002594|    null|           null|           null|           3.0|            -6|-0.9204| -1.3066242803057224| -0.5341757196942775|      null|               null|               null|[Subsignificant p...|   94140.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002600|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     342.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002600|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|     425.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|             null|   GCST002683|    null|           null|           null|          null|          null|   null|                null|                null|      null|               null|               null|                null|    3889.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|    chr1:14929571|   GCST002927|    null|           null|           null|           8.0|            -6| -0.294|-0.42305180037652035|-0.16494819962347965|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr1:227555822|   GCST002927|    null|           null|           null|           2.0|            -6|  -1.32| -1.8642813241066774| -0.7757186758933228|      null|               null|               null|[Subsignificant p...|   22776.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr17:59505389|   GCST002932|    null|           null|           null|           6.0|            -6|   1.14|  0.6463614859943496|  1.6336385140056502|      null|               null|               null|[Subsignificant p...|   35113.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|   chr5:116971885|   GCST002932|    null|           null|           null|           2.0|            -6|   1.23|  0.7228287661733235|  1.7371712338266765|      null|               null|               null|[Subsignificant p...|   35113.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "|      null|chr11:102118158-A|   GCST002992|    null|           null|           null|           3.0|            -8|   null|                null|                null|       4.9|  2.793022875169206|  8.596420821847165|[Incomplete genom...| 1665216.0|        null|     null|   null|    null|         null|                true|                true|\n",
      "+----------+-----------------+-------------+--------+---------------+---------------+--------------+--------------+-------+--------------------+--------------------+----------+-------------------+-------------------+--------------------+----------+------------+---------+-------+--------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.parquet('gs://genetics_etl_python_playground/XX.XX/output/python_etl/parquet/pics_credible_set').persist()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35626446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35475806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(~f.isnan(f.col('pics_postprob')) & f.col('pics_postprob').isNotNull())\n",
    "    # .show(1, False, True)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30235987"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(~f.isnan(f.col('pics_postprob')) & f.col('pics_postprob').isNotNull())\n",
    "    .select('studyId', 'variantId', 'tagVariantId')\n",
    "    .distinct()\n",
    "    # .show(1, False, True)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18686423"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(~f.isnan(f.col('pics_postprob')) & f.col('pics_postprob').isNotNull() & f.col('pics_99_perc_credset'))\n",
    "    .select('studyId', 'variantId', 'tagVariantId')\n",
    "    .distinct()\n",
    "    # .show(1, False, True)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def _pval_to_zscore(pval_col: Column) -> Column:\n",
    "    \"\"\"Convert p-value column to z-score column.\n",
    "\n",
    "    Args:\n",
    "        pval_col (Column): pvalues to be casted to floats.\n",
    "\n",
    "    Returns:\n",
    "        Column: p-values transformed to z-scores\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [{\"id\": \"t1\", \"pval\": \"1\"}, {\"id\": \"t2\", \"pval\": \"0.9\"}, {\"id\": \"t3\", \"pval\": \"0.05\"}, {\"id\": \"t4\", \"pval\": \"1e-300\"}, {\"id\": \"t5\", \"pval\": \"1e-1000\"}, {\"id\": \"t6\", \"pval\": \"NA\"}]\n",
    "        >>> df = spark.createDataFrame(d)\n",
    "        >>> df.withColumn(\"zscore\", _pval_to_zscore(f.col(\"pval\"))).show()\n",
    "        +---+-------+----------+\n",
    "        | id|   pval|    zscore|\n",
    "        +---+-------+----------+\n",
    "        | t1|      1|       0.0|\n",
    "        | t2|    0.9|0.12566137|\n",
    "        | t3|   0.05|  1.959964|\n",
    "        | t4| 1e-300| 37.537838|\n",
    "        | t5|1e-1000| 37.537838|\n",
    "        | t6|     NA|      null|\n",
    "        +---+-------+----------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    pvalue_float = pval_col.cast(t.FloatType())\n",
    "    pvalue_nozero = f.when(pvalue_float == 0, sys.float_info.min).otherwise(\n",
    "        pvalue_float\n",
    "    )\n",
    "    return f.udf(\n",
    "        lambda pv: float(abs(norm.ppf((float(pv)) / 2))) if pv else None,\n",
    "        t.FloatType(),\n",
    "    )(pvalue_nozero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+\n",
      "| id|   pval|    zscore|\n",
      "+---+-------+----------+\n",
      "| t1|      1|       0.0|\n",
      "| t2|    0.9|0.12566137|\n",
      "| t3|   0.05|  1.959964|\n",
      "| t4| 1e-300| 37.537838|\n",
      "| t5|1e-1000| 37.537838|\n",
      "| t6|     NA|      null|\n",
      "+---+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = [{\"id\": \"t1\", \"pval\": \"1\"}, {\"id\": \"t2\", \"pval\": \"0.9\"}, {\"id\": \"t3\", \"pval\": \"0.05\"}, {\"id\": \"t4\", \"pval\": \"1e-300\"}, {\"id\": \"t5\", \"pval\": \"1e-1000\"}, {\"id\": \"t6\", \"pval\": \"NA\"}]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"zscore\", _pval_to_zscore(f.col(\"pval\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|allele|revcom_allele|\n",
      "+------+-------------+\n",
      "|     A|            T|\n",
      "|     T|            A|\n",
      "|     G|            C|\n",
      "|     C|            G|\n",
      "|    AC|           GT|\n",
      "|GTaatc|       GATTAC|\n",
      "|     ?|            ?|\n",
      "|  null|         null|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _get_reverse_complement(allele_col: Column) -> Column:\n",
    "    \"\"\"A function to return the reverse complement of an allele column.\n",
    "\n",
    "    It takes a string and returns the reverse complement of that string if it's a DNA sequence,\n",
    "    otherwise it returns the original string\n",
    "\n",
    "    Args:\n",
    "        allele_col (Column): The column containing the allele to reverse complement.\n",
    "\n",
    "    Returns:\n",
    "        A column that is the reverse complement of the allele column.\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [{\"allele\": 'A'}, {\"allele\": 'T'},{\"allele\": 'G'}, {\"allele\": 'C'},{\"allele\": 'AC'}, {\"allele\": 'GT'},{\"allele\": '?'}, {\"allele\": None}]\n",
    "        >>> df = spark.createDataFrame(d)\n",
    "        >>> df.withColumn(\"revcom_allele\", _get_reverse_complement(f.col(\"allele\"))).show()\n",
    "        +------+-------------+\n",
    "        |allele|revcom_allele|\n",
    "        +------+-------------+\n",
    "        |     A|            T|\n",
    "        |     T|            A|\n",
    "        |     G|            C|\n",
    "        |     C|            G|\n",
    "        |    AC|           GT|\n",
    "        |    GT|           AC|\n",
    "        |     ?|            ?|\n",
    "        |  null|         null|\n",
    "        +------+-------------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    allele_col = f.upper(allele_col)\n",
    "    return f.when(\n",
    "        allele_col.rlike(\"[ACTG]+\"),\n",
    "        f.reverse(f.translate(allele_col, \"ACTG\", \"TGAC\")),\n",
    "    ).otherwise(allele_col)\n",
    "\n",
    "\n",
    "d = [{\"allele\": 'A'}, {\"allele\": 'T'},{\"allele\": 'G'}, {\"allele\": 'C'},{\"allele\": 'AC'}, {\"allele\": 'GTaatc'},{\"allele\": '?'}, {\"allele\": None}]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"revcom_allele\", _get_reverse_complement(f.col(\"allele\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+----+\n",
      "| confidence_interval|effect_size|needs_harmonization|beta|\n",
      "+--------------------+-----------+-------------------+----+\n",
      "|[0.1-0.9] unit de...|        0.6|               true| 0.6|\n",
      "|[0.1-0.9] unit de...|        0.6|              false|-0.6|\n",
      "|[0.1-0.9] unit in...|        0.6|               true|-0.6|\n",
      "|[0.1-0.9] unit in...|        0.6|              false| 0.6|\n",
      "|           [0.1-0.9]|        0.6|              false|null|\n",
      "+--------------------+-----------+-------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _harmonize_beta(\n",
    "    effect_size: Column, confidence_interval: Column, needs_harmonization: Column\n",
    ") -> Column:\n",
    "    \"\"\"A function to harmonize beta.\n",
    "\n",
    "    If the confidence interval contains the word \"increase\" and the effect size needs to be harmonized,\n",
    "    then multiply the effect size by -1\n",
    "\n",
    "    Args:\n",
    "        effect_size (Column): The effect size column from the dataframe\n",
    "        confidence_interval (Column): The confidence interval of the effect size.\n",
    "        needs_harmonization (Column): a boolean column that indicates whether the effect size needs to be flipped\n",
    "\n",
    "    Returns:\n",
    "        A column of the harmonized beta values.\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [\n",
    "        >>>     {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit decrease', 'needs_harmonization': True},\n",
    "        >>>     {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit decrease', 'needs_harmonization': False},\n",
    "        >>>     {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit increase', 'needs_harmonization': True},\n",
    "        >>>     {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit increase', 'needs_harmonization': False},\n",
    "        >>>     {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9]', 'needs_harmonization': False},\n",
    "        >>> ]\n",
    "        >>> df = spark.createDataFrame(d)\n",
    "        >>> df.withColumn(\"beta\", _harmonize_beta(f.col(\"effect_size\"), f.col('confidence_interval'), f.col('needs_harmonization'))).show()\n",
    "        +--------------------+-----------+-------------------+----+\n",
    "        | confidence_interval|effect_size|needs_harmonization|beta|\n",
    "        +--------------------+-----------+-------------------+----+\n",
    "        |[0.1-0.9] unit de...|        0.6|               true| 0.6|\n",
    "        |[0.1-0.9] unit de...|        0.6|              false|-0.6|\n",
    "        |[0.1-0.9] unit in...|        0.6|               true|-0.6|\n",
    "        |[0.1-0.9] unit in...|        0.6|              false| 0.6|\n",
    "        |           [0.1-0.9]|        0.6|              false|null|\n",
    "        +--------------------+-----------+-------------------+----+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    # The effect is given as beta, if the confidence interval contains 'increase' or 'decrease'\n",
    "    beta = f.when(\n",
    "        confidence_interval.contains(\"increase\")\n",
    "        | confidence_interval.contains(\"decrease\"),\n",
    "        effect_size,\n",
    "    )\n",
    "    # Flipping beta if harmonization is required or effect negated by saying 'decrease'\n",
    "    return f.when(\n",
    "        (confidence_interval.contains(\"increase\") & needs_harmonization)\n",
    "        | (confidence_interval.contains(\"decrease\") & ~needs_harmonization),\n",
    "        beta * -1,\n",
    "    ).otherwise(beta)\n",
    "\n",
    "d = [\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit decrease', 'needs_harmonization': True},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit decrease', 'needs_harmonization': False},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit increase', 'needs_harmonization': True},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit increase', 'needs_harmonization': False},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9]', 'needs_harmonization': False},\n",
    "]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"beta\", _harmonize_beta(f.col(\"effect_size\"), f.col('confidence_interval'), f.col('needs_harmonization'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+----------+\n",
      "| confidence_interval|effect_size|needs_harmonization|odds_ratio|\n",
      "+--------------------+-----------+-------------------+----------+\n",
      "|[0.1-0.9] unit de...|        0.6|               true|      null|\n",
      "|[0.1-0.9] unit de...|        0.6|              false|      null|\n",
      "|[0.1-0.9] unit in...|        0.6|               true|      null|\n",
      "|[0.1-0.9] unit in...|        0.6|              false|      null|\n",
      "|           [0.1-0.9]|        0.6|              false|       0.6|\n",
      "+--------------------+-----------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _harmonize_odds_ratio(\n",
    "    effect_size: Column, confidence_interval: Column, needs_harmonization: Column\n",
    ") -> Column:\n",
    "    \"\"\"Harmonizing odds ratio.\n",
    "\n",
    "    Args:\n",
    "        effect_size (Column): The effect size column from the dataframe\n",
    "        confidence_interval (Column): The confidence interval of the effect size.\n",
    "        needs_harmonization (Column): a boolean column that indicates whether the odds ratio needs to be flipped\n",
    "\n",
    "    Returns:\n",
    "        A column with the odds ratio, or 1/odds_ratio if harmonization required.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # The confidence interval tells if we are not dealing with betas -> OR\n",
    "    odds_ratio = f.when(\n",
    "        ~confidence_interval.contains(\"increase\")\n",
    "        & ~confidence_interval.contains(\"decrease\"),\n",
    "        effect_size,\n",
    "    )\n",
    "\n",
    "    return f.when(needs_harmonization, 1 / odds_ratio).otherwise(odds_ratio)\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"odds_ratio\", _harmonize_odds_ratio(f.col(\"effect_size\"), f.col('confidence_interval'), f.col('needs_harmonization'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------------+------------------+\n",
      "| confidence_interval|effect_size|needs_harmonization|        odds_ratio|\n",
      "+--------------------+-----------+-------------------+------------------+\n",
      "|[0.1-0.9] unit de...|        0.6|               true|              null|\n",
      "|           [0.1-0.9]|        0.6|              false|               0.6|\n",
      "|           [0.1-0.9]|        0.6|               true|1.6666666666666667|\n",
      "+--------------------+-----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = [\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9] unit decrease', 'needs_harmonization': True},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9]', 'needs_harmonization': False},\n",
    "    {\"effect_size\": 0.6, 'confidence_interval': '[0.1-0.9]', 'needs_harmonization': True},\n",
    "]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"odds_ratio\", _harmonize_odds_ratio(f.col(\"effect_size\"), f.col('confidence_interval'), f.col('needs_harmonization'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+------------------------+\n",
      "|beta|direction|zscore|beta_confidence_interval|\n",
      "+----+---------+------+------------------------+\n",
      "| 0.6|    upper|     3|                   0.992|\n",
      "| 0.6|    lower|     3|     0.20800000000000002|\n",
      "| 0.6|something|     3|                    null|\n",
      "|null|    lower|     3|                    null|\n",
      "+----+---------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _calculate_beta_ci(beta: Column, zscore: Column, direction: Column) -> Column:\n",
    "    \"\"\"Calculating confidence intervals for beta values.\n",
    "\n",
    "    Args:\n",
    "        beta (Column): The beta value for the given row\n",
    "        zscore (Column): The z-score of the beta coefficient.\n",
    "        direction (Column): This is the direction of the confidence interval. It can be either \"upper\" or \"lower\".\n",
    "\n",
    "    Returns:\n",
    "        The upper and lower bounds of the confidence interval for the beta coefficient.\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [\n",
    "        ...    {\"beta\": 0.6, 'zscore': 3, 'direction': 'upper'},\n",
    "        ...    {\"beta\": 0.6, 'zscore': 3, 'direction': 'lower'},\n",
    "        ...    {\"beta\": 0.6, 'zscore': 3, 'direction': 'something'},\n",
    "        ...    {\"beta\": None, 'zscore': 3, 'direction': 'lower'},\n",
    "        ... ]\n",
    "        >>> df = spark.createDataFrame(d)\n",
    "        >>> df.withColumn(\"beta\",  _calculate_beta_ci(f.col(\"beta\"), f.col('zscore'), f.col('direction'))).show()\n",
    "        +----+---------+------+------------------------+\n",
    "        |beta|direction|zscore|beta_confidence_interval|\n",
    "        +----+---------+------+------------------------+\n",
    "        | 0.6|    upper|     3|                   0.992|\n",
    "        | 0.6|    lower|     3|     0.20800000000000002|\n",
    "        | 0.6|somethign|     3|                    null|\n",
    "        |null|    lower|     3|                    null|\n",
    "        +----+---------+------+------------------------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    zscore_95 = f.lit(1.96)\n",
    "    return (\n",
    "        f.when(direction == \"upper\", beta + f.abs(zscore_95 * beta) / zscore)\n",
    "        .when(direction == \"lower\", beta - f.abs(zscore_95 * beta) / zscore)\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "d = [\n",
    "    {\"beta\": 0.6, 'zscore': 3, 'direction': 'upper'},\n",
    "    {\"beta\": 0.6, 'zscore': 3, 'direction': 'lower'},\n",
    "    {\"beta\": 0.6, 'zscore': 3, 'direction': 'something'},\n",
    "    {\"beta\": None, 'zscore': 3, 'direction': 'lower'},\n",
    "]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"beta_confidence_interval\", _calculate_beta_ci(f.col(\"beta\"), f.col('zscore'), f.col('direction'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+----------------------+\n",
      "|direction|odds_ratio|zscore|or_confidence_interval|\n",
      "+---------+----------+------+----------------------+\n",
      "|    upper|       0.6|     3|    0.8377075574145849|\n",
      "|    lower|       1.6|     3|    1.1769597039688107|\n",
      "|something|       0.6|     3|                  null|\n",
      "|    lower|      null|     3|                  null|\n",
      "+---------+----------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _calculate_or_ci(odds_ratio: Column, zscore: Column, direction: Column) -> Column:\n",
    "    \"\"\"Calculating confidence intervals for odds-ratio values.\n",
    "\n",
    "    Args:\n",
    "        odds_ratio (Column): The odds ratio of the association between the exposure and outcome.\n",
    "        zscore (Column): The z-score of the confidence interval.\n",
    "        direction (Column): This is either \"upper\" or \"lower\" and determines whether the upper or lower confidence interval is calculated.\n",
    "\n",
    "    Returns:\n",
    "        The upper and lower bounds of the 95% confidence interval for the odds ratio.\n",
    "\n",
    "    Examples:\n",
    "        >>> d = [\n",
    "        ...     {\"odds_ratio\": 0.6, 'zscore': 3, 'direction': 'upper'},\n",
    "        ...     {\"odds_ratio\": 1.6, 'zscore': 3, 'direction': 'lower'},\n",
    "        ...     {\"odds_ratio\": 0.6, 'zscore': 3, 'direction': 'something'},\n",
    "        ...     {\"odds_ratio\": None, 'zscore': 3, 'direction': 'lower'},\n",
    "        ... ]\n",
    "        >>> df = spark.createDataFrame(d)\n",
    "        >>> df.withColumn(\"or_confidence_interval\", _calculate_or_ci(f.col(\"odds_ratio\"), f.col('zscore'), f.col('direction'))).show()\n",
    "        +---------+----------+------+----------------------+\n",
    "        |direction|odds_ratio|zscore|or_confidence_interval|\n",
    "        +---------+----------+------+----------------------+\n",
    "        |    upper|       0.6|     3|    0.8377075574145849|\n",
    "        |    lower|       1.6|     3|    1.1769597039688107|\n",
    "        |something|       0.6|     3|                  null|\n",
    "        |    lower|      null|     3|                  null|\n",
    "        +---------+----------+------+----------------------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    zscore_95 = f.lit(1.96)\n",
    "    odds_ratio_estimate = f.log(odds_ratio)\n",
    "    odds_ratio_se = odds_ratio_estimate / zscore\n",
    "    return f.when(\n",
    "        direction == \"upper\",\n",
    "        f.exp(odds_ratio_estimate + f.abs(zscore_95 * odds_ratio_se)),\n",
    "    ).when(\n",
    "        direction == \"lower\",\n",
    "        f.exp(odds_ratio_estimate - f.abs(zscore_95 * odds_ratio_se)),\n",
    "    )\n",
    "\n",
    "\n",
    "d = [\n",
    "    {\"odds_ratio\": 0.6, 'zscore': 3, 'direction': 'upper'},\n",
    "    {\"odds_ratio\": 1.6, 'zscore': 3, 'direction': 'lower'},\n",
    "    {\"odds_ratio\": 0.6, 'zscore': 3, 'direction': 'something'},\n",
    "    {\"odds_ratio\": None, 'zscore': 3, 'direction': 'lower'},\n",
    "]\n",
    "df = spark.createDataFrame(d)\n",
    "df.withColumn(\"or_confidence_interval\", _calculate_or_ci(f.col(\"odds_ratio\"), f.col('zscore'), f.col('direction'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "|referenceAllele|alternateAllele|riskAllele|pValueMantissa|pValueExponent|effectSize|  confidenceInterval|isBeta|isBetaPositive| isOR|isORPositive|isPalindrome|qualityControl|\n",
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "|              A|              C|         C|             5|           -11|       0.6|[0.013-0.024] uni...|  true|          true|false|       false|       false|            []|\n",
      "|              A|              C|         T|             5|           -11|       0.6|[0.013-0.024] uni...|  true|         false|false|       false|       false|            []|\n",
      "|              A|              T|         A|             5|           -11|       0.6|[0.013-0.024] uni...| false|         false|false|       false|        true|            []|\n",
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    data = [\n",
    "        # Beta, no need to harmonization:\n",
    "        (\n",
    "            \"A\",\n",
    "            \"C\",\n",
    "            \"C\",\n",
    "            5,\n",
    "            -11,\n",
    "            0.6,\n",
    "            \"[0.013-0.024] unit increase\",\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "        ),\n",
    "        # Beta, harmonization required:\n",
    "        (\n",
    "            \"A\",\n",
    "            \"C\",\n",
    "            \"T\",\n",
    "            5,\n",
    "            -11,\n",
    "            0.6,\n",
    "            \"[0.013-0.024] unit increase\",\n",
    "            True,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "        ),\n",
    "        # Beta, effect dropped due to palindromic alleles:\n",
    "        (\n",
    "            \"A\",\n",
    "            \"T\",\n",
    "            \"A\",\n",
    "            5,\n",
    "            -11,\n",
    "            0.6,\n",
    "            \"[0.013-0.024] unit increase\",\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    "    mock_df = (\n",
    "        spark.createDataFrame(\n",
    "            data,\n",
    "            [\n",
    "                \"referenceAllele\",\n",
    "                \"alternateAllele\",\n",
    "                \"riskAllele\",\n",
    "                \"pValueMantissa\",\n",
    "                \"pValueExponent\",\n",
    "                \"effectSize\",\n",
    "                \"confidenceInterval\",\n",
    "                \"isBeta\",\n",
    "                \"isBetaPositive\",\n",
    "                \"isOR\",\n",
    "                \"isORPositive\",\n",
    "                \"isPalindrome\",\n",
    "            ],\n",
    "        )\n",
    "        .withColumn(\"qualityControl\", f.array())\n",
    "        .persist()\n",
    "    )\n",
    "mock_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "|referenceAllele|alternateAllele|riskAllele|pValueMantissa|pValueExponent|effectSize|  confidenceInterval|isBeta|isBetaPositive| isOR|isORPositive|isPalindrome|qualityControl|\n",
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "|              A|              C|         C|             5|           -11|       0.6|[0.013-0.024] uni...|  true|          true|false|       false|       false|            []|\n",
      "|              A|              C|         T|             5|           -11|       0.6|[0.013-0.024] uni...|  true|         false|false|       false|       false|            []|\n",
      "|              A|              T|         A|             5|           -11|       0.6|[0.013-0.024] uni...| false|         false|false|       false|        true|            []|\n",
      "+---------------+---------------+----------+--------------+--------------+----------+--------------------+------+--------------+-----+------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mock_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------+----------------------+\n",
      "|associationId|        gnomad|   gwas|or_confidence_interval|\n",
      "+-------------+--------------+-------+----------------------+\n",
      "|            1|[rs123, rs523]|[rs123]|                  true|\n",
      "|            2|            []|[rs123]|                 false|\n",
      "|            3|[rs123, rs523]|     []|                 false|\n",
      "|            4|            []|     []|                 false|\n",
      "+-------------+--------------+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _check_rsids(gnomad: Column, gwas: Column) -> Column:\n",
    "    \"\"\"If the intersection of the two arrays is greater than 0, return True, otherwise return False.\n",
    "\n",
    "    Args:\n",
    "        gnomad (Column): rsids from gnomad\n",
    "        gwas (Column): rsids from the GWAS Catalog\n",
    "\n",
    "    Returns:\n",
    "        A boolean column that is true if the GnomAD rsIDs can be found in the GWAS rsIDs.\n",
    "    \n",
    "    Examples:\n",
    "        >>> d = [\n",
    "        ...    (1, [\"rs123\", \"rs523\"], [\"rs123\"], True),\n",
    "        ...    (2, [], [\"rs123\"], False),\n",
    "        ...    (2, [\"rs123\", \"rs523\"], [], False),\n",
    "        ... ]\n",
    "        >>> df = spark.createDataFrame(d, ['associationId', 'gnomad', 'gwas', 'isRsIdMatched'])\n",
    "        >>> df.withColumn(\"or_confidence_interval\", _check_rsids(f.col(\"gnomad\"),f.col('gwas'))).show()\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        |associationId|        gnomad|   gwas|isRsIdMatched|or_confidence_interval|\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        |            1|[rs123, rs523]|[rs123]|         true|                  true|\n",
    "        |            2|            []|[rs123]|        false|                 false|\n",
    "        |            2|[rs123, rs523]|     []|        false|                 false|\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    return f.when(f.size(f.array_intersect(gnomad, gwas)) > 0, True).otherwise(False)\n",
    "\n",
    "\n",
    "d = [\n",
    "    (1, [\"rs123\", \"rs523\"], [\"rs123\"]),\n",
    "    (2, [], [\"rs123\"]),\n",
    "    (3, [\"rs123\", \"rs523\"], []),\n",
    "    (4, [], []),\n",
    "]\n",
    "df = spark.createDataFrame(d, ['associationId', 'gnomad', 'gwas'])\n",
    "df.withColumn(\"or_confidence_interval\", _check_rsids(f.col(\"gnomad\"),f.col('gwas'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+---------------+------------+\n",
      "|riskAllele|referenceAllele|alternateAllele|isConcordant|\n",
      "+----------+---------------+---------------+------------+\n",
      "|         A|              A|              G|        true|\n",
      "|         A|              T|              G|        true|\n",
      "|         A|              C|              G|       false|\n",
      "|         A|              A|              ?|        true|\n",
      "|      null|           null|              A|        true|\n",
      "+----------+---------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _check_concordance(\n",
    "    risk_allele: Column, reference_allele: Column, alternate_allele: Column\n",
    ") -> Column:\n",
    "    \"\"\"A function to check if the risk allele is concordant with the alt or ref allele.\n",
    "\n",
    "    If the risk allele is the same as the reference or alternate allele, or if the reverse complement of\n",
    "    the risk allele is the same as the reference or alternate allele, then the allele is concordant.\n",
    "    If no mapping is available (ref/alt is null), the function returns True.\n",
    "\n",
    "    Args:\n",
    "        risk_allele (Column): The allele that is associated with the risk of the disease.\n",
    "        reference_allele (Column): The reference allele from the GWAS catalog\n",
    "        alternate_allele (Column): The alternate allele of the variant.\n",
    "\n",
    "    Returns:\n",
    "        A boolean column that is True if the risk allele is the same as the reference or alternate allele,\n",
    "        or if the reverse complement of the risk allele is the same as the reference or alternate allele.\n",
    "    \n",
    "    Examples:\n",
    "        >>> d = [\n",
    "        ...     ('A', 'A', 'G'),\n",
    "        ...     ('A', 'T', 'G'),\n",
    "        ...     ('A', 'C', 'G'),\n",
    "        ...     ('A', 'A', '?'),\n",
    "        ...     (None, None, 'A'),\n",
    "        ... ]\n",
    "        >>> df = spark.createDataFrame(d, ['riskAllele', 'referenceAllele', 'alternateAllele'])\n",
    "        >>> df.withColumn(\"isConcordant\", _check_concordance(f.col(\"riskAllele\"),f.col('referenceAllele'), f.col('alternateAllele'))).show()\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        |associationId|        gnomad|   gwas|isRsIdMatched|or_confidence_interval|\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        |            1|[rs123, rs523]|[rs123]|         true|                  true|\n",
    "        |            2|            []|[rs123]|        false|                 false|\n",
    "        |            2|[rs123, rs523]|     []|        false|                 false|\n",
    "        +-------------+--------------+-------+-------------+----------------------+\n",
    "        <BLANKLINE>\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculating the reverse complement of the risk allele:\n",
    "    risk_allele_reverse_complement = f.when(\n",
    "        risk_allele.rlike(r\"^[ACTG]+$\"),\n",
    "        f.reverse(f.translate(risk_allele, \"ACTG\", \"TGAC\")),\n",
    "    ).otherwise(risk_allele)\n",
    "\n",
    "    # OK, is the risk allele or the reverse complent is the same as the mapped alleles:\n",
    "    return (\n",
    "        f.when(\n",
    "            (risk_allele == reference_allele) | (risk_allele == alternate_allele),\n",
    "            True,\n",
    "        )\n",
    "        # If risk allele is found on the negative strand:\n",
    "        .when(\n",
    "            (risk_allele_reverse_complement == reference_allele)\n",
    "            | (risk_allele_reverse_complement == alternate_allele),\n",
    "            True,\n",
    "        )\n",
    "        # If risk allele is ambiguous, still accepted: < This condition could be reconsidered\n",
    "        .when(risk_allele == \"?\", True)\n",
    "        # If the association could not be mapped we keep it:\n",
    "        .when(reference_allele.isNull(), True)\n",
    "        # Allele is discordant:\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "\n",
    "d = [\n",
    "    ('A', 'A', 'G'),\n",
    "    ('A', 'T', 'G'),\n",
    "    ('A', 'C', 'G'),\n",
    "    ('A', 'A', '?'),\n",
    "    (None, None, 'A'),\n",
    "]\n",
    "df = spark.createDataFrame(d, ['riskAllele', 'referenceAllele', 'alternateAllele'])\n",
    "df.withColumn(\"isConcordant\", _check_concordance(f.col(\"riskAllele\"),f.col('referenceAllele'), f.col('alternateAllele'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+------------+\n",
      "|associationId|filter|isConcordant|\n",
      "+-------------+------+------------+\n",
      "|            1| false|        true|\n",
      "|            1| false|        true|\n",
      "|            3|  true|        true|\n",
      "|            3|  true|        true|\n",
      "|            2| false|       false|\n",
      "|            2|  true|        true|\n",
      "+-------------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _find_mappings_to_drop(association_id: Column, filter_column: Column) -> Column:\n",
    "    \"\"\"Flagging mappings to drop for each association.\n",
    "\n",
    "    Some associations have multiple mappings. Some has matching rsId others don't. We only\n",
    "    want to drop the non-matching mappings, when a matching is available for the given association.\n",
    "    This logic can be generalised for other measures eg. allele concordance.\n",
    "\n",
    "    Args:\n",
    "        association_id (Column): association identifier column\n",
    "        filter_column (Column): boolean col indicating to keep a mapping\n",
    "\n",
    "    Returns:\n",
    "        A column with a boolean value.\n",
    "\n",
    "    Examples:\n",
    "    >>> d = [\n",
    "    ...    (1, False),\n",
    "    ...    (1, False),\n",
    "    ...    (2, False),\n",
    "    ...    (2, True),\n",
    "    ...    (3, True),\n",
    "    ...    (3, True),\n",
    "    ...]\n",
    "    >>> df = spark.createDataFrame(d, ['associationId', 'filter'])\n",
    "    >>> df.withColumn(\"isConcordant\", _find_mappings_to_drop(f.col(\"associationId\"),f.col('filter'))).show()\n",
    "    +-------------+------+------------+\n",
    "    |associationId|filter|isConcordant|\n",
    "    +-------------+------+------------+\n",
    "    |            1| false|        true|\n",
    "    |            1| false|        true|\n",
    "    |            3|  true|        true|\n",
    "    |            3|  true|        true|\n",
    "    |            2| false|       false|\n",
    "    |            2|  true|        true|\n",
    "    +-------------+------+------------+\n",
    "    <BLANKLINE>\n",
    "    \n",
    "    \"\"\"\n",
    "    w = Window.partitionBy(association_id)\n",
    "\n",
    "    # Generating a boolean column informing if the filter column contains true anywhere for the association:\n",
    "    aggregated_filter = f.when(\n",
    "        f.array_contains(f.collect_set(filter_column).over(w), True), True\n",
    "    ).otherwise(False)\n",
    "\n",
    "    # Generate a filter column:\n",
    "    return f.when(aggregated_filter & (~filter_column), False).otherwise(True)\n",
    "\n",
    "\n",
    "d = [\n",
    "    (1, False),\n",
    "    (1, False),\n",
    "    (2, False),\n",
    "    (2, True),\n",
    "    (3, True),\n",
    "    (3, True),\n",
    "]\n",
    "df = spark.createDataFrame(d, ['associationId', 'filter'])\n",
    "df.withColumn(\"isConcordant\", _find_mappings_to_drop(f.col(\"associationId\"),f.col('filter'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------+\n",
      "|associationId|maxMaf|isTopMaf|\n",
      "+-------------+------+--------+\n",
      "|            1|   0.4|    true|\n",
      "|            1|   0.4|   false|\n",
      "|            3|  null|    true|\n",
      "|            2|   0.2|    true|\n",
      "|            2|   0.1|   false|\n",
      "+-------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _keep_mapping_with_top_maf(association_id: Column, maf_column: Column) -> Column:\n",
    "    \"\"\"For each association ID, keep the row with the highest MAF.\n",
    "\n",
    "    Args:\n",
    "        association_id (Column): Column\n",
    "        maf_column (Column): the column that contains the MAF values\n",
    "\n",
    "    Returns:\n",
    "        A column with a boolean value.\n",
    "\n",
    "    Examples:\n",
    "    >>> d = [\n",
    "    ...    (1, 0.4),\n",
    "    ...    (1, 0.4),\n",
    "    ...    (2, 0.2),\n",
    "    ...    (2, 0.1),\n",
    "    ...    (3, None),\n",
    "    ... ]\n",
    "    >>> df = spark.createDataFrame(d, ['associationId', 'maxMaf'])\n",
    "    >>> df.withColumn(\"isTopMaf\", _keep_mapping_with_top_maf(f.col(\"associationId\"),f.col('maxMaf'))).show()\n",
    "    +-------------+------+--------+\n",
    "    |associationId|maxMaf|isTopMaf|\n",
    "    +-------------+------+--------+\n",
    "    |            1|   0.4|    true|\n",
    "    |            1|   0.4|   false|\n",
    "    |            3|  null|    true|\n",
    "    |            2|   0.2|    true|\n",
    "    |            2|   0.1|   false|\n",
    "    +-------------+------+--------+\n",
    "    <BLANKLINE>\n",
    "    \n",
    "    \"\"\"\n",
    "    w = Window.partitionBy(association_id).orderBy(f.desc(maf_column))\n",
    "    row_numbers = f.row_number().over(w)\n",
    "    return f.when(row_numbers == 1, True).otherwise(False)\n",
    "\n",
    "\n",
    "\n",
    "d = [\n",
    "    (1, 0.4),\n",
    "    (1, 0.4),\n",
    "    (2, 0.2),\n",
    "    (2, 0.1),\n",
    "    (3, None),\n",
    "]\n",
    "df = spark.createDataFrame(d, ['associationId', 'maxMaf'])\n",
    "df.withColumn(\"isTopMaf\", _keep_mapping_with_top_maf(f.col(\"associationId\"),f.col('maxMaf'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de3a7304373a2ed386fe951c9137ef8d6c9c0656a76027db0e908c100510c9c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
